{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFhMDyD-vXLs"
      },
      "source": [
        "NOTE: For the most up to date version of this notebook, please be sure to copy from this link:\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ByRi9d6_Yzu0nrEKArmLMLuMaZjYfygO#scrollTo=WgHANbxqWJPa)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgHANbxqWJPa"
      },
      "source": [
        "## **Training YOLOv3 object detection on a custom dataset**\n",
        "\n",
        "ðŸ’¡ Recommendation: [Open this blog post](https://blog.roboflow.ai/training-a-yolov3-object-detection-model-with-a-custom-dataset/) to continue.\n",
        "\n",
        "### **Overview**\n",
        "\n",
        "This notebook walks through how to train a YOLOv3 object detection model on your own dataset using Roboflow and Colab.\n",
        "\n",
        "In this specific example, we'll training an object detection model to recognize chess pieces in images. **To adapt this example to your own dataset, you only need to change one line of code in this notebook.**\n",
        "\n",
        "![Chess Example](https://i.imgur.com/nkjobw1.png)\n",
        "\n",
        "### **Our Data**\n",
        "\n",
        "Our dataset of 289 chess images (and 2894 annotations!) is hosted publicly on Roboflow [here](https://public.roboflow.ai/object-detection/chess-full).\n",
        "\n",
        "### **Our Model**\n",
        "\n",
        "We'll be training a YOLOv3 (You Only Look Once) model. This specific model is a one-shot learner, meaning each image only passes through the network once to make a prediction, which allows the architecture to be very performant, viewing up to 60 frames per second in predicting against video feeds.\n",
        "\n",
        "The GitHub repo containing the majority of the code we'll use is available [here](https://github.com/roboflow-ai/keras-yolo3.git).\n",
        "\n",
        "### **Training**\n",
        "\n",
        "Google Colab provides free GPU resources. Click \"Runtime\" â†’ \"Change runtime type\" â†’ Hardware Accelerator dropdown to \"GPU.\"\n",
        "\n",
        "Colab does have memory limitations, and notebooks must be open in your browser to run. Sessions automatically clear themselves after 24 hours.\n",
        "\n",
        "### **Inference**\n",
        "\n",
        "We'll leverage the `python_video.py` script to produce predictions. Arguments are specified below.\n",
        "\n",
        "It's recommended that you expand the left-hand panel to view this notebook's Table of contents, Code Snippets, and Files.\n",
        "\n",
        "![Expand Colab](https://i.imgur.com/r8kWzIv.png \"Click here\")\n",
        "\n",
        "Then, click \"Files.\" You'll see files appear here as we work through the notebook.\n",
        "\n",
        "\n",
        "### **About**\n",
        "\n",
        "[Roboflow](https://roboflow.ai) makes managing, preprocessing, augmenting, and versioning datasets for computer vision seamless.\n",
        "\n",
        "Developers reduce 50% of their boilerplate code when using Roboflow's workflow, save training time, and increase model reproducibility.\n",
        "\n",
        "#### ![Roboflow Workmark](https://i.imgur.com/WHFqYSJ.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHNPC6kwbKAL"
      },
      "source": [
        "## Setup our environment\n",
        "\n",
        "First, we'll install the version of Keras our YOLOv3 implementation calls for and verify it installs corrects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pyrwfpiiEkH",
        "outputId": "58282faf-6f08-421a-ee83-7978d6930853"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, Roboflow\n"
          ]
        }
      ],
      "source": [
        "# Get our kernel running\n",
        "print(\"Hello, Roboflow\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5uU7LmXI9gM"
      },
      "source": [
        "## Convert back to python 3.5 to resolve dependencies in the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StsEFBkv0GR8",
        "outputId": "624e6bcd-65d3-469c-d65d-39b219237388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PREFIX=/usr/local\n",
            "installing: python-3.5.2-0 ...\n",
            "installing: conda-env-2.6.0-0 ...\n",
            "installing: openssl-1.0.2j-0 ...\n",
            "installing: pycosat-0.6.1-py35_1 ...\n",
            "installing: readline-6.2-2 ...\n",
            "installing: requests-2.11.1-py35_0 ...\n",
            "installing: ruamel_yaml-0.11.14-py35_0 ...\n",
            "installing: sqlite-3.13.0-0 ...\n",
            "installing: tk-8.5.18-0 ...\n",
            "installing: xz-5.2.2-0 ...\n",
            "installing: yaml-0.1.6-0 ...\n",
            "installing: zlib-1.2.8-3 ...\n",
            "installing: conda-4.2.12-py35_0 ...\n",
            "installing: pycrypto-2.6.1-py35_4 ...\n",
            "installing: pip-8.1.2-py35_0 ...\n",
            "installing: wheel-0.29.0-py35_0 ...\n",
            "installing: setuptools-27.2.0-py35_0 ...\n",
            "creating default environment...\n",
            "using -f (force) option\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--2024-04-01 09:08:32--  https://repo.continuum.io/miniconda/Miniconda3-4.2.12-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.177.84, 104.18.176.84, 2606:4700::6812:b154, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.177.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-4.2.12-Linux-x86_64.sh [following]\n",
            "--2024-04-01 09:08:33--  https://repo.anaconda.com/miniconda/Miniconda3-4.2.12-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8203, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33905474 (32M) [application/x-sh]\n",
            "Saving to: â€˜Miniconda3-4.2.12-Linux-x86_64.shâ€™\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0% 93.5M 0s\n",
            "    50K .......... .......... .......... .......... ..........  0% 5.02M 3s\n",
            "   100K .......... .......... .......... .......... ..........  0% 6.81M 4s\n",
            "   150K .......... .......... .......... .......... ..........  0% 6.93M 4s\n",
            "   200K .......... .......... .......... .......... ..........  0%  220M 3s\n",
            "   250K .......... .......... .......... .......... ..........  0%  168M 3s\n",
            "   300K .......... .......... .......... .......... ..........  1%  139M 2s\n",
            "   350K .......... .......... .......... .......... ..........  1% 7.66M 3s\n",
            "   400K .......... .......... .......... .......... ..........  1%  296M 2s\n",
            "   450K .......... .......... .......... .......... ..........  1%  132M 2s\n",
            "   500K .......... .......... .......... .......... ..........  1%  170M 2s\n",
            "   550K .......... .......... .......... .......... ..........  1%  140M 2s\n",
            "   600K .......... .......... .......... .......... ..........  1%  108M 2s\n",
            "   650K .......... .......... .......... .......... ..........  2%  121M 2s\n",
            "   700K .......... .......... .......... .......... ..........  2%  237M 1s\n",
            "   750K .......... .......... .......... .......... ..........  2%  108M 1s\n",
            "   800K .......... .......... .......... .......... ..........  2%  125M 1s\n",
            "   850K .......... .......... .......... .......... ..........  2% 5.14M 2s\n",
            "   900K .......... .......... .......... .......... ..........  2%  215M 2s\n",
            "   950K .......... .......... .......... .......... ..........  3%  242M 1s\n",
            "  1000K .......... .......... .......... .......... ..........  3%  260M 1s\n",
            "  1050K .......... .......... .......... .......... ..........  3%  285M 1s\n",
            "  1100K .......... .......... .......... .......... ..........  3%  257M 1s\n",
            "  1150K .......... .......... .......... .......... ..........  3%  210M 1s\n",
            "  1200K .......... .......... .......... .......... ..........  3%  285M 1s\n",
            "  1250K .......... .......... .......... .......... ..........  3%  281M 1s\n",
            "  1300K .......... .......... .......... .......... ..........  4%  286M 1s\n",
            "  1350K .......... .......... .......... .......... ..........  4%  101M 1s\n",
            "  1400K .......... .......... .......... .......... ..........  4% 58.6M 1s\n",
            "  1450K .......... .......... .......... .......... ..........  4% 26.0M 1s\n",
            "  1500K .......... .......... .......... .......... ..........  4% 57.4M 1s\n",
            "  1550K .......... .......... .......... .......... ..........  4% 52.2M 1s\n",
            "  1600K .......... .......... .......... .......... ..........  4% 72.8M 1s\n",
            "  1650K .......... .......... .......... .......... ..........  5%  259M 1s\n",
            "  1700K .......... .......... .......... .......... ..........  5% 6.53M 1s\n",
            "  1750K .......... .......... .......... .......... ..........  5%  222M 1s\n",
            "  1800K .......... .......... .......... .......... ..........  5% 85.0M 1s\n",
            "  1850K .......... .......... .......... .......... ..........  5% 26.1M 1s\n",
            "  1900K .......... .......... .......... .......... ..........  5% 17.7M 1s\n",
            "  1950K .......... .......... .......... .......... ..........  6%  199M 1s\n",
            "  2000K .......... .......... .......... .......... ..........  6% 49.7M 1s\n",
            "  2050K .......... .......... .......... .......... ..........  6% 36.6M 1s\n",
            "  2100K .......... .......... .......... .......... ..........  6% 84.3M 1s\n",
            "  2150K .......... .......... .......... .......... ..........  6%  225M 1s\n",
            "  2200K .......... .......... .......... .......... ..........  6% 70.5M 1s\n",
            "  2250K .......... .......... .......... .......... ..........  6% 60.8M 1s\n",
            "  2300K .......... .......... .......... .......... ..........  7%  100M 1s\n",
            "  2350K .......... .......... .......... .......... ..........  7% 45.8M 1s\n",
            "  2400K .......... .......... .......... .......... ..........  7% 61.6M 1s\n",
            "  2450K .......... .......... .......... .......... ..........  7% 44.9M 1s\n",
            "  2500K .......... .......... .......... .......... ..........  7%  138M 1s\n",
            "  2550K .......... .......... .......... .......... ..........  7%  118M 1s\n",
            "  2600K .......... .......... .......... .......... ..........  8% 85.7M 1s\n",
            "  2650K .......... .......... .......... .......... ..........  8% 51.7M 1s\n",
            "  2700K .......... .......... .......... .......... ..........  8% 61.6M 1s\n",
            "  2750K .......... .......... .......... .......... ..........  8% 53.6M 1s\n",
            "  2800K .......... .......... .......... .......... ..........  8% 56.0M 1s\n",
            "  2850K .......... .......... .......... .......... ..........  8% 55.8M 1s\n",
            "  2900K .......... .......... .......... .......... ..........  8% 61.6M 1s\n",
            "  2950K .......... .......... .......... .......... ..........  9%  185M 1s\n",
            "  3000K .......... .......... .......... .......... ..........  9%  206M 1s\n",
            "  3050K .......... .......... .......... .......... ..........  9%  103M 1s\n",
            "  3100K .......... .......... .......... .......... ..........  9% 53.1M 1s\n",
            "  3150K .......... .......... .......... .......... ..........  9% 49.2M 1s\n",
            "  3200K .......... .......... .......... .......... ..........  9% 60.3M 1s\n",
            "  3250K .......... .......... .......... .......... ..........  9% 60.3M 1s\n",
            "  3300K .......... .......... .......... .......... .......... 10%  107M 1s\n",
            "  3350K .......... .......... .......... .......... .......... 10%  157M 1s\n",
            "  3400K .......... .......... .......... .......... .......... 10%  203M 1s\n",
            "  3450K .......... .......... .......... .......... .......... 10%  259M 1s\n",
            "  3500K .......... .......... .......... .......... .......... 10%  285M 1s\n",
            "  3550K .......... .......... .......... .......... .......... 10%  219M 1s\n",
            "  3600K .......... .......... .......... .......... .......... 11% 68.3M 1s\n",
            "  3650K .......... .......... .......... .......... .......... 11% 64.3M 1s\n",
            "  3700K .......... .......... .......... .......... .......... 11% 53.0M 1s\n",
            "  3750K .......... .......... .......... .......... .......... 11% 50.7M 1s\n",
            "  3800K .......... .......... .......... .......... .......... 11% 61.1M 1s\n",
            "  3850K .......... .......... .......... .......... .......... 11% 64.9M 1s\n",
            "  3900K .......... .......... .......... .......... .......... 11% 64.3M 1s\n",
            "  3950K .......... .......... .......... .......... .......... 12% 43.9M 1s\n",
            "  4000K .......... .......... .......... .......... .......... 12% 47.9M 1s\n",
            "  4050K .......... .......... .......... .......... .......... 12% 55.0M 1s\n",
            "  4100K .......... .......... .......... .......... .......... 12% 50.7M 1s\n",
            "  4150K .......... .......... .......... .......... .......... 12% 55.1M 1s\n",
            "  4200K .......... .......... .......... .......... .......... 12%  251M 1s\n",
            "  4250K .......... .......... .......... .......... .......... 12%  265M 1s\n",
            "  4300K .......... .......... .......... .......... .......... 13%  267M 1s\n",
            "  4350K .......... .......... .......... .......... .......... 13%  221M 1s\n",
            "  4400K .......... .......... .......... .......... .......... 13%  223M 1s\n",
            "  4450K .......... .......... .......... .......... .......... 13% 64.4M 1s\n",
            "  4500K .......... .......... .......... .......... .......... 13% 55.6M 1s\n",
            "  4550K .......... .......... .......... .......... .......... 13% 49.6M 1s\n",
            "  4600K .......... .......... .......... .......... .......... 14% 50.9M 1s\n",
            "  4650K .......... .......... .......... .......... .......... 14% 63.0M 1s\n",
            "  4700K .......... .......... .......... .......... .......... 14% 56.5M 1s\n",
            "  4750K .......... .......... .......... .......... .......... 14% 64.6M 1s\n",
            "  4800K .......... .......... .......... .......... .......... 14%  276M 1s\n",
            "  4850K .......... .......... .......... .......... .......... 14%  270M 1s\n",
            "  4900K .......... .......... .......... .......... .......... 14%  248M 1s\n",
            "  4950K .......... .......... .......... .......... .......... 15%  222M 1s\n",
            "  5000K .......... .......... .......... .......... .......... 15%  267M 1s\n",
            "  5050K .......... .......... .......... .......... .......... 15% 69.2M 1s\n",
            "  5100K .......... .......... .......... .......... .......... 15% 60.1M 1s\n",
            "  5150K .......... .......... .......... .......... .......... 15% 40.5M 1s\n",
            "  5200K .......... .......... .......... .......... .......... 15% 57.6M 1s\n",
            "  5250K .......... .......... .......... .......... .......... 16% 62.2M 1s\n",
            "  5300K .......... .......... .......... .......... .......... 16% 63.7M 1s\n",
            "  5350K .......... .......... .......... .......... .......... 16% 48.6M 1s\n",
            "  5400K .......... .......... .......... .......... .......... 16% 67.2M 1s\n",
            "  5450K .......... .......... .......... .......... .......... 16%  167M 1s\n",
            "  5500K .......... .......... .......... .......... .......... 16% 64.5M 1s\n",
            "  5550K .......... .......... .......... .......... .......... 16%  117M 1s\n",
            "  5600K .......... .......... .......... .......... .......... 17%  240M 1s\n",
            "  5650K .......... .......... .......... .......... .......... 17%  205M 1s\n",
            "  5700K .......... .......... .......... .......... .......... 17%  192M 1s\n",
            "  5750K .......... .......... .......... .......... .......... 17% 40.0M 1s\n",
            "  5800K .......... .......... .......... .......... .......... 17% 50.5M 1s\n",
            "  5850K .......... .......... .......... .......... .......... 17% 62.9M 1s\n",
            "  5900K .......... .......... .......... .......... .......... 17% 56.0M 1s\n",
            "  5950K .......... .......... .......... .......... .......... 18% 51.7M 1s\n",
            "  6000K .......... .......... .......... .......... .......... 18% 64.0M 1s\n",
            "  6050K .......... .......... .......... .......... .......... 18%  165M 1s\n",
            "  6100K .......... .......... .......... .......... .......... 18%  217M 1s\n",
            "  6150K .......... .......... .......... .......... .......... 18% 52.9M 1s\n",
            "  6200K .......... .......... .......... .......... .......... 18% 49.5M 1s\n",
            "  6250K .......... .......... .......... .......... .......... 19%  149M 1s\n",
            "  6300K .......... .......... .......... .......... .......... 19%  276M 1s\n",
            "  6350K .......... .......... .......... .......... .......... 19%  229M 1s\n",
            "  6400K .......... .......... .......... .......... .......... 19%  183M 1s\n",
            "  6450K .......... .......... .......... .......... .......... 19% 74.7M 1s\n",
            "  6500K .......... .......... .......... .......... .......... 19% 63.4M 1s\n",
            "  6550K .......... .......... .......... .......... .......... 19% 29.8M 1s\n",
            "  6600K .......... .......... .......... .......... .......... 20% 60.3M 1s\n",
            "  6650K .......... .......... .......... .......... .......... 20% 11.8M 1s\n",
            "  6700K .......... .......... .......... .......... .......... 20% 19.1M 1s\n",
            "  6750K .......... .......... .......... .......... .......... 20%  186M 1s\n",
            "  6800K .......... .......... .......... .......... .......... 20%  253M 1s\n",
            "  6850K .......... .......... .......... .......... .......... 20%  212M 1s\n",
            "  6900K .......... .......... .......... .......... .......... 20%  232M 1s\n",
            "  6950K .......... .......... .......... .......... .......... 21%  201M 0s\n",
            "  7000K .......... .......... .......... .......... .......... 21%  224M 0s\n",
            "  7050K .......... .......... .......... .......... .......... 21% 29.7M 0s\n",
            "  7100K .......... .......... .......... .......... .......... 21% 8.64M 1s\n",
            "  7150K .......... .......... .......... .......... .......... 21% 42.5M 1s\n",
            "  7200K .......... .......... .......... .......... .......... 21% 56.0M 1s\n",
            "  7250K .......... .......... .......... .......... .......... 22% 56.7M 1s\n",
            "  7300K .......... .......... .......... .......... .......... 22% 60.6M 1s\n",
            "  7350K .......... .......... .......... .......... .......... 22% 54.8M 1s\n",
            "  7400K .......... .......... .......... .......... .......... 22% 55.7M 1s\n",
            "  7450K .......... .......... .......... .......... .......... 22%  196M 1s\n",
            "  7500K .......... .......... .......... .......... .......... 22% 62.7M 1s\n",
            "  7550K .......... .......... .......... .......... .......... 22% 64.2M 0s\n",
            "  7600K .......... .......... .......... .......... .......... 23%  207M 0s\n",
            "  7650K .......... .......... .......... .......... .......... 23%  276M 0s\n",
            "  7700K .......... .......... .......... .......... .......... 23%  258M 0s\n",
            "  7750K .......... .......... .......... .......... .......... 23%  233M 0s\n",
            "  7800K .......... .......... .......... .......... .......... 23%  141M 0s\n",
            "  7850K .......... .......... .......... .......... .......... 23% 55.0M 0s\n",
            "  7900K .......... .......... .......... .......... .......... 24% 57.6M 0s\n",
            "  7950K .......... .......... .......... .......... .......... 24% 52.2M 0s\n",
            "  8000K .......... .......... .......... .......... .......... 24% 62.2M 0s\n",
            "  8050K .......... .......... .......... .......... .......... 24% 60.8M 0s\n",
            "  8100K .......... .......... .......... .......... .......... 24% 56.9M 0s\n",
            "  8150K .......... .......... .......... .......... .......... 24% 51.7M 0s\n",
            "  8200K .......... .......... .......... .......... .......... 24% 60.5M 0s\n",
            "  8250K .......... .......... .......... .......... .......... 25%  111M 0s\n",
            "  8300K .......... .......... .......... .......... .......... 25% 57.1M 0s\n",
            "  8350K .......... .......... .......... .......... .......... 25% 50.8M 0s\n",
            "  8400K .......... .......... .......... .......... .......... 25% 95.4M 0s\n",
            "  8450K .......... .......... .......... .......... .......... 25% 87.3M 0s\n",
            "  8500K .......... .......... .......... .......... .......... 25% 70.0M 0s\n",
            "  8550K .......... .......... .......... .......... .......... 25% 50.0M 0s\n",
            "  8600K .......... .......... .......... .......... .......... 26% 78.3M 0s\n",
            "  8650K .......... .......... .......... .......... .......... 26% 57.0M 0s\n",
            "  8700K .......... .......... .......... .......... .......... 26% 74.1M 0s\n",
            "  8750K .......... .......... .......... .......... .......... 26% 60.3M 0s\n",
            "  8800K .......... .......... .......... .......... .......... 26% 85.8M 0s\n",
            "  8850K .......... .......... .......... .......... .......... 26% 57.4M 0s\n",
            "  8900K .......... .......... .......... .......... .......... 27% 84.1M 0s\n",
            "  8950K .......... .......... .......... .......... .......... 27% 73.1M 0s\n",
            "  9000K .......... .......... .......... .......... .......... 27%  272M 0s\n",
            "  9050K .......... .......... .......... .......... .......... 27%  206M 0s\n",
            "  9100K .......... .......... .......... .......... .......... 27% 60.6M 0s\n",
            "  9150K .......... .......... .......... .......... .......... 27% 50.2M 0s\n",
            "  9200K .......... .......... .......... .......... .......... 27% 50.6M 0s\n",
            "  9250K .......... .......... .......... .......... .......... 28% 69.1M 0s\n",
            "  9300K .......... .......... .......... .......... .......... 28% 23.3M 0s\n",
            "  9350K .......... .......... .......... .......... .......... 28%  130M 0s\n",
            "  9400K .......... .......... .......... .......... .......... 28%  100M 0s\n",
            "  9450K .......... .......... .......... .......... .......... 28% 49.4M 0s\n",
            "  9500K .......... .......... .......... .......... .......... 28% 56.0M 0s\n",
            "  9550K .......... .......... .......... .......... .......... 28% 73.5M 0s\n",
            "  9600K .......... .......... .......... .......... .......... 29% 88.8M 0s\n",
            "  9650K .......... .......... .......... .......... .......... 29% 56.7M 0s\n",
            "  9700K .......... .......... .......... .......... .......... 29%  257M 0s\n",
            "  9750K .......... .......... .......... .......... .......... 29%  173M 0s\n",
            "  9800K .......... .......... .......... .......... .......... 29% 63.2M 0s\n",
            "  9850K .......... .......... .......... .......... .......... 29% 58.2M 0s\n",
            "  9900K .......... .......... .......... .......... .......... 30% 57.8M 0s\n",
            "  9950K .......... .......... .......... .......... .......... 30% 53.3M 0s\n",
            " 10000K .......... .......... .......... .......... .......... 30%  177M 0s\n",
            " 10050K .......... .......... .......... .......... .......... 30%  248M 0s\n",
            " 10100K .......... .......... .......... .......... .......... 30%  140M 0s\n",
            " 10150K .......... .......... .......... .......... .......... 30% 48.1M 0s\n",
            " 10200K .......... .......... .......... .......... .......... 30% 55.2M 0s\n",
            " 10250K .......... .......... .......... .......... .......... 31% 58.3M 0s\n",
            " 10300K .......... .......... .......... .......... .......... 31% 88.9M 0s\n",
            " 10350K .......... .......... .......... .......... .......... 31% 37.1M 0s\n",
            " 10400K .......... .......... .......... .......... .......... 31% 49.9M 0s\n",
            " 10450K .......... .......... .......... .......... .......... 31% 44.4M 0s\n",
            " 10500K .......... .......... .......... .......... .......... 31% 64.1M 0s\n",
            " 10550K .......... .......... .......... .......... .......... 32% 49.8M 0s\n",
            " 10600K .......... .......... .......... .......... .......... 32% 70.4M 0s\n",
            " 10650K .......... .......... .......... .......... .......... 32%  104M 0s\n",
            " 10700K .......... .......... .......... .......... .......... 32% 60.2M 0s\n",
            " 10750K .......... .......... .......... .......... .......... 32% 75.9M 0s\n",
            " 10800K .......... .......... .......... .......... .......... 32%  268M 0s\n",
            " 10850K .......... .......... .......... .......... .......... 32%  120M 0s\n",
            " 10900K .......... .......... .......... .......... .......... 33% 5.21M 0s\n",
            " 10950K .......... .......... .......... .......... .......... 33% 33.1M 0s\n",
            " 11000K .......... .......... .......... .......... .......... 33% 49.4M 0s\n",
            " 11050K .......... .......... .......... .......... .......... 33% 19.8M 0s\n",
            " 11100K .......... .......... .......... .......... .......... 33% 58.8M 0s\n",
            " 11150K .......... .......... .......... .......... .......... 33% 91.5M 0s\n",
            " 11200K .......... .......... .......... .......... .......... 33% 66.8M 0s\n",
            " 11250K .......... .......... .......... .......... .......... 34% 57.1M 0s\n",
            " 11300K .......... .......... .......... .......... .......... 34% 70.7M 0s\n",
            " 11350K .......... .......... .......... .......... .......... 34% 37.0M 0s\n",
            " 11400K .......... .......... .......... .......... .......... 34% 72.5M 0s\n",
            " 11450K .......... .......... .......... .......... .......... 34% 31.6M 0s\n",
            " 11500K .......... .......... .......... .......... .......... 34% 68.7M 0s\n",
            " 11550K .......... .......... .......... .......... .......... 35%  219M 0s\n",
            " 11600K .......... .......... .......... .......... .......... 35%  271M 0s\n",
            " 11650K .......... .......... .......... .......... .......... 35%  263M 0s\n",
            " 11700K .......... .......... .......... .......... .......... 35%  236M 0s\n",
            " 11750K .......... .......... .......... .......... .......... 35%  229M 0s\n",
            " 11800K .......... .......... .......... .......... .......... 35% 22.2M 0s\n",
            " 11850K .......... .......... .......... .......... .......... 35% 61.4M 0s\n",
            " 11900K .......... .......... .......... .......... .......... 36% 63.6M 0s\n",
            " 11950K .......... .......... .......... .......... .......... 36% 54.6M 0s\n",
            " 12000K .......... .......... .......... .......... .......... 36% 16.5M 0s\n",
            " 12050K .......... .......... .......... .......... .......... 36% 35.6M 0s\n",
            " 12100K .......... .......... .......... .......... .......... 36%  281M 0s\n",
            " 12150K .......... .......... .......... .......... .......... 36%  159M 0s\n",
            " 12200K .......... .......... .......... .......... .......... 36% 90.3M 0s\n",
            " 12250K .......... .......... .......... .......... .......... 37% 16.0M 0s\n",
            " 12300K .......... .......... .......... .......... .......... 37%  241M 0s\n",
            " 12350K .......... .......... .......... .......... .......... 37%  157M 0s\n",
            " 12400K .......... .......... .......... .......... .......... 37% 20.5M 0s\n",
            " 12450K .......... .......... .......... .......... .......... 37%  157M 0s\n",
            " 12500K .......... .......... .......... .......... .......... 37%  162M 0s\n",
            " 12550K .......... .......... .......... .......... .......... 38% 11.7M 0s\n",
            " 12600K .......... .......... .......... .......... .......... 38%  231M 0s\n",
            " 12650K .......... .......... .......... .......... .......... 38%  233M 0s\n",
            " 12700K .......... .......... .......... .......... .......... 38%  247M 0s\n",
            " 12750K .......... .......... .......... .......... .......... 38%  204M 0s\n",
            " 12800K .......... .......... .......... .......... .......... 38% 18.8M 0s\n",
            " 12850K .......... .......... .......... .......... .......... 38%  232M 0s\n",
            " 12900K .......... .......... .......... .......... .......... 39%  220M 0s\n",
            " 12950K .......... .......... .......... .......... .......... 39% 20.5M 0s\n",
            " 13000K .......... .......... .......... .......... .......... 39%  221M 0s\n",
            " 13050K .......... .......... .......... .......... .......... 39%  223M 0s\n",
            " 13100K .......... .......... .......... .......... .......... 39%  235M 0s\n",
            " 13150K .......... .......... .......... .......... .......... 39% 7.47M 0s\n",
            " 13200K .......... .......... .......... .......... .......... 40%  243M 0s\n",
            " 13250K .......... .......... .......... .......... .......... 40%  235M 0s\n",
            " 13300K .......... .......... .......... .......... .......... 40% 19.3M 0s\n",
            " 13350K .......... .......... .......... .......... .......... 40%  201M 0s\n",
            " 13400K .......... .......... .......... .......... .......... 40%  254M 0s\n",
            " 13450K .......... .......... .......... .......... .......... 40%  231M 0s\n",
            " 13500K .......... .......... .......... .......... .......... 40%  278M 0s\n",
            " 13550K .......... .......... .......... .......... .......... 41%  238M 0s\n",
            " 13600K .......... .......... .......... .......... .......... 41%  245M 0s\n",
            " 13650K .......... .......... .......... .......... .......... 41%  222M 0s\n",
            " 13700K .......... .......... .......... .......... .......... 41% 8.46M 0s\n",
            " 13750K .......... .......... .......... .......... .......... 41%  125M 0s\n",
            " 13800K .......... .......... .......... .......... .......... 41% 17.6M 0s\n",
            " 13850K .......... .......... .......... .......... .......... 41%  112M 0s\n",
            " 13900K .......... .......... .......... .......... .......... 42%  244M 0s\n",
            " 13950K .......... .......... .......... .......... .......... 42%  126M 0s\n",
            " 14000K .......... .......... .......... .......... .......... 42% 28.6M 0s\n",
            " 14050K .......... .......... .......... .......... .......... 42%  219M 0s\n",
            " 14100K .......... .......... .......... .......... .......... 42% 67.4M 0s\n",
            " 14150K .......... .......... .......... .......... .......... 42% 62.5M 0s\n",
            " 14200K .......... .......... .......... .......... .......... 43%  280M 0s\n",
            " 14250K .......... .......... .......... .......... .......... 43%  294M 0s\n",
            " 14300K .......... .......... .......... .......... .......... 43%  265M 0s\n",
            " 14350K .......... .......... .......... .......... .......... 43%  235M 0s\n",
            " 14400K .......... .......... .......... .......... .......... 43%  286M 0s\n",
            " 14450K .......... .......... .......... .......... .......... 43%  280M 0s\n",
            " 14500K .......... .......... .......... .......... .......... 43%  314M 0s\n",
            " 14550K .......... .......... .......... .......... .......... 44% 37.4M 0s\n",
            " 14600K .......... .......... .......... .......... .......... 44% 75.8M 0s\n",
            " 14650K .......... .......... .......... .......... .......... 44%  183M 0s\n",
            " 14700K .......... .......... .......... .......... .......... 44%  220M 0s\n",
            " 14750K .......... .......... .......... .......... .......... 44%  212M 0s\n",
            " 14800K .......... .......... .......... .......... .......... 44%  211M 0s\n",
            " 14850K .......... .......... .......... .......... .......... 45%  275M 0s\n",
            " 14900K .......... .......... .......... .......... .......... 45%  207M 0s\n",
            " 14950K .......... .......... .......... .......... .......... 45% 27.1M 0s\n",
            " 15000K .......... .......... .......... .......... .......... 45%  219M 0s\n",
            " 15050K .......... .......... .......... .......... .......... 45%  218M 0s\n",
            " 15100K .......... .......... .......... .......... .......... 45%  229M 0s\n",
            " 15150K .......... .......... .......... .......... .......... 45%  153M 0s\n",
            " 15200K .......... .......... .......... .......... .......... 46%  238M 0s\n",
            " 15250K .......... .......... .......... .......... .......... 46% 25.7M 0s\n",
            " 15300K .......... .......... .......... .......... .......... 46%  100M 0s\n",
            " 15350K .......... .......... .......... .......... .......... 46%  200M 0s\n",
            " 15400K .......... .......... .......... .......... .......... 46%  235M 0s\n",
            " 15450K .......... .......... .......... .......... .......... 46%  166M 0s\n",
            " 15500K .......... .......... .......... .......... .......... 46%  149M 0s\n",
            " 15550K .......... .......... .......... .......... .......... 47%  216M 0s\n",
            " 15600K .......... .......... .......... .......... .......... 47%  236M 0s\n",
            " 15650K .......... .......... .......... .......... .......... 47%  123M 0s\n",
            " 15700K .......... .......... .......... .......... .......... 47%  180M 0s\n",
            " 15750K .......... .......... .......... .......... .......... 47% 84.9M 0s\n",
            " 15800K .......... .......... .......... .......... .......... 47% 58.6M 0s\n",
            " 15850K .......... .......... .......... .......... .......... 48%  129M 0s\n",
            " 15900K .......... .......... .......... .......... .......... 48%  152M 0s\n",
            " 15950K .......... .......... .......... .......... .......... 48%  176M 0s\n",
            " 16000K .......... .......... .......... .......... .......... 48% 56.2M 0s\n",
            " 16050K .......... .......... .......... .......... .......... 48%  175M 0s\n",
            " 16100K .......... .......... .......... .......... .......... 48%  111M 0s\n",
            " 16150K .......... .......... .......... .......... .......... 48% 71.2M 0s\n",
            " 16200K .......... .......... .......... .......... .......... 49%  181M 0s\n",
            " 16250K .......... .......... .......... .......... .......... 49%  243M 0s\n",
            " 16300K .......... .......... .......... .......... .......... 49% 56.2M 0s\n",
            " 16350K .......... .......... .......... .......... .......... 49%  159M 0s\n",
            " 16400K .......... .......... .......... .......... .......... 49%  241M 0s\n",
            " 16450K .......... .......... .......... .......... .......... 49% 53.0M 0s\n",
            " 16500K .......... .......... .......... .......... .......... 49%  161M 0s\n",
            " 16550K .......... .......... .......... .......... .......... 50%  219M 0s\n",
            " 16600K .......... .......... .......... .......... .......... 50% 53.9M 0s\n",
            " 16650K .......... .......... .......... .......... .......... 50%  184M 0s\n",
            " 16700K .......... .......... .......... .......... .......... 50%  107M 0s\n",
            " 16750K .......... .......... .......... .......... .......... 50%  140M 0s\n",
            " 16800K .......... .......... .......... .......... .......... 50% 33.6M 0s\n",
            " 16850K .......... .......... .......... .......... .......... 51%  235M 0s\n",
            " 16900K .......... .......... .......... .......... .......... 51% 2.39M 0s\n",
            " 16950K .......... .......... .......... .......... .......... 51%  216M 0s\n",
            " 17000K .......... .......... .......... .......... .......... 51%  232M 0s\n",
            " 17050K .......... .......... .......... .......... .......... 51%  225M 0s\n",
            " 17100K .......... .......... .......... .......... .......... 51%  259M 0s\n",
            " 17150K .......... .......... .......... .......... .......... 51%  222M 0s\n",
            " 17200K .......... .......... .......... .......... .......... 52%  261M 0s\n",
            " 17250K .......... .......... .......... .......... .......... 52%  269M 0s\n",
            " 17300K .......... .......... .......... .......... .......... 52% 8.82M 0s\n",
            " 17350K .......... .......... .......... .......... .......... 52% 16.6M 0s\n",
            " 17400K .......... .......... .......... .......... .......... 52%  215M 0s\n",
            " 17450K .......... .......... .......... .......... .......... 52%  164M 0s\n",
            " 17500K .......... .......... .......... .......... .......... 53% 9.61M 0s\n",
            " 17550K .......... .......... .......... .......... .......... 53%  171M 0s\n",
            " 17600K .......... .......... .......... .......... .......... 53%  241M 0s\n",
            " 17650K .......... .......... .......... .......... .......... 53%  279M 0s\n",
            " 17700K .......... .......... .......... .......... .......... 53%  277M 0s\n",
            " 17750K .......... .......... .......... .......... .......... 53%  230M 0s\n",
            " 17800K .......... .......... .......... .......... .......... 53%  263M 0s\n",
            " 17850K .......... .......... .......... .......... .......... 54%  189M 0s\n",
            " 17900K .......... .......... .......... .......... .......... 54%  234M 0s\n",
            " 17950K .......... .......... .......... .......... .......... 54%  211M 0s\n",
            " 18000K .......... .......... .......... .......... .......... 54% 12.5M 0s\n",
            " 18050K .......... .......... .......... .......... .......... 54%  156M 0s\n",
            " 18100K .......... .......... .......... .......... .......... 54%  222M 0s\n",
            " 18150K .......... .......... .......... .......... .......... 54% 80.3M 0s\n",
            " 18200K .......... .......... .......... .......... .......... 55% 44.8M 0s\n",
            " 18250K .......... .......... .......... .......... .......... 55%  175M 0s\n",
            " 18300K .......... .......... .......... .......... .......... 55%  130M 0s\n",
            " 18350K .......... .......... .......... .......... .......... 55% 93.6M 0s\n",
            " 18400K .......... .......... .......... .......... .......... 55%  210M 0s\n",
            " 18450K .......... .......... .......... .......... .......... 55%  111M 0s\n",
            " 18500K .......... .......... .......... .......... .......... 56%  210M 0s\n",
            " 18550K .......... .......... .......... .......... .......... 56% 93.2M 0s\n",
            " 18600K .......... .......... .......... .......... .......... 56%  105M 0s\n",
            " 18650K .......... .......... .......... .......... .......... 56%  108M 0s\n",
            " 18700K .......... .......... .......... .......... .......... 56%  112M 0s\n",
            " 18750K .......... .......... .......... .......... .......... 56%  158M 0s\n",
            " 18800K .......... .......... .......... .......... .......... 56%  130M 0s\n",
            " 18850K .......... .......... .......... .......... .......... 57%  119M 0s\n",
            " 18900K .......... .......... .......... .......... .......... 57%  218M 0s\n",
            " 18950K .......... .......... .......... .......... .......... 57% 41.3M 0s\n",
            " 19000K .......... .......... .......... .......... .......... 57%  206M 0s\n",
            " 19050K .......... .......... .......... .......... .......... 57%  269M 0s\n",
            " 19100K .......... .......... .......... .......... .......... 57% 74.1M 0s\n",
            " 19150K .......... .......... .......... .......... .......... 57%  206M 0s\n",
            " 19200K .......... .......... .......... .......... .......... 58%  119M 0s\n",
            " 19250K .......... .......... .......... .......... .......... 58%  268M 0s\n",
            " 19300K .......... .......... .......... .......... .......... 58%  283M 0s\n",
            " 19350K .......... .......... .......... .......... .......... 58% 65.0M 0s\n",
            " 19400K .......... .......... .......... .......... .......... 58%  149M 0s\n",
            " 19450K .......... .......... .......... .......... .......... 58%  233M 0s\n",
            " 19500K .......... .......... .......... .......... .......... 59%  176M 0s\n",
            " 19550K .......... .......... .......... .......... .......... 59%  186M 0s\n",
            " 19600K .......... .......... .......... .......... .......... 59% 42.9M 0s\n",
            " 19650K .......... .......... .......... .......... .......... 59% 77.4M 0s\n",
            " 19700K .......... .......... .......... .......... .......... 59%  193M 0s\n",
            " 19750K .......... .......... .......... .......... .......... 59%  152M 0s\n",
            " 19800K .......... .......... .......... .......... .......... 59%  105M 0s\n",
            " 19850K .......... .......... .......... .......... .......... 60%  163M 0s\n",
            " 19900K .......... .......... .......... .......... .......... 60%  139M 0s\n",
            " 19950K .......... .......... .......... .......... .......... 60% 86.3M 0s\n",
            " 20000K .......... .......... .......... .......... .......... 60%  168M 0s\n",
            " 20050K .......... .......... .......... .......... .......... 60%  180M 0s\n",
            " 20100K .......... .......... .......... .......... .......... 60% 5.00M 0s\n",
            " 20150K .......... .......... .......... .......... .......... 61%  216M 0s\n",
            " 20200K .......... .......... .......... .......... .......... 61% 27.7M 0s\n",
            " 20250K .......... .......... .......... .......... .......... 61%  204M 0s\n",
            " 20300K .......... .......... .......... .......... .......... 61% 44.0M 0s\n",
            " 20350K .......... .......... .......... .......... .......... 61%  205M 0s\n",
            " 20400K .......... .......... .......... .......... .......... 61% 28.6M 0s\n",
            " 20450K .......... .......... .......... .......... .......... 61%  194M 0s\n",
            " 20500K .......... .......... .......... .......... .......... 62%  238M 0s\n",
            " 20550K .......... .......... .......... .......... .......... 62%  209M 0s\n",
            " 20600K .......... .......... .......... .......... .......... 62%  223M 0s\n",
            " 20650K .......... .......... .......... .......... .......... 62% 17.7M 0s\n",
            " 20700K .......... .......... .......... .......... .......... 62% 27.4M 0s\n",
            " 20750K .......... .......... .......... .......... .......... 62%  201M 0s\n",
            " 20800K .......... .......... .......... .......... .......... 62%  234M 0s\n",
            " 20850K .......... .......... .......... .......... .......... 63%  204M 0s\n",
            " 20900K .......... .......... .......... .......... .......... 63%  239M 0s\n",
            " 20950K .......... .......... .......... .......... .......... 63%  172M 0s\n",
            " 21000K .......... .......... .......... .......... .......... 63%  257M 0s\n",
            " 21050K .......... .......... .......... .......... .......... 63%  270M 0s\n",
            " 21100K .......... .......... .......... .......... .......... 63% 11.5M 0s\n",
            " 21150K .......... .......... .......... .......... .......... 64%  143M 0s\n",
            " 21200K .......... .......... .......... .......... .......... 64%  202M 0s\n",
            " 21250K .......... .......... .......... .......... .......... 64% 16.7M 0s\n",
            " 21300K .......... .......... .......... .......... .......... 64%  203M 0s\n",
            " 21350K .......... .......... .......... .......... .......... 64% 41.0M 0s\n",
            " 21400K .......... .......... .......... .......... .......... 64%  216M 0s\n",
            " 21450K .......... .......... .......... .......... .......... 64%  205M 0s\n",
            " 21500K .......... .......... .......... .......... .......... 65%  150M 0s\n",
            " 21550K .......... .......... .......... .......... .......... 65%  106M 0s\n",
            " 21600K .......... .......... .......... .......... .......... 65%  203M 0s\n",
            " 21650K .......... .......... .......... .......... .......... 65%  196M 0s\n",
            " 21700K .......... .......... .......... .......... .......... 65%  194M 0s\n",
            " 21750K .......... .......... .......... .......... .......... 65%  143M 0s\n",
            " 21800K .......... .......... .......... .......... .......... 65%  170M 0s\n",
            " 21850K .......... .......... .......... .......... .......... 66%  204M 0s\n",
            " 21900K .......... .......... .......... .......... .......... 66%  166M 0s\n",
            " 21950K .......... .......... .......... .......... .......... 66%  235M 0s\n",
            " 22000K .......... .......... .......... .......... .......... 66%  181M 0s\n",
            " 22050K .......... .......... .......... .......... .......... 66%  251M 0s\n",
            " 22100K .......... .......... .......... .......... .......... 66%  134M 0s\n",
            " 22150K .......... .......... .......... .......... .......... 67%  219M 0s\n",
            " 22200K .......... .......... .......... .......... .......... 67%  284M 0s\n",
            " 22250K .......... .......... .......... .......... .......... 67%  232M 0s\n",
            " 22300K .......... .......... .......... .......... .......... 67%  217M 0s\n",
            " 22350K .......... .......... .......... .......... .......... 67%  209M 0s\n",
            " 22400K .......... .......... .......... .......... .......... 67%  273M 0s\n",
            " 22450K .......... .......... .......... .......... .......... 67%  253M 0s\n",
            " 22500K .......... .......... .......... .......... .......... 68%  169M 0s\n",
            " 22550K .......... .......... .......... .......... .......... 68%  191M 0s\n",
            " 22600K .......... .......... .......... .......... .......... 68%  230M 0s\n",
            " 22650K .......... .......... .......... .......... .......... 68%  218M 0s\n",
            " 22700K .......... .......... .......... .......... .......... 68%  236M 0s\n",
            " 22750K .......... .......... .......... .......... .......... 68%  145M 0s\n",
            " 22800K .......... .......... .......... .......... .......... 69%  217M 0s\n",
            " 22850K .......... .......... .......... .......... .......... 69%  234M 0s\n",
            " 22900K .......... .......... .......... .......... .......... 69%  145M 0s\n",
            " 22950K .......... .......... .......... .......... .......... 69%  212M 0s\n",
            " 23000K .......... .......... .......... .......... .......... 69%  105M 0s\n",
            " 23050K .......... .......... .......... .......... .......... 69%  155M 0s\n",
            " 23100K .......... .......... .......... .......... .......... 69%  224M 0s\n",
            " 23150K .......... .......... .......... .......... .......... 70%  150M 0s\n",
            " 23200K .......... .......... .......... .......... .......... 70%  169M 0s\n",
            " 23250K .......... .......... .......... .......... .......... 70%  217M 0s\n",
            " 23300K .......... .......... .......... .......... .......... 70%  153M 0s\n",
            " 23350K .......... .......... .......... .......... .......... 70%  133M 0s\n",
            " 23400K .......... .......... .......... .......... .......... 70%  198M 0s\n",
            " 23450K .......... .......... .......... .......... .......... 70%  165M 0s\n",
            " 23500K .......... .......... .......... .......... .......... 71%  212M 0s\n",
            " 23550K .......... .......... .......... .......... .......... 71%  148M 0s\n",
            " 23600K .......... .......... .......... .......... .......... 71%  225M 0s\n",
            " 23650K .......... .......... .......... .......... .......... 71%  166M 0s\n",
            " 23700K .......... .......... .......... .......... .......... 71%  239M 0s\n",
            " 23750K .......... .......... .......... .......... .......... 71%  160M 0s\n",
            " 23800K .......... .......... .......... .......... .......... 72%  179M 0s\n",
            " 23850K .......... .......... .......... .......... .......... 72%  181M 0s\n",
            " 23900K .......... .......... .......... .......... .......... 72%  210M 0s\n",
            " 23950K .......... .......... .......... .......... .......... 72%  128M 0s\n",
            " 24000K .......... .......... .......... .......... .......... 72%  134M 0s\n",
            " 24050K .......... .......... .......... .......... .......... 72%  109M 0s\n",
            " 24100K .......... .......... .......... .......... .......... 72%  211M 0s\n",
            " 24150K .......... .......... .......... .......... .......... 73% 56.3M 0s\n",
            " 24200K .......... .......... .......... .......... .......... 73% 67.4M 0s\n",
            " 24250K .......... .......... .......... .......... .......... 73%  175M 0s\n",
            " 24300K .......... .......... .......... .......... .......... 73% 91.8M 0s\n",
            " 24350K .......... .......... .......... .......... .......... 73%  151M 0s\n",
            " 24400K .......... .......... .......... .......... .......... 73% 71.0M 0s\n",
            " 24450K .......... .......... .......... .......... .......... 73%  120M 0s\n",
            " 24500K .......... .......... .......... .......... .......... 74%  205M 0s\n",
            " 24550K .......... .......... .......... .......... .......... 74% 76.4M 0s\n",
            " 24600K .......... .......... .......... .......... .......... 74%  139M 0s\n",
            " 24650K .......... .......... .......... .......... .......... 74%  278M 0s\n",
            " 24700K .......... .......... .......... .......... .......... 74% 57.4M 0s\n",
            " 24750K .......... .......... .......... .......... .......... 74% 57.2M 0s\n",
            " 24800K .......... .......... .......... .......... .......... 75%  196M 0s\n",
            " 24850K .......... .......... .......... .......... .......... 75%  109M 0s\n",
            " 24900K .......... .......... .......... .......... .......... 75%  131M 0s\n",
            " 24950K .......... .......... .......... .......... .......... 75%  137M 0s\n",
            " 25000K .......... .......... .......... .......... .......... 75% 44.4M 0s\n",
            " 25050K .......... .......... .......... .......... .......... 75%  202M 0s\n",
            " 25100K .......... .......... .......... .......... .......... 75% 2.25M 0s\n",
            " 25150K .......... .......... .......... .......... .......... 76%  183M 0s\n",
            " 25200K .......... .......... .......... .......... .......... 76%  131M 0s\n",
            " 25250K .......... .......... .......... .......... .......... 76%  277M 0s\n",
            " 25300K .......... .......... .......... .......... .......... 76% 14.0M 0s\n",
            " 25350K .......... .......... .......... .......... .......... 76%  123M 0s\n",
            " 25400K .......... .......... .......... .......... .......... 76% 23.8M 0s\n",
            " 25450K .......... .......... .......... .......... .......... 77%  165M 0s\n",
            " 25500K .......... .......... .......... .......... .......... 77% 9.26M 0s\n",
            " 25550K .......... .......... .......... .......... .......... 77% 49.4M 0s\n",
            " 25600K .......... .......... .......... .......... .......... 77%  138M 0s\n",
            " 25650K .......... .......... .......... .......... .......... 77%  239M 0s\n",
            " 25700K .......... .......... .......... .......... .......... 77%  157M 0s\n",
            " 25750K .......... .......... .......... .......... .......... 77% 13.9M 0s\n",
            " 25800K .......... .......... .......... .......... .......... 78% 76.4M 0s\n",
            " 25850K .......... .......... .......... .......... .......... 78% 34.5M 0s\n",
            " 25900K .......... .......... .......... .......... .......... 78%  228M 0s\n",
            " 25950K .......... .......... .......... .......... .......... 78%  208M 0s\n",
            " 26000K .......... .......... .......... .......... .......... 78%  230M 0s\n",
            " 26050K .......... .......... .......... .......... .......... 78% 31.1M 0s\n",
            " 26100K .......... .......... .......... .......... .......... 78%  183M 0s\n",
            " 26150K .......... .......... .......... .......... .......... 79%  170M 0s\n",
            " 26200K .......... .......... .......... .......... .......... 79%  241M 0s\n",
            " 26250K .......... .......... .......... .......... .......... 79%  267M 0s\n",
            " 26300K .......... .......... .......... .......... .......... 79%  131M 0s\n",
            " 26350K .......... .......... .......... .......... .......... 79%  104M 0s\n",
            " 26400K .......... .......... .......... .......... .......... 79%  230M 0s\n",
            " 26450K .......... .......... .......... .......... .......... 80%  108M 0s\n",
            " 26500K .......... .......... .......... .......... .......... 80%  206M 0s\n",
            " 26550K .......... .......... .......... .......... .......... 80% 66.4M 0s\n",
            " 26600K .......... .......... .......... .......... .......... 80%  128M 0s\n",
            " 26650K .......... .......... .......... .......... .......... 80%  247M 0s\n",
            " 26700K .......... .......... .......... .......... .......... 80% 68.9M 0s\n",
            " 26750K .......... .......... .......... .......... .......... 80%  144M 0s\n",
            " 26800K .......... .......... .......... .......... .......... 81%  123M 0s\n",
            " 26850K .......... .......... .......... .......... .......... 81%  209M 0s\n",
            " 26900K .......... .......... .......... .......... .......... 81% 76.7M 0s\n",
            " 26950K .......... .......... .......... .......... .......... 81% 54.8M 0s\n",
            " 27000K .......... .......... .......... .......... .......... 81%  230M 0s\n",
            " 27050K .......... .......... .......... .......... .......... 81% 53.2M 0s\n",
            " 27100K .......... .......... .......... .......... .......... 81%  229M 0s\n",
            " 27150K .......... .......... .......... .......... .......... 82% 58.4M 0s\n",
            " 27200K .......... .......... .......... .......... .......... 82%  219M 0s\n",
            " 27250K .......... .......... .......... .......... .......... 82%  214M 0s\n",
            " 27300K .......... .......... .......... .......... .......... 82%  110M 0s\n",
            " 27350K .......... .......... .......... .......... .......... 82%  191M 0s\n",
            " 27400K .......... .......... .......... .......... .......... 82%  249M 0s\n",
            " 27450K .......... .......... .......... .......... .......... 83% 33.8M 0s\n",
            " 27500K .......... .......... .......... .......... .......... 83% 17.1M 0s\n",
            " 27550K .......... .......... .......... .......... .......... 83% 16.5M 0s\n",
            " 27600K .......... .......... .......... .......... .......... 83%  243M 0s\n",
            " 27650K .......... .......... .......... .......... .......... 83%  230M 0s\n",
            " 27700K .......... .......... .......... .......... .......... 83% 19.0M 0s\n",
            " 27750K .......... .......... .......... .......... .......... 83%  174M 0s\n",
            " 27800K .......... .......... .......... .......... .......... 84%  237M 0s\n",
            " 27850K .......... .......... .......... .......... .......... 84%  206M 0s\n",
            " 27900K .......... .......... .......... .......... .......... 84%  247M 0s\n",
            " 27950K .......... .......... .......... .......... .......... 84%  177M 0s\n",
            " 28000K .......... .......... .......... .......... .......... 84%  223M 0s\n",
            " 28050K .......... .......... .......... .......... .......... 84% 7.76M 0s\n",
            " 28100K .......... .......... .......... .......... .......... 85%  245M 0s\n",
            " 28150K .......... .......... .......... .......... .......... 85%  226M 0s\n",
            " 28200K .......... .......... .......... .......... .......... 85%  233M 0s\n",
            " 28250K .......... .......... .......... .......... .......... 85% 14.1M 0s\n",
            " 28300K .......... .......... .......... .......... .......... 85%  258M 0s\n",
            " 28350K .......... .......... .......... .......... .......... 85%  216M 0s\n",
            " 28400K .......... .......... .......... .......... .......... 85%  263M 0s\n",
            " 28450K .......... .......... .......... .......... .......... 86% 18.6M 0s\n",
            " 28500K .......... .......... .......... .......... .......... 86%  234M 0s\n",
            " 28550K .......... .......... .......... .......... .......... 86% 49.1M 0s\n",
            " 28600K .......... .......... .......... .......... .......... 86% 17.9M 0s\n",
            " 28650K .......... .......... .......... .......... .......... 86%  219M 0s\n",
            " 28700K .......... .......... .......... .......... .......... 86%  272M 0s\n",
            " 28750K .......... .......... .......... .......... .......... 86%  184M 0s\n",
            " 28800K .......... .......... .......... .......... .......... 87%  257M 0s\n",
            " 28850K .......... .......... .......... .......... .......... 87%  254M 0s\n",
            " 28900K .......... .......... .......... .......... .......... 87%  245M 0s\n",
            " 28950K .......... .......... .......... .......... .......... 87%  218M 0s\n",
            " 29000K .......... .......... .......... .......... .......... 87% 31.1M 0s\n",
            " 29050K .......... .......... .......... .......... .......... 87%  218M 0s\n",
            " 29100K .......... .......... .......... .......... .......... 88%  148M 0s\n",
            " 29150K .......... .......... .......... .......... .......... 88%  188M 0s\n",
            " 29200K .......... .......... .......... .......... .......... 88% 81.8M 0s\n",
            " 29250K .......... .......... .......... .......... .......... 88%  154M 0s\n",
            " 29300K .......... .......... .......... .......... .......... 88% 57.8M 0s\n",
            " 29350K .......... .......... .......... .......... .......... 88%  164M 0s\n",
            " 29400K .......... .......... .......... .......... .......... 88%  235M 0s\n",
            " 29450K .......... .......... .......... .......... .......... 89%  137M 0s\n",
            " 29500K .......... .......... .......... .......... .......... 89%  198M 0s\n",
            " 29550K .......... .......... .......... .......... .......... 89%  128M 0s\n",
            " 29600K .......... .......... .......... .......... .......... 89%  142M 0s\n",
            " 29650K .......... .......... .......... .......... .......... 89%  212M 0s\n",
            " 29700K .......... .......... .......... .......... .......... 89%  136M 0s\n",
            " 29750K .......... .......... .......... .......... .......... 90%  233M 0s\n",
            " 29800K .......... .......... .......... .......... .......... 90%  142M 0s\n",
            " 29850K .......... .......... .......... .......... .......... 90%  261M 0s\n",
            " 29900K .......... .......... .......... .......... .......... 90%  123M 0s\n",
            " 29950K .......... .......... .......... .......... .......... 90%  202M 0s\n",
            " 30000K .......... .......... .......... .......... .......... 90%  123M 0s\n",
            " 30050K .......... .......... .......... .......... .......... 90%  250M 0s\n",
            " 30100K .......... .......... .......... .......... .......... 91%  124M 0s\n",
            " 30150K .......... .......... .......... .......... .......... 91% 44.5M 0s\n",
            " 30200K .......... .......... .......... .......... .......... 91%  218M 0s\n",
            " 30250K .......... .......... .......... .......... .......... 91% 80.4M 0s\n",
            " 30300K .......... .......... .......... .......... .......... 91%  191M 0s\n",
            " 30350K .......... .......... .......... .......... .......... 91%  157M 0s\n",
            " 30400K .......... .......... .......... .......... .......... 91%  222M 0s\n",
            " 30450K .......... .......... .......... .......... .......... 92% 71.0M 0s\n",
            " 30500K .......... .......... .......... .......... .......... 92% 43.9M 0s\n",
            " 30550K .......... .......... .......... .......... .......... 92% 32.4M 0s\n",
            " 30600K .......... .......... .......... .......... .......... 92% 49.1M 0s\n",
            " 30650K .......... .......... .......... .......... .......... 92% 57.9M 0s\n",
            " 30700K .......... .......... .......... .......... .......... 92% 55.9M 0s\n",
            " 30750K .......... .......... .......... .......... .......... 93% 48.7M 0s\n",
            " 30800K .......... .......... .......... .......... .......... 93% 57.1M 0s\n",
            " 30850K .......... .......... .......... .......... .......... 93% 46.3M 0s\n",
            " 30900K .......... .......... .......... .......... .......... 93% 50.3M 0s\n",
            " 30950K .......... .......... .......... .......... .......... 93% 48.6M 0s\n",
            " 31000K .......... .......... .......... .......... .......... 93% 57.5M 0s\n",
            " 31050K .......... .......... .......... .......... .......... 93% 52.9M 0s\n",
            " 31100K .......... .......... .......... .......... .......... 94% 51.8M 0s\n",
            " 31150K .......... .......... .......... .......... .......... 94% 51.7M 0s\n",
            " 31200K .......... .......... .......... .......... .......... 94% 56.3M 0s\n",
            " 31250K .......... .......... .......... .......... .......... 94% 49.3M 0s\n",
            " 31300K .......... .......... .......... .......... .......... 94% 48.2M 0s\n",
            " 31350K .......... .......... .......... .......... .......... 94% 41.6M 0s\n",
            " 31400K .......... .......... .......... .......... .......... 94% 48.8M 0s\n",
            " 31450K .......... .......... .......... .......... .......... 95% 55.6M 0s\n",
            " 31500K .......... .......... .......... .......... .......... 95% 55.4M 0s\n",
            " 31550K .......... .......... .......... .......... .......... 95% 47.0M 0s\n",
            " 31600K .......... .......... .......... .......... .......... 95% 46.4M 0s\n",
            " 31650K .......... .......... .......... .......... .......... 95% 41.6M 0s\n",
            " 31700K .......... .......... .......... .......... .......... 95% 36.5M 0s\n",
            " 31750K .......... .......... .......... .......... .......... 96% 36.9M 0s\n",
            " 31800K .......... .......... .......... .......... .......... 96% 47.8M 0s\n",
            " 31850K .......... .......... .......... .......... .......... 96% 69.8M 0s\n",
            " 31900K .......... .......... .......... .......... .......... 96%  153M 0s\n",
            " 31950K .......... .......... .......... .......... .......... 96%  110M 0s\n",
            " 32000K .......... .......... .......... .......... .......... 96% 94.3M 0s\n",
            " 32050K .......... .......... .......... .......... .......... 96%  200M 0s\n",
            " 32100K .......... .......... .......... .......... .......... 97%  204M 0s\n",
            " 32150K .......... .......... .......... .......... .......... 97%  139M 0s\n",
            " 32200K .......... .......... .......... .......... .......... 97% 54.1M 0s\n",
            " 32250K .......... .......... .......... .......... .......... 97% 57.5M 0s\n",
            " 32300K .......... .......... .......... .......... .......... 97% 50.4M 0s\n",
            " 32350K .......... .......... .......... .......... .......... 97% 47.9M 0s\n",
            " 32400K .......... .......... .......... .......... .......... 98% 66.9M 0s\n",
            " 32450K .......... .......... .......... .......... .......... 98% 64.4M 0s\n",
            " 32500K .......... .......... .......... .......... .......... 98%  243M 0s\n",
            " 32550K .......... .......... .......... .......... .......... 98% 45.4M 0s\n",
            " 32600K .......... .......... .......... .......... .......... 98% 99.2M 0s\n",
            " 32650K .......... .......... .......... .......... .......... 98%  225M 0s\n",
            " 32700K .......... .......... .......... .......... .......... 98% 55.1M 0s\n",
            " 32750K .......... .......... .......... .......... .......... 99% 57.5M 0s\n",
            " 32800K .......... .......... .......... .......... .......... 99%  274M 0s\n",
            " 32850K .......... .......... .......... .......... .......... 99% 69.9M 0s\n",
            " 32900K .......... .......... .......... .......... .......... 99% 60.0M 0s\n",
            " 32950K .......... .......... .......... .......... .......... 99% 82.0M 0s\n",
            " 33000K .......... .......... .......... .......... .......... 99%  125M 0s\n",
            " 33050K .......... .......... .......... .......... .......... 99%  287M 0s\n",
            " 33100K ..........                                            100%  192M=0.5s\n",
            "\n",
            "2024-04-01 09:08:33 (59.0 MB/s) - â€˜Miniconda3-4.2.12-Linux-x86_64.shâ€™ saved [33905474/33905474]\n",
            "\n",
            "Python 3.5.2 :: Continuum Analytics, Inc.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.2.12-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I added miniconda as the interpreter of the notebook to get a custom version of python and to enable download on tensorflow 1, bash script works on colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJE5JxD9JGls",
        "outputId": "c6eaa586-bc0f-472c-9a52-17dbf1954610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.5.2 :: Continuum Analytics, Inc.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "_ = (sys.path.append(\"/usr/local/lib/python3.5/site-packages\"))\n",
        "\n",
        "!python --version # Check python version if correclty installed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Python 3.5.2 was installed but pip was not added"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEzTP6gxJ1Wj",
        "outputId": "2ac3ca0c-183b-4ecd-8259-5d79ea2be1cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pip<21.0\n",
            "  Downloading pip-20.3.4-py2.py3-none-any.whl (1.5 MB)\n",
            "\u001b[?25l\r\u001b[K     |â–                               | 10 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |â–                               | 20 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |â–‹                               | 30 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |â–‰                               | 40 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆ                               | 51 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–Ž                              | 61 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–Œ                              | 71 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–Š                              | 81 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆ                              | 92 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–                             | 102 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–                             | 112 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–‹                             | 122 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–‰                             | 133 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆ                             | 143 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–Ž                            | 153 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–Œ                            | 163 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–‹                            | 174 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–‰                            | 184 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆ                            | 194 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 204 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 215 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 225 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 235 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 245 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 256 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 266 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 276 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 286 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 296 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 307 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 317 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 327 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 337 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 348 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 358 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 368 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 378 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 389 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 399 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 409 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 419 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 430 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 440 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 450 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 460 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 471 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 481 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 491 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 501 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 512 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 522 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 532 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 542 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 552 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 563 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 573 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 583 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 593 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 604 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 614 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 624 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 634 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 645 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                  | 655 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 665 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 675 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 686 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                 | 696 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 706 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 716 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 727 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 737 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                | 747 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 757 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 768 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 778 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 788 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰               | 798 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 808 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 819 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 829 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹              | 839 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰              | 849 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 860 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž             | 870 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 880 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 890 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 901 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 911 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 921 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 931 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 942 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 952 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž           | 962 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 972 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 983 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 993 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰      | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.5 MB 8.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 8.1.2\n",
            "    Uninstalling pip-8.1.2:\n",
            "      Successfully uninstalled pip-8.1.2\n",
            "Successfully installed pip-20.3.4\n"
          ]
        }
      ],
      "source": [
        "!curl -fsSL https://bootstrap.pypa.io/pip/3.5/get-pip.py | python3.5 # Installs pip to python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "pip is installed successfully"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R0zUfyWyJ4HK",
        "outputId": "13a40873-f0e2-472f-e79b-b7b7c665d2a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "  Downloading tensorflow-1.15.0-cp35-cp35m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 412.3 MB 27 kB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting grpcio>=1.8.6\n",
            "  Downloading grpcio-1.41.1.tar.gz (21.2 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.2 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting google-pasta>=0.1.6\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting termcolor>=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.5/site-packages (from tensorflow==1.15.0) (0.29.0)\n",
            "Collecting absl-py>=0.7.0\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132 kB 40.9 MB/s \n",
            "\u001b[?25hCollecting six>=1.10.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting astor>=0.6.0\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting protobuf>=3.6.1\n",
            "  Downloading protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 162 kB 61.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 503 kB 59.4 MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8 MB 51.0 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting numpy<2.0,>=1.16.0\n",
            "  Downloading numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.9 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting keras-preprocessing>=1.0.5\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting wrapt>=1.11.1\n",
            "  Downloading wrapt-1.15.0-cp35-cp35m-manylinux2010_x86_64.whl (79 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79 kB 9.6 MB/s \n",
            "\u001b[?25hIgnoring futures: markers 'python_version < \"3.2\"' don't match your environment\n",
            "Ignoring enum34: markers 'python_version < \"3.4\"' don't match your environment\n",
            "Collecting h5py\n",
            "  Downloading h5py-2.10.0-cp35-cp35m-manylinux1_x86_64.whl (2.8 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.8 MB 51.9 MB/s \n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88 kB 9.1 MB/s \n",
            "\u001b[?25hCollecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298 kB 60.3 MB/s \n",
            "\u001b[?25hCollecting setuptools>=41.0.0\n",
            "  Downloading setuptools-50.3.2-py3-none-any.whl (785 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785 kB 50.8 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata\n",
            "  Downloading importlib_metadata-2.1.3-py2.py3-none-any.whl (10 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-1.2.0-py2.py3-none-any.whl (4.8 kB)\n",
            "Building wheels for collected packages: grpcio, termcolor, gast\n",
            "  Building wheel for grpcio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grpcio: filename=grpcio-1.41.1-cp35-cp35m-linux_x86_64.whl size=49583052 sha256=1961e1ba3161f43ee76e328b2204a3962c148bbdd5b5e512929b93772a7131a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/79/8e/2aa88c6daffd594ac957c188bb161d034e49ac39e535ea8be4\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=5680 sha256=11db80f769233723a37ef6f4988fdc9f86532da57dc718f04ec74f51bf3e133c\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/0e/11/1f1321dce76e9c542907008e4a94ff79f8bf525a3fa32b09f3\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7636 sha256=69aaf7b970108d588d81bfab3f062db580e763dd22244dd1d0fa9c6b3f1636ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/b2/f9/b3052fd0a0c1e61f4eb5b879161a8b6670fb1c26951a5ad5d6\n",
            "Successfully built grpcio termcolor gast\n",
            "Installing collected packages: zipp, six, numpy, importlib-metadata, werkzeug, setuptools, protobuf, markdown, h5py, grpcio, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras-applications, google-pasta, gast, astor, tensorflow\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 27.2.0\n",
            "    Uninstalling setuptools-27.2.0:\n",
            "\u001b[33m      WARNING: Cannot remove entries from nonexistent file /usr/local/lib/python3.5/site-packages/easy-install.pth\u001b[0m\n",
            "      Successfully uninstalled setuptools-27.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio 1.41.1 requires enum34>=1.0.4, which is not installed.\n",
            "grpcio 1.41.1 requires futures>=2.2.0, which is not installed.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 astor-0.8.1 gast-0.2.2 google-pasta-0.2.0 grpcio-1.41.1 h5py-2.10.0 importlib-metadata-2.1.3 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.2.2 numpy-1.18.5 opt-einsum-3.3.0 protobuf-3.19.6 setuptools-50.3.2 six-1.16.0 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1 termcolor-1.1.0 werkzeug-1.0.1 wrapt-1.15.0 zipp-1.2.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "6824994b812f4a23b5324cec034010ab",
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install tensorflow==1.15.0 # Working version of tensorflow that gives less errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRIj10jNhqH1",
        "outputId": "89c8f6df-c4d8-4af8-cd20-fe579ccdf613"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras==2.2.4\n",
            "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 312 kB 7.8 MB/s \n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269 kB 45.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.5/site-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/site-packages (from keras==2.2.4) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/site-packages (from keras==2.2.4) (1.18.5)\n",
            "Collecting scipy>=0.14\n",
            "  Downloading scipy-1.4.1-cp35-cp35m-manylinux1_x86_64.whl (26.0 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26.0 MB 36.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.5/site-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.5/site-packages (from keras==2.2.4) (1.0.8)\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp35-cp35m-linux_x86_64.whl size=505956 sha256=847eca0cc264ea79b59a3b92cca2e3d1cf9033671ffa1d65c9ff9c753fd10c30\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/d0/2c/e2003abb5bc1a94c2e8a6fe1c03b8055d074e34c13672e7eb7\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: scipy, pyyaml, keras\n",
            "Successfully installed keras-2.2.4 pyyaml-5.3.1 scipy-1.4.1\n"
          ]
        }
      ],
      "source": [
        "# Our YOLOv3 implementation calls for this Keras version\n",
        "!pip install keras==2.2.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r788kvmKuD5O"
      },
      "outputs": [],
      "source": [
        "# use TF 1.x\n",
        "#%tensorflow_version 1.x "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Will result into `\"ValueError: Tensorflow 1 is unsupported in Colab\"`, tensorflow 1 is no longer supported on colab if magic word was used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMI-zNrrhmuG",
        "outputId": "23858c75-f4ac-4f45-b757-79926ea46859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "2.2.4\n"
          ]
        }
      ],
      "source": [
        "# Verify our version is correct\n",
        "!python -c 'import keras; print(keras.__version__)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lweWDcTyVeLs",
        "outputId": "1070af39-192b-405f-9745-76e10aaf5661"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-yolo3'...\n",
            "remote: Enumerating objects: 169, done.\u001b[K\n",
            "remote: Total 169 (delta 0), reused 0 (delta 0), pack-reused 169\u001b[K\n",
            "Receiving objects: 100% (169/169), 172.74 KiB | 1016.00 KiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n"
          ]
        }
      ],
      "source": [
        "# Next, we'll grab all the code from our repository of interest\n",
        "!git clone https://github.com/roboflow-ai/keras-yolo3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyPfLjFBbOAw",
        "outputId": "a40509f9-8115-453a-e24c-219473726e26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mkeras-yolo3\u001b[0m/  \u001b[01;32mMiniconda3-4.2.12-Linux-x86_64.sh\u001b[0m*  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "# here's what we cloned (also, see \"Files\" in the left-hand Colab pane)\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adwdKfxBVlom",
        "outputId": "d6437389-9831-4eaa-85f2-c546f0003685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/keras-yolo3\n"
          ]
        }
      ],
      "source": [
        "# change directory to the repo we cloned\n",
        "%cd keras-yolo3/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6DNWhOEbGB6",
        "outputId": "0a3cbd2a-02f9-4dcc-973e-a5654b17ac7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "coco_annotation.py  \u001b[0m\u001b[01;34mfont\u001b[0m/      \u001b[01;34mmodel_data\u001b[0m/          train.py           \u001b[01;34myolo3\u001b[0m/      yolov3-tiny.cfg\n",
            "convert.py          kmeans.py  README.md            Tutorial.ipynb     yolo.py     yolo_video.py\n",
            "darknet53.cfg       LICENSE    train_bottleneck.py  voc_annotation.py  yolov3.cfg\n"
          ]
        }
      ],
      "source": [
        "# show the contents of our repo\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I--RqDmpwqmv"
      },
      "source": [
        "## Get our training data from Roboflow\n",
        "\n",
        "Next, we need to add our data from Roboflow into our environment.\n",
        "\n",
        "Our dataset, with annotations, is [here](https://public.roboflow.ai/object-detection/chess-full).\n",
        "\n",
        "Here's how to bring those images from Roboflow to Colab:\n",
        "\n",
        "1. Visit this [link](https://public.roboflow.ai/object-detection/chess-full).\n",
        "2. Click the \"416x416auto-orient\" under Downloads.\n",
        "3. On the dataset detail page, select \"Download\" in the upper right-hand corner.\n",
        "4. If you are not signed in, you will be prompted to create a free account (sign in with GitHub or email), and redirected to the dataset page to Download.\n",
        "5. On the download popup, select the YOLOv3 Keras option **and** the \"Show download `code`\".\n",
        "6. Copy the code snippet Roboflow generates for you, and paste it in the next cell.\n",
        "\n",
        "This is the download menu you want (from step 5):\n",
        "#### ![Download Menu](https://i.imgur.com/KW2PyQO.png)\n",
        "\n",
        "The top code snippet is the one you want to copy (from step 6) and paste in the next notebook cell:\n",
        "### ![Code Snippet](https://i.imgur.com/qzJckWR.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AmSSTFFWud7"
      },
      "source": [
        "**This cell below is only one you need to change to have YOLOv3 train on your own Roboflow dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nclkjonbT25",
        "outputId": "ad9001a0-d68a-46af-9f22-0ef10da582ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   907  100   907    0     0   2588      0 --:--:-- --:--:-- --:--:--  2591\n",
            "100 16.2M  100 16.2M    0     0  17.9M      0 --:--:-- --:--:-- --:--:--  103M\n",
            "Archive:  roboflow.zip\n",
            " extracting: README.dataset.txt      \n",
            " extracting: README.roboflow.txt     \n",
            "   creating: test/\n",
            " extracting: test/0b47311f426ff926578c9d738d683e76_jpg.rf.40183eae584a653181bbd795ba3c353f.jpg  \n",
            " extracting: test/1c0060ef868bdc326ce5e6389cb6732f_jpg.rf.f02cd668d26a53d9bf001497992b3657.jpg  \n",
            " extracting: test/2f6fb003bb89cd401322a535acb42f65_jpg.rf.66c0a46773a9cd583fb96c3df41a9e0c.jpg  \n",
            " extracting: test/410993714e325a1de3e394ffe860df3a_jpg.rf.657c49ca295ef54da23469189070a075.jpg  \n",
            " extracting: test/4e3117459d759798537eb52cf5bf534d_jpg.rf.ec961b62d4b0e131fae760ed1f80836b.jpg  \n",
            " extracting: test/5a35ba2ec3e0d0b2b12b1758a8ac29aa_jpg.rf.9dbdb057f6533c0c09c0eda0747fbc9e.jpg  \n",
            " extracting: test/654bb8835258b26c466b1c19893df451_jpg.rf.55fb7f23a4422a80793f01e152fabe4d.jpg  \n",
            " extracting: test/685b860d412b91f5d4f7f9e643b84452_jpg.rf.2d78193e4021ae5ffb49ecd1060bebd7.jpg  \n",
            " extracting: test/73a38a5c8f8f1b09f093f304660d5326_jpg.rf.65192fc4204952bfd1121ee212aade1e.jpg  \n",
            " extracting: test/749e9074a77f8d34d86e2218f26cdab4_jpg.rf.b39c00c032a7ecbb62b8792bbe05497e.jpg  \n",
            " extracting: test/7a34d8620235048917b28bcfd3b5572b_jpg.rf.450c577e3be66b5232c54ffc9ec9e6b7.jpg  \n",
            " extracting: test/8ff752f9ed443e6e49d495abfceb2032_jpg.rf.530a6c314a4848ead2b0ebc40e6ba651.jpg  \n",
            " extracting: test/IMG_0159_JPG.rf.f0d34122f8817d538e396b04f2b70d33.jpg  \n",
            " extracting: test/IMG_0169_JPG.rf.1de291413bb78ef8ff0eaa8ffac38b06.jpg  \n",
            " extracting: test/IMG_0170_JPG.rf.480e7164cb4727f6654402882f0ce942.jpg  \n",
            " extracting: test/_annotations.txt   \n",
            " extracting: test/_classes.txt       \n",
            " extracting: test/a3863d0be6002c21b20ac88817b2c56f_jpg.rf.0413d5178136ace55f588df9556c060a.jpg  \n",
            " extracting: test/b4ff4132c8c85da97d8bf9a2a4ed3e3d_jpg.rf.ec790769b4818025b7652ca6aab9307e.jpg  \n",
            " extracting: test/b526b661a33ff481231d1342aff2a266_jpg.rf.287d21a885ec3abeb6da818a6a9cd05b.jpg  \n",
            " extracting: test/b9402881fa580d0eb8b9b98845417550_jpg.rf.7c401587706c0c03dab27877a8d22f55.jpg  \n",
            " extracting: test/c4943d83c06a12ad5e0399d19514a4ca_jpg.rf.99b2d7e1faa204e71fdc71676040c4d6.jpg  \n",
            " extracting: test/c5a012dfa72816098d23fc8baee67834_jpg.rf.6e0feae2ac0229ff5f20fc842852c81d.jpg  \n",
            " extracting: test/cf4769d0586df6b3fb0dc618d9f8abe6_jpg.rf.81d8a4fa4e06ba4399292de7f5b5e300.jpg  \n",
            " extracting: test/cfc306bf86176b92ffc1afbb98d7896f_jpg.rf.effd71a5dcd98ec0f24072af5f7c0a31.jpg  \n",
            " extracting: test/d7887071e972604ddf5940d8eb2702e7_jpg.rf.5f20fe9a6c746d488d6d0478828478cb.jpg  \n",
            " extracting: test/e0d38d159ad3a801d0304d7e275812cc_jpg.rf.16aa43d37a5a2d2c32402cfa877d0a0d.jpg  \n",
            " extracting: test/e4147f3d8819fc5d67a9f72596bd9e47_jpg.rf.ecc7863357d316634c6f22a2f0758303.jpg  \n",
            " extracting: test/e4583d082076b2b549b3736ad1b193c9_jpg.rf.c64d9d89f8d479bf811e6b355b93e90e.jpg  \n",
            " extracting: test/f1a24b6bb778ee11ba33687415aa84f2_jpg.rf.f2646d2d46b39f6510975f24d554bae1.jpg  \n",
            " extracting: test/fdcd6ada676799da8a870f58fdf548db_jpg.rf.b0ea8552b6106bb4ab62ca8957fca40d.jpg  \n",
            "   creating: train/\n",
            " extracting: train/00bc0cacffdebe6b11bdeec56f63ee49_jpg.rf.1a1407058a6170f001f2c269411d31d3.jpg  \n",
            " extracting: train/00bc0cacffdebe6b11bdeec56f63ee49_jpg.rf.20e061b75dc554ebe40b33189e320831.jpg  \n",
            " extracting: train/00bc0cacffdebe6b11bdeec56f63ee49_jpg.rf.38c0bb7971151bf4cb185f5498fddcc0.jpg  \n",
            " extracting: train/0115e4df73475b550e5c6f7a88b2474f_jpg.rf.22f030d1bd7a26c987f287d2de4b19c7.jpg  \n",
            " extracting: train/0115e4df73475b550e5c6f7a88b2474f_jpg.rf.254cb905329fee7e2df63d14b15368db.jpg  \n",
            " extracting: train/0115e4df73475b550e5c6f7a88b2474f_jpg.rf.9d4f5de6e48861cf9108e46aee8dbb8f.jpg  \n",
            " extracting: train/02f0931b536dfba10affc3231a3d64fb_jpg.rf.087fbe5ea178dd757f4eb065ae5cf941.jpg  \n",
            " extracting: train/02f0931b536dfba10affc3231a3d64fb_jpg.rf.51d15aa9df1efc29ceca818ecbce37e1.jpg  \n",
            " extracting: train/02f0931b536dfba10affc3231a3d64fb_jpg.rf.d1c527f45625192911705f97416af54b.jpg  \n",
            " extracting: train/0301b7f9ed4d5ba503fda79fc4370c29_jpg.rf.56da1174519560712119d3fc195068cb.jpg  \n",
            " extracting: train/0301b7f9ed4d5ba503fda79fc4370c29_jpg.rf.7871491670bed0423e3beceb3fae8016.jpg  \n",
            " extracting: train/0301b7f9ed4d5ba503fda79fc4370c29_jpg.rf.91a1164b0c74bbe8ab32435e44b990a4.jpg  \n",
            " extracting: train/03886821377011fec599e8fa12d86e89_jpg.rf.44fb00bcea92435e28c1ea1a89595b32.jpg  \n",
            " extracting: train/03886821377011fec599e8fa12d86e89_jpg.rf.7ec3f29be4f3793b35a2c4a9880d831c.jpg  \n",
            " extracting: train/03886821377011fec599e8fa12d86e89_jpg.rf.98865e45954a6f1a7c8cdd2c0be465e2.jpg  \n",
            " extracting: train/03d3ff4582c8125d69c19a72f846bec8_jpg.rf.0abd6e8d01091ac5396f7a9cf390bdc9.jpg  \n",
            " extracting: train/03d3ff4582c8125d69c19a72f846bec8_jpg.rf.7a003146bd5c6847a71accae7e87bf3b.jpg  \n",
            " extracting: train/03d3ff4582c8125d69c19a72f846bec8_jpg.rf.8cfdbdc73a4c6149758151715b2e8b44.jpg  \n",
            " extracting: train/040f2bcba5afce3afafdd5bbf36d2ca5_jpg.rf.41718e1241c9b432c1aef73937e12feb.jpg  \n",
            " extracting: train/040f2bcba5afce3afafdd5bbf36d2ca5_jpg.rf.4b3a8c8430ecaaf5d31ff3b6ff994876.jpg  \n",
            " extracting: train/040f2bcba5afce3afafdd5bbf36d2ca5_jpg.rf.76f9bf46e314e3671d2b9a9fe1eff19f.jpg  \n",
            " extracting: train/04aed88a8d23cf27e47806eb23948495_jpg.rf.0afccd002b73949b13d75032bca2828b.jpg  \n",
            " extracting: train/04aed88a8d23cf27e47806eb23948495_jpg.rf.5b2ede62cd0912672150d67bc6ed8ead.jpg  \n",
            " extracting: train/04aed88a8d23cf27e47806eb23948495_jpg.rf.b2b9c08d458461669627c4976b744f46.jpg  \n",
            " extracting: train/055b79dd8db4c43e1a23be6095aaf624_jpg.rf.0cecb46a274c53aaaf172c0fbe0e6eaa.jpg  \n",
            " extracting: train/055b79dd8db4c43e1a23be6095aaf624_jpg.rf.cd15336671f029c9f3319e08f54705e5.jpg  \n",
            " extracting: train/055b79dd8db4c43e1a23be6095aaf624_jpg.rf.cf511a337b73cbbe392f4830229e03be.jpg  \n",
            " extracting: train/05de676d5078dc0a13796f3f627993ef_jpg.rf.1ae70c9f54b2825eb3a4d0c4e43d7213.jpg  \n",
            " extracting: train/05de676d5078dc0a13796f3f627993ef_jpg.rf.c37fdbdb3b34643c655814729cc944eb.jpg  \n",
            " extracting: train/05de676d5078dc0a13796f3f627993ef_jpg.rf.cc83e123e6905474c14e40a7a06b3fbb.jpg  \n",
            " extracting: train/06770ce99d4866165c0dfb104179c361_jpg.rf.30f74da3f9fb816762fe128339f2b880.jpg  \n",
            " extracting: train/06770ce99d4866165c0dfb104179c361_jpg.rf.4e1731dc330bcc7c45afae38ba2a6b66.jpg  \n",
            " extracting: train/06770ce99d4866165c0dfb104179c361_jpg.rf.6e91bc2ccd7b43b371771f4aa6565d58.jpg  \n",
            " extracting: train/0798bfb058da59d189c1bfadcf814f29_jpg.rf.1e4fca7542b10b91f6436d8b1b3cb08f.jpg  \n",
            " extracting: train/0798bfb058da59d189c1bfadcf814f29_jpg.rf.d15086fbba4dea88618e8da79d0e52fc.jpg  \n",
            " extracting: train/0798bfb058da59d189c1bfadcf814f29_jpg.rf.f416b21fe1523c919632ecb16aace2e2.jpg  \n",
            " extracting: train/0b4ba28f0c759a11750a6430649b52e3_jpg.rf.360b52c8b8fb20ebbe87ca4a63d454a4.jpg  \n",
            " extracting: train/0b4ba28f0c759a11750a6430649b52e3_jpg.rf.79ce979766c7725eac584a892f2af5b1.jpg  \n",
            " extracting: train/0b4ba28f0c759a11750a6430649b52e3_jpg.rf.a385c2a65e0d9faff02ab153556cd00b.jpg  \n",
            " extracting: train/0cf670506bf9e0fe587647cd62caa232_jpg.rf.45dd2d1228e8eeb0d736bc53b3246b7c.jpg  \n",
            " extracting: train/0cf670506bf9e0fe587647cd62caa232_jpg.rf.87a892b7346e822c1255df1993d0cb80.jpg  \n",
            " extracting: train/0cf670506bf9e0fe587647cd62caa232_jpg.rf.e44dd3107c47246d4ec175ac16e91830.jpg  \n",
            " extracting: train/0d9dbf62d5ee42b92bf55197bba4254d_jpg.rf.214eb5f360891da5197e1900013439ec.jpg  \n",
            " extracting: train/0d9dbf62d5ee42b92bf55197bba4254d_jpg.rf.820147842f33369719d3eeca69bb6769.jpg  \n",
            " extracting: train/0d9dbf62d5ee42b92bf55197bba4254d_jpg.rf.b159d61997f9dc9fdf926f76aa9c273f.jpg  \n",
            " extracting: train/104ec0199cb67e1a359b1b0845ee66f3_jpg.rf.04dc1a59935ead8705530bd4583a1222.jpg  \n",
            " extracting: train/104ec0199cb67e1a359b1b0845ee66f3_jpg.rf.13fe6ec9290d49ca950115c142c76d57.jpg  \n",
            " extracting: train/104ec0199cb67e1a359b1b0845ee66f3_jpg.rf.c8750ec52c3ade1aca9de15694cf9eb5.jpg  \n",
            " extracting: train/13106bbc80a01cc413c2ab5052d2ec25_jpg.rf.137d13b354dafa0c28ae4d8136031f6b.jpg  \n",
            " extracting: train/13106bbc80a01cc413c2ab5052d2ec25_jpg.rf.19c72bddcf32faef8dbe854f65ec3e6f.jpg  \n",
            " extracting: train/13106bbc80a01cc413c2ab5052d2ec25_jpg.rf.b232d48e25d062c5d25a5be4e1f81021.jpg  \n",
            " extracting: train/1595777dfa66e954ae23655743e24809_jpg.rf.5dc97daf85a90e102fd9454665288eb5.jpg  \n",
            " extracting: train/1595777dfa66e954ae23655743e24809_jpg.rf.86c2d8bf856a3470877532a75c12a144.jpg  \n",
            " extracting: train/1595777dfa66e954ae23655743e24809_jpg.rf.b60c3a36f35dd1eba3d57d815d930d67.jpg  \n",
            " extracting: train/1728cd731489df8bb8e0396e178fe393_jpg.rf.72e14139be3f1f663f1512324adbe0cd.jpg  \n",
            " extracting: train/1728cd731489df8bb8e0396e178fe393_jpg.rf.7ef76473b0a2962c632997f2fd7570eb.jpg  \n",
            " extracting: train/1728cd731489df8bb8e0396e178fe393_jpg.rf.cf3127987c30548d691295953a2326db.jpg  \n",
            " extracting: train/1877a28e4c5f5c1ea68aca66f4e85d95_jpg.rf.8214b540ec0fb6594f0a37059176df33.jpg  \n",
            " extracting: train/1877a28e4c5f5c1ea68aca66f4e85d95_jpg.rf.9e17aead7bdfecd30e23fcbd0cdf9305.jpg  \n",
            " extracting: train/1877a28e4c5f5c1ea68aca66f4e85d95_jpg.rf.c65abe6a33f5679f8c1e84d9029a77e4.jpg  \n",
            " extracting: train/196829feb704a34a4e471155f14bdd80_jpg.rf.344f88ded341e5b5351c31ddc7e07fdb.jpg  \n",
            " extracting: train/196829feb704a34a4e471155f14bdd80_jpg.rf.6c682963e8e934a976fb4a4373bf05b4.jpg  \n",
            " extracting: train/196829feb704a34a4e471155f14bdd80_jpg.rf.7f5d3545dcb27e896e6f68208ca86dcd.jpg  \n",
            " extracting: train/1a530d578f3f0bf3497bfeff3d953025_jpg.rf.a03681d6dbbeb2e50eac9e1feabbd309.jpg  \n",
            " extracting: train/1a530d578f3f0bf3497bfeff3d953025_jpg.rf.a920532b8b005cc545bc368ad3c8f2ef.jpg  \n",
            " extracting: train/1a530d578f3f0bf3497bfeff3d953025_jpg.rf.b8a3b1a645357b4ab6dc8daa540ba89d.jpg  \n",
            " extracting: train/1a8a4abcba7c4ead35c01f05b9fae8e5_jpg.rf.442f136a399a1f9fe7ebdbfb4ba111a1.jpg  \n",
            " extracting: train/1a8a4abcba7c4ead35c01f05b9fae8e5_jpg.rf.d4317263bf28a3b3e8a9e0f6618e9745.jpg  \n",
            " extracting: train/1a8a4abcba7c4ead35c01f05b9fae8e5_jpg.rf.e7ce7cfefb2970bf066ee8409dafc31f.jpg  \n",
            " extracting: train/1b4ccdf7d5ff45dc6c3885243bde5af2_jpg.rf.26b8553d31c5667b5ac5c7249bf80642.jpg  \n",
            " extracting: train/1b4ccdf7d5ff45dc6c3885243bde5af2_jpg.rf.31d77a84d3d6370bc2aed5ffd3e6f2e8.jpg  \n",
            " extracting: train/1b4ccdf7d5ff45dc6c3885243bde5af2_jpg.rf.92bd5a7bb83cb5d8639db85d02fe7511.jpg  \n",
            " extracting: train/22e74efb18b2d88fba63d25a61bf5f97_jpg.rf.385b3e9a3203fff03fb378e343ccff7b.jpg  \n",
            " extracting: train/22e74efb18b2d88fba63d25a61bf5f97_jpg.rf.a3d860399c54e7d955b2235f44679f53.jpg  \n",
            " extracting: train/22e74efb18b2d88fba63d25a61bf5f97_jpg.rf.e472c82b49f6f6da28b302bda8ecc4d4.jpg  \n",
            " extracting: train/23988893ef7381fece6d1ef32ef5428f_jpg.rf.bde765e553747a196d113f9fec702805.jpg  \n",
            " extracting: train/23988893ef7381fece6d1ef32ef5428f_jpg.rf.c17c56f4463bd4def9641c0218c16471.jpg  \n",
            " extracting: train/23988893ef7381fece6d1ef32ef5428f_jpg.rf.dd1332a601e86a4f219edb4145bdf239.jpg  \n",
            " extracting: train/239c409d5c09b493fed01a70a3cda4bc_jpg.rf.01a3333223abb899709f52303c100d19.jpg  \n",
            " extracting: train/239c409d5c09b493fed01a70a3cda4bc_jpg.rf.0da84dd41081b1d68b3eed86259f4927.jpg  \n",
            " extracting: train/239c409d5c09b493fed01a70a3cda4bc_jpg.rf.8f3596ebdf348f77b1bde7b51557bf0f.jpg  \n",
            " extracting: train/247f9cf35a263dc7dd7886b187fd5480_jpg.rf.21d5039624e6deb14401c708a2ebcdcb.jpg  \n",
            " extracting: train/247f9cf35a263dc7dd7886b187fd5480_jpg.rf.d77746d6c6ff2592f94f08d808a5947d.jpg  \n",
            " extracting: train/247f9cf35a263dc7dd7886b187fd5480_jpg.rf.f0572fa5484481b70ca83d63a3d7e184.jpg  \n",
            " extracting: train/254f92b18b2a81f88b85e7aed3cabc61_jpg.rf.040f2bb097a768c0c16d459430205a70.jpg  \n",
            " extracting: train/254f92b18b2a81f88b85e7aed3cabc61_jpg.rf.4c7568df4f838db750f7d7b54122210b.jpg  \n",
            " extracting: train/254f92b18b2a81f88b85e7aed3cabc61_jpg.rf.a55e3d26992b9f4d43e7f317a078689b.jpg  \n",
            " extracting: train/26d663ab5ffbec49f9dc8e592982cfd4_jpg.rf.0fe973299ff9e73874d9e684cba4e406.jpg  \n",
            " extracting: train/26d663ab5ffbec49f9dc8e592982cfd4_jpg.rf.5e1a9d49ad09f5a7549225a05e1f66a6.jpg  \n",
            " extracting: train/26d663ab5ffbec49f9dc8e592982cfd4_jpg.rf.bb226be189ee3a6399fbbd5080852e5b.jpg  \n",
            " extracting: train/285d7c487a4e20ad832a74acb527b77f_jpg.rf.3dc659a479a4644b5a633a089379b94c.jpg  \n",
            " extracting: train/285d7c487a4e20ad832a74acb527b77f_jpg.rf.5898c8f286182a8e159cb26d009defc3.jpg  \n",
            " extracting: train/285d7c487a4e20ad832a74acb527b77f_jpg.rf.df00faf5828d265a002f42c16f6aab0a.jpg  \n",
            " extracting: train/292b0ddcacad7de06a628980954b6993_jpg.rf.67f9ea5e7adf1465fa4334d3cad42707.jpg  \n",
            " extracting: train/292b0ddcacad7de06a628980954b6993_jpg.rf.f38c3bb31f5e00206f9dd1882d9aa1b1.jpg  \n",
            " extracting: train/292b0ddcacad7de06a628980954b6993_jpg.rf.ffb6b085a9d60c9f2c2e7524963000a4.jpg  \n",
            " extracting: train/2c32afd520cc8bf076dfa5b6e2e1c4c1_jpg.rf.85581a8cd489d624f76364df69817031.jpg  \n",
            " extracting: train/2c32afd520cc8bf076dfa5b6e2e1c4c1_jpg.rf.87c42395d755e8a3dd8c496a501efa69.jpg  \n",
            " extracting: train/2c32afd520cc8bf076dfa5b6e2e1c4c1_jpg.rf.df50bc6bf291f7313cae27c09bb9c8a0.jpg  \n",
            " extracting: train/2ee0fd0963465ba29d8f27c6e605c55d_jpg.rf.744c9a5ed432b0fccbd744ba3fe4b247.jpg  \n",
            " extracting: train/2ee0fd0963465ba29d8f27c6e605c55d_jpg.rf.ab3d6a72f56e3d0a0fb341073880b760.jpg  \n",
            " extracting: train/2ee0fd0963465ba29d8f27c6e605c55d_jpg.rf.b725ad9181e61d96753ab8a50c4b0aa9.jpg  \n",
            " extracting: train/2fe75c34fd54e960146fb8b0ad8b3fd6_jpg.rf.46b8727756f5cbdf9d26a07bf9ee78d7.jpg  \n",
            " extracting: train/2fe75c34fd54e960146fb8b0ad8b3fd6_jpg.rf.5b4da5b9403cb9506ae3e52de96842fc.jpg  \n",
            " extracting: train/2fe75c34fd54e960146fb8b0ad8b3fd6_jpg.rf.693b072eeb2a9b531b0857ce94b0fedc.jpg  \n",
            " extracting: train/300f80826bbb7dc4bf83e148614f2f77_jpg.rf.145cd48465162eac7e40dfeca236f55b.jpg  \n",
            " extracting: train/300f80826bbb7dc4bf83e148614f2f77_jpg.rf.5281cacb5e3bcfc6bc9056ce0acc5e70.jpg  \n",
            " extracting: train/300f80826bbb7dc4bf83e148614f2f77_jpg.rf.9839ccdb0a608ad3c703bc90147df6ca.jpg  \n",
            " extracting: train/3057eba7e9b0221ddbdc96a01f39ab79_jpg.rf.2447ca37ec7de9b84cadcbbe539525e9.jpg  \n",
            " extracting: train/3057eba7e9b0221ddbdc96a01f39ab79_jpg.rf.349a5aaf97f4108589df81010c7c4bde.jpg  \n",
            " extracting: train/3057eba7e9b0221ddbdc96a01f39ab79_jpg.rf.787d84dddfa8b765df03c4b1af8fa18c.jpg  \n",
            " extracting: train/3091c9b25d76e9cbd0af83ced9f354e5_jpg.rf.8df700ac741b6284988ebf22aabf95e9.jpg  \n",
            " extracting: train/3091c9b25d76e9cbd0af83ced9f354e5_jpg.rf.afa51006174811b7734f491d2d6ad2b7.jpg  \n",
            " extracting: train/3091c9b25d76e9cbd0af83ced9f354e5_jpg.rf.bfe4874bf78f4241bf8a602aef15c352.jpg  \n",
            " extracting: train/31419854b103ca6becc4cc394c449e95_jpg.rf.1d33687e2a30c2496be1818a82863686.jpg  \n",
            " extracting: train/31419854b103ca6becc4cc394c449e95_jpg.rf.4fcab5207dfc54387d4589fbc69c7a47.jpg  \n",
            " extracting: train/31419854b103ca6becc4cc394c449e95_jpg.rf.9640ba223176f79f1fc49b0258a4da86.jpg  \n",
            " extracting: train/3161933dffedf8a859d6623a99492c53_jpg.rf.8cff35ee63144dcc204352db8773f590.jpg  \n",
            " extracting: train/3161933dffedf8a859d6623a99492c53_jpg.rf.972fd8a3af30fa01316510fbb84cccc6.jpg  \n",
            " extracting: train/3161933dffedf8a859d6623a99492c53_jpg.rf.b3cca32040dcb031002296f83298f3d1.jpg  \n",
            " extracting: train/3474d785b1b21d68163f56aa00a92bc9_jpg.rf.526eb41b7d4b9055bcd36adc5d65734a.jpg  \n",
            " extracting: train/3474d785b1b21d68163f56aa00a92bc9_jpg.rf.6ae75801d3082ec64235d399987e2f2d.jpg  \n",
            " extracting: train/3474d785b1b21d68163f56aa00a92bc9_jpg.rf.dc30237c228a1ef77d0fa95a2836791e.jpg  \n",
            " extracting: train/34ad1966ae7a17d4502ca141413ed8d2_jpg.rf.33e7286b5e4b1d97dc8521130bfbb381.jpg  \n",
            " extracting: train/34ad1966ae7a17d4502ca141413ed8d2_jpg.rf.b4e802ae4c541fc3c17ccf55d8653abe.jpg  \n",
            " extracting: train/34ad1966ae7a17d4502ca141413ed8d2_jpg.rf.e8667dbbad2ad13b03ae4e809af01fda.jpg  \n",
            " extracting: train/36066ba85572ce99198f1a21c2c8bbff_jpg.rf.0e1fe87ccd50187773a1725f684648e4.jpg  \n",
            " extracting: train/36066ba85572ce99198f1a21c2c8bbff_jpg.rf.7cc3238420fd4fdce4e67d256d487f9f.jpg  \n",
            " extracting: train/36066ba85572ce99198f1a21c2c8bbff_jpg.rf.b2440aa8c27cef761d6f79eb24689ca9.jpg  \n",
            " extracting: train/3730ef213ac6aad431475a9ab28f349a_jpg.rf.077f757828e9ff709c4e1e8b90f2bd52.jpg  \n",
            " extracting: train/3730ef213ac6aad431475a9ab28f349a_jpg.rf.7529be3c45ccff8446d9464f88f8d1ae.jpg  \n",
            " extracting: train/3730ef213ac6aad431475a9ab28f349a_jpg.rf.94811f6e8a9f59622e25c0ccc4b39c91.jpg  \n",
            " extracting: train/3796db002cba7265bd32b0161ddd9127_jpg.rf.41aa0068bba0c15b03cb7a681aa6533c.jpg  \n",
            " extracting: train/3796db002cba7265bd32b0161ddd9127_jpg.rf.7b8109ee9b9e4dc55b72ec056ee8a747.jpg  \n",
            " extracting: train/3796db002cba7265bd32b0161ddd9127_jpg.rf.e6cc5ba486f5c2010b53ccfa048a0c66.jpg  \n",
            " extracting: train/37fe05bcf7d8568a9e55b569afdbccbd_jpg.rf.024d7337fe60aa8e79bdefe7b2a3bb9b.jpg  \n",
            " extracting: train/37fe05bcf7d8568a9e55b569afdbccbd_jpg.rf.3a8156b29c22bf3e8a0a9fb0e019b005.jpg  \n",
            " extracting: train/37fe05bcf7d8568a9e55b569afdbccbd_jpg.rf.9f9e465232a4c7b586422397223786e9.jpg  \n",
            " extracting: train/383c2ed7bbe2d327ab55a871db497c33_jpg.rf.86e4f3f7434d212f1874685d71056f1a.jpg  \n",
            " extracting: train/383c2ed7bbe2d327ab55a871db497c33_jpg.rf.9d983827ab445085bc8eef5da0b96932.jpg  \n",
            " extracting: train/383c2ed7bbe2d327ab55a871db497c33_jpg.rf.bb72df5de81f3e76ee75e36e99566217.jpg  \n",
            " extracting: train/389b4c47568c78c44df11dbb1377ffea_jpg.rf.0185f6bf38d82f7cbf9365edd7b2bfc7.jpg  \n",
            " extracting: train/389b4c47568c78c44df11dbb1377ffea_jpg.rf.4105215a89a9e91f39916aabf7bd3724.jpg  \n",
            " extracting: train/389b4c47568c78c44df11dbb1377ffea_jpg.rf.8ecdacfacb51a1088354bbae4d6a0731.jpg  \n",
            " extracting: train/38f26ee82e38d332b2a831aa47bd363b_jpg.rf.70eebaf376a7a948c757715dad519b41.jpg  \n",
            " extracting: train/38f26ee82e38d332b2a831aa47bd363b_jpg.rf.8e046f6c557a95effc7ca1d7e69c2dee.jpg  \n",
            " extracting: train/38f26ee82e38d332b2a831aa47bd363b_jpg.rf.9531ac0c4855e848bb2d188218efe2ed.jpg  \n",
            " extracting: train/3914be0cea4aa8a6bbd1081ec3b034a7_jpg.rf.95fd9107c63ea71989cd7fddd5d9e033.jpg  \n",
            " extracting: train/3914be0cea4aa8a6bbd1081ec3b034a7_jpg.rf.a2edb468c84f94882c8d1ed4b983d810.jpg  \n",
            " extracting: train/3914be0cea4aa8a6bbd1081ec3b034a7_jpg.rf.dc33766dd5985aee3962019edd74dd7a.jpg  \n",
            " extracting: train/3bab0eaaeb63a2ac9ae4942df4006a25_jpg.rf.8fd1c7b01ae630cdb96546469e0c742d.jpg  \n",
            " extracting: train/3bab0eaaeb63a2ac9ae4942df4006a25_jpg.rf.b78947d5207c15119ee81058a1b75c1e.jpg  \n",
            " extracting: train/3bab0eaaeb63a2ac9ae4942df4006a25_jpg.rf.d137ab448f3c219896325f1e464c9cdc.jpg  \n",
            " extracting: train/3e8fb24addda1a0945bd6b7777bc4018_jpg.rf.57548fe2320bf43321fcf4372bfe6e2f.jpg  \n",
            " extracting: train/3e8fb24addda1a0945bd6b7777bc4018_jpg.rf.bc9daf0bd452e0c7dfd9167761e02135.jpg  \n",
            " extracting: train/3e8fb24addda1a0945bd6b7777bc4018_jpg.rf.f842c9757bdb85fddeddce5fddd65bc0.jpg  \n",
            " extracting: train/446e75de1ffefc2115e79696bcf0e357_jpg.rf.378829d017d56bcfbe81248206ba928d.jpg  \n",
            " extracting: train/446e75de1ffefc2115e79696bcf0e357_jpg.rf.c74c5023e09478494c8b41aa67f070fe.jpg  \n",
            " extracting: train/446e75de1ffefc2115e79696bcf0e357_jpg.rf.fc5ddb0686d3ecafa3b5a0c5ae084777.jpg  \n",
            " extracting: train/4667110b61b16e786673ed6126ccc35d_jpg.rf.3dc2ee18962afee7c0f61083d17ed411.jpg  \n",
            " extracting: train/4667110b61b16e786673ed6126ccc35d_jpg.rf.a4f83fe2f7c74d0fde01c1fcb729af7c.jpg  \n",
            " extracting: train/4667110b61b16e786673ed6126ccc35d_jpg.rf.b58c56605fbe3e496fa3a357f3dce9b7.jpg  \n",
            " extracting: train/479459fe5c8213a84fd55ba82f2670b1_jpg.rf.a4c7681de134fd46a3463e388f1e48ec.jpg  \n",
            " extracting: train/479459fe5c8213a84fd55ba82f2670b1_jpg.rf.aed5813593dffed834ffe36cd1a2e976.jpg  \n",
            " extracting: train/479459fe5c8213a84fd55ba82f2670b1_jpg.rf.d7c8eb7af0feef6985de36ee54a50f84.jpg  \n",
            " extracting: train/47e842dd95735a11cf92c0ddf1161193_jpg.rf.550ba2f2bb261d19394fa2973ec4480a.jpg  \n",
            " extracting: train/47e842dd95735a11cf92c0ddf1161193_jpg.rf.60c38d132c7d19cb8454be79650d53a5.jpg  \n",
            " extracting: train/47e842dd95735a11cf92c0ddf1161193_jpg.rf.a08d492a1f68458ff0d6eb299c6a8478.jpg  \n",
            " extracting: train/4807629b8df9c7eb4366b7feccd72e6a_jpg.rf.3a08163076ee5b06be9828b63ec69139.jpg  \n",
            " extracting: train/4807629b8df9c7eb4366b7feccd72e6a_jpg.rf.478258d366ce8053d7b5400071103a8b.jpg  \n",
            " extracting: train/4807629b8df9c7eb4366b7feccd72e6a_jpg.rf.52cd2115863114b29306879f88bb2650.jpg  \n",
            " extracting: train/4894f034a55eaa9252cd261a62b11d27_jpg.rf.bcd60bd54187dbd564c6d84e8a4d3cb9.jpg  \n",
            " extracting: train/4894f034a55eaa9252cd261a62b11d27_jpg.rf.e153d650cc91ee8985dbc0f9b5050e98.jpg  \n",
            " extracting: train/4894f034a55eaa9252cd261a62b11d27_jpg.rf.ec15ec6e91a0367ded74d29495beadca.jpg  \n",
            " extracting: train/48d3c59a99b2b5a5b9f1eb7d5ba63b60_jpg.rf.03a5018519fa45d9439d5716a03d3d02.jpg  \n",
            " extracting: train/48d3c59a99b2b5a5b9f1eb7d5ba63b60_jpg.rf.303fc026ea7df3c5cafd1f551ed75390.jpg  \n",
            " extracting: train/48d3c59a99b2b5a5b9f1eb7d5ba63b60_jpg.rf.d798956fd75f2a961a741523c14d932b.jpg  \n",
            " extracting: train/48e115dcbf1b3a67ca47a75a92da3f33_jpg.rf.213e4eb4f61d74e9b61d8c7032da1766.jpg  \n",
            " extracting: train/48e115dcbf1b3a67ca47a75a92da3f33_jpg.rf.5b14a17bd1d17edb532b6b6db9c35077.jpg  \n",
            " extracting: train/48e115dcbf1b3a67ca47a75a92da3f33_jpg.rf.957bf6dd4345aa7c771e116ba8273385.jpg  \n",
            " extracting: train/4939035108d04ee672570a7cc937e270_jpg.rf.0bb1cc45c05e40db8106b53800168de6.jpg  \n",
            " extracting: train/4939035108d04ee672570a7cc937e270_jpg.rf.665362625fea5d5db13389cfa7a51e28.jpg  \n",
            " extracting: train/4939035108d04ee672570a7cc937e270_jpg.rf.c676ffd8b63ca7b82aeb3348c032c768.jpg  \n",
            " extracting: train/49c2afbbe5726160b289f7c0c62cdace_jpg.rf.18b76575c39d8cf45f9a9a8b6c6b6646.jpg  \n",
            " extracting: train/49c2afbbe5726160b289f7c0c62cdace_jpg.rf.518f9a645071b5dfd9104711c09c2b49.jpg  \n",
            " extracting: train/49c2afbbe5726160b289f7c0c62cdace_jpg.rf.c09e87097759a1f3c86cfc83a677ee7d.jpg  \n",
            " extracting: train/49d365236ee4fb6bd982b0f00bff007e_jpg.rf.526a1568df59ddce6050cf2bce92f260.jpg  \n",
            " extracting: train/49d365236ee4fb6bd982b0f00bff007e_jpg.rf.64f40e96e43baa404c6341ccd672ca08.jpg  \n",
            " extracting: train/49d365236ee4fb6bd982b0f00bff007e_jpg.rf.da164da26c512372f70e3090200361a9.jpg  \n",
            " extracting: train/49f78dc9aaeadd0c76ed2def75c358f3_jpg.rf.8df70d46b69b46482c5a2bab67b045b2.jpg  \n",
            " extracting: train/49f78dc9aaeadd0c76ed2def75c358f3_jpg.rf.c79a51cf35ad3e236c3ea41e5a659b31.jpg  \n",
            " extracting: train/49f78dc9aaeadd0c76ed2def75c358f3_jpg.rf.f80f03233e3dea74dbb92e5f2340f29a.jpg  \n",
            " extracting: train/4ae38537a74c5ed10d5223f8066659fc_jpg.rf.2a3fc30eafd01a0c64b484b6082ded39.jpg  \n",
            " extracting: train/4ae38537a74c5ed10d5223f8066659fc_jpg.rf.b01826258e0bba0f3ad3f79f161ca106.jpg  \n",
            " extracting: train/4ae38537a74c5ed10d5223f8066659fc_jpg.rf.c07420cc60cdf3ede129a75dec9678e6.jpg  \n",
            " extracting: train/4bf38c062fa7b5796d15ba90d6c3a456_jpg.rf.54d7350f0b18e8ec51cc8b9c351f6dce.jpg  \n",
            " extracting: train/4bf38c062fa7b5796d15ba90d6c3a456_jpg.rf.5dc82d8843d5593359743fb73bd57edd.jpg  \n",
            " extracting: train/4bf38c062fa7b5796d15ba90d6c3a456_jpg.rf.91410d81d86b82171fe7b271b94a4f58.jpg  \n",
            " extracting: train/4d6b667ecbd41ebd603b38848366d9d0_jpg.rf.316c7f9af0955c14bc8303c62d5f0cd6.jpg  \n",
            " extracting: train/4d6b667ecbd41ebd603b38848366d9d0_jpg.rf.4e30bb8f1b1048c822c448c40663b90d.jpg  \n",
            " extracting: train/4d6b667ecbd41ebd603b38848366d9d0_jpg.rf.7cc24cb0d6e9d83179bc05d30f21bb49.jpg  \n",
            " extracting: train/4d7820ad9fb4fe69d5168e1d7317dd02_jpg.rf.64764ea1b78a8aec014ead34271137f7.jpg  \n",
            " extracting: train/4d7820ad9fb4fe69d5168e1d7317dd02_jpg.rf.8cb302097c3cd4d1488ba6ed0b6c0abf.jpg  \n",
            " extracting: train/4d7820ad9fb4fe69d5168e1d7317dd02_jpg.rf.fe26c65d9b961251ae7dc598e45679b8.jpg  \n",
            " extracting: train/4de23afff63bc169b4ebe547a9c9b692_jpg.rf.958dc90b7cb5eeb2bdc66b0356537d03.jpg  \n",
            " extracting: train/4de23afff63bc169b4ebe547a9c9b692_jpg.rf.b16d4e221a3c932898f7efac57ab331f.jpg  \n",
            " extracting: train/4de23afff63bc169b4ebe547a9c9b692_jpg.rf.d5caca6c6352c358873e2bcbe08dcb3e.jpg  \n",
            " extracting: train/4eb630d4dd38528dacf72355caf5c06d_jpg.rf.542d02f24b1238b2b8ddf7e63669c6f1.jpg  \n",
            " extracting: train/4eb630d4dd38528dacf72355caf5c06d_jpg.rf.aa4d36c64699330596d6503653e43b00.jpg  \n",
            " extracting: train/4eb630d4dd38528dacf72355caf5c06d_jpg.rf.d291d9ff254a5001b29ef8ce2d722509.jpg  \n",
            " extracting: train/53de0674524ae6d77bdfff48136dec2a_jpg.rf.108f3dd477ce61cd4f9251ab967b9ed5.jpg  \n",
            " extracting: train/53de0674524ae6d77bdfff48136dec2a_jpg.rf.418e577139ae88cec5118571c10db894.jpg  \n",
            " extracting: train/53de0674524ae6d77bdfff48136dec2a_jpg.rf.bd9646f1a26121fe3ab5d9ee21242c82.jpg  \n",
            " extracting: train/54a90aab8c73562975cc560d51a9d2d1_jpg.rf.3de5a183732df4464edd9264ff210593.jpg  \n",
            " extracting: train/54a90aab8c73562975cc560d51a9d2d1_jpg.rf.6d2f9f9d7b95d619880e632d994d535f.jpg  \n",
            " extracting: train/54a90aab8c73562975cc560d51a9d2d1_jpg.rf.f081bba0a3c5e5e14c0b6bd94992465f.jpg  \n",
            " extracting: train/5758322233deed7ae7adc23536db2a4f_jpg.rf.07a3d3e2244da0cdeddc6bf88e0d86a1.jpg  \n",
            " extracting: train/5758322233deed7ae7adc23536db2a4f_jpg.rf.469940331ca0c0fbabd2eaad8348ed71.jpg  \n",
            " extracting: train/5758322233deed7ae7adc23536db2a4f_jpg.rf.b16cd14d6af50949e7efe4fffdf0a1d1.jpg  \n",
            " extracting: train/5825608dccde6544eef91822136079d0_jpg.rf.7978595f8c77d14fd89ab7a6f37a165d.jpg  \n",
            " extracting: train/5825608dccde6544eef91822136079d0_jpg.rf.8eb618cb2ddaa495dce8b3c21edb5a03.jpg  \n",
            " extracting: train/5825608dccde6544eef91822136079d0_jpg.rf.dc066eb4cb44e69c2e98df8a874f613e.jpg  \n",
            " extracting: train/59727dce26aaa6100078810b61404069_jpg.rf.133f5f4c2d66f3c1cb83e25323606c51.jpg  \n",
            " extracting: train/59727dce26aaa6100078810b61404069_jpg.rf.7921f54d55b72950940731ff0736852a.jpg  \n",
            " extracting: train/59727dce26aaa6100078810b61404069_jpg.rf.86632bfcf9c96df565417f9cb5e54245.jpg  \n",
            " extracting: train/5a8433ec79c881f84ef19a07dc73665d_jpg.rf.00544a8110f323e0d7721b3acf2a9e1e.jpg  \n",
            " extracting: train/5a8433ec79c881f84ef19a07dc73665d_jpg.rf.4f609e90d2f6cf6dfdc09b85b8540822.jpg  \n",
            " extracting: train/5a8433ec79c881f84ef19a07dc73665d_jpg.rf.ff374a0e164f5d51813ebbdb38ae9167.jpg  \n",
            " extracting: train/5cecd3b3946aac5c713a51e0bd4617c9_jpg.rf.95fed532326e22f1bc20ee6f4768fb46.jpg  \n",
            " extracting: train/5cecd3b3946aac5c713a51e0bd4617c9_jpg.rf.b6acbacc6e21614897ae17bfc1610149.jpg  \n",
            " extracting: train/5cecd3b3946aac5c713a51e0bd4617c9_jpg.rf.e3e350b59dff7927d46041502756c8f3.jpg  \n",
            " extracting: train/5e71cb8d41c333a18e799ef0004b040c_jpg.rf.05d2a8f977945663a18db2cc223250d3.jpg  \n",
            " extracting: train/5e71cb8d41c333a18e799ef0004b040c_jpg.rf.3b081eddaeaa4d9e1da3f8990354d2b8.jpg  \n",
            " extracting: train/5e71cb8d41c333a18e799ef0004b040c_jpg.rf.8a014b0d0195c6cc3a046974a1fec787.jpg  \n",
            " extracting: train/614811e933a680fd6535ac8bf06bf530_jpg.rf.283f06fa4884ea55a91410d9ca4f937c.jpg  \n",
            " extracting: train/614811e933a680fd6535ac8bf06bf530_jpg.rf.a3ef46761353d060a2693bb7ada2ab7e.jpg  \n",
            " extracting: train/614811e933a680fd6535ac8bf06bf530_jpg.rf.fb18ccc88d4752a62d47a3260f9e0cf9.jpg  \n",
            " extracting: train/614aadadb4a7f5b475b027b8e11398ee_jpg.rf.01b40c037e8cf1ff49c740244753af5a.jpg  \n",
            " extracting: train/614aadadb4a7f5b475b027b8e11398ee_jpg.rf.04c134d966574ad5fdcacfb8ab619fd6.jpg  \n",
            " extracting: train/614aadadb4a7f5b475b027b8e11398ee_jpg.rf.9c328189083b33832b90aa43f1de101d.jpg  \n",
            " extracting: train/61567b97353acc18ba9e8aac0f111326_jpg.rf.5765711e8acd7531ab0b7c5df47febf7.jpg  \n",
            " extracting: train/61567b97353acc18ba9e8aac0f111326_jpg.rf.94cec1f562c9e5d3eb3b3544eecc72a0.jpg  \n",
            " extracting: train/61567b97353acc18ba9e8aac0f111326_jpg.rf.9744632c3305a0e7db1b8035a4cd3f5f.jpg  \n",
            " extracting: train/6179b463c8f503445e213b706d2a4de5_jpg.rf.60047d46835605a44d1373c2fbc9d86a.jpg  \n",
            " extracting: train/6179b463c8f503445e213b706d2a4de5_jpg.rf.6dad401212f974d778d11ec908ef1845.jpg  \n",
            " extracting: train/6179b463c8f503445e213b706d2a4de5_jpg.rf.8d422c23f907d10ba6ce02a34fc3e32e.jpg  \n",
            " extracting: train/6403b91d63799cb9b5531c47b195d088_jpg.rf.5cc9e50f7632e7938bead4a10e5fff77.jpg  \n",
            " extracting: train/6403b91d63799cb9b5531c47b195d088_jpg.rf.c98b6f1a55887b0abf43a46704ffce4a.jpg  \n",
            " extracting: train/6403b91d63799cb9b5531c47b195d088_jpg.rf.f88dea07bfc6c748c9b2bbdb9142935b.jpg  \n",
            " extracting: train/6589f4cfb37439d7d276f0d70f7ee1f0_jpg.rf.5e07c88452d0555565cf271ea458a66e.jpg  \n",
            " extracting: train/6589f4cfb37439d7d276f0d70f7ee1f0_jpg.rf.7cd0c647da853363af83fd4223c78dee.jpg  \n",
            " extracting: train/6589f4cfb37439d7d276f0d70f7ee1f0_jpg.rf.fb12b9c28e07eb3813f431bca229ef56.jpg  \n",
            " extracting: train/65ba27557c78850168b1df70a3ce4ff7_jpg.rf.1431d99ebaf30d4ecb2764af7d18a452.jpg  \n",
            " extracting: train/65ba27557c78850168b1df70a3ce4ff7_jpg.rf.30a3ce572eb4c0a6cdbc01380dd7e390.jpg  \n",
            " extracting: train/65ba27557c78850168b1df70a3ce4ff7_jpg.rf.81006b590b068c8c93153e7f18a20c1f.jpg  \n",
            " extracting: train/66f3c2c7c10a9263de9c6e056ba5c1b9_jpg.rf.14a1fa7ff39bebb52c565e529d7c4d21.jpg  \n",
            " extracting: train/66f3c2c7c10a9263de9c6e056ba5c1b9_jpg.rf.b4bc9d32ccb677ebb9789a4b99869931.jpg  \n",
            " extracting: train/66f3c2c7c10a9263de9c6e056ba5c1b9_jpg.rf.fd49e15d41262253b45c5bab05240902.jpg  \n",
            " extracting: train/673bcd0d44f495fbe9dd88d5cacfceb3_jpg.rf.06788087ab120edd9cfeb3dde2ec559f.jpg  \n",
            " extracting: train/673bcd0d44f495fbe9dd88d5cacfceb3_jpg.rf.3b647f8c3bb9f3fc64a0d0edf806f691.jpg  \n",
            " extracting: train/673bcd0d44f495fbe9dd88d5cacfceb3_jpg.rf.c3db2d6f80603a8fdd150776e4a74da0.jpg  \n",
            " extracting: train/675619f2c8078824cfd182cec2eeba95_jpg.rf.0130e3c26b1bf275bf240894ba73ed7c.jpg  \n",
            " extracting: train/675619f2c8078824cfd182cec2eeba95_jpg.rf.13e6aede17ac36e46af40237b2af1717.jpg  \n",
            " extracting: train/675619f2c8078824cfd182cec2eeba95_jpg.rf.5a41f34953687f23f2a1a38a223eb333.jpg  \n",
            " extracting: train/699edbacbfee5e6d4d6d2189bc88990a_jpg.rf.05759b66a63504389df87f76ea3e1bb3.jpg  \n",
            " extracting: train/699edbacbfee5e6d4d6d2189bc88990a_jpg.rf.57b3e5ffba66e0e4c1e7ecb65a422249.jpg  \n",
            " extracting: train/699edbacbfee5e6d4d6d2189bc88990a_jpg.rf.ecdf9c3d5f17c0c43930335adcd9ffef.jpg  \n",
            " extracting: train/6ba74e310dd824af891d057d674cedb9_jpg.rf.08dafde0b81de46e57122cc80a5cdc80.jpg  \n",
            " extracting: train/6ba74e310dd824af891d057d674cedb9_jpg.rf.1a5dc9d3dcc29d0b47f898d0d5c06868.jpg  \n",
            " extracting: train/6ba74e310dd824af891d057d674cedb9_jpg.rf.2538782d08f7ce2bebeb479450f67a8b.jpg  \n",
            " extracting: train/6bb6f7cb96bf37230681d12ff7882f61_jpg.rf.0735069f44fbf300bb0824ee46630bd4.jpg  \n",
            " extracting: train/6bb6f7cb96bf37230681d12ff7882f61_jpg.rf.391d72bf1073621fe3eac397ae4e34d9.jpg  \n",
            " extracting: train/6bb6f7cb96bf37230681d12ff7882f61_jpg.rf.77cbc9c645b41068d312e144d05d3792.jpg  \n",
            " extracting: train/6f0a888f9e5aed9516e336fd04723ce1_jpg.rf.190df401c6ca3dfa7bec7c5704ad4727.jpg  \n",
            " extracting: train/6f0a888f9e5aed9516e336fd04723ce1_jpg.rf.8151961a5cf2cebf38ce030f7eec1b68.jpg  \n",
            " extracting: train/6f0a888f9e5aed9516e336fd04723ce1_jpg.rf.96cb5b0fd28087f53914ec4b992a849c.jpg  \n",
            " extracting: train/6f0de9b594de9f9b92c6a20daa51a28a_jpg.rf.8f172ec0ccc12d54f9e13be42c61f072.jpg  \n",
            " extracting: train/6f0de9b594de9f9b92c6a20daa51a28a_jpg.rf.9716020a6b1eeb6980969dc359031f66.jpg  \n",
            " extracting: train/6f0de9b594de9f9b92c6a20daa51a28a_jpg.rf.d10980ee6f2a7a600d16ff48d980a15c.jpg  \n",
            " extracting: train/759a86e63667ca033255c4ab438dd392_jpg.rf.0caf155d6d5d35c723fb6b362c8c1493.jpg  \n",
            " extracting: train/759a86e63667ca033255c4ab438dd392_jpg.rf.a5cd6d950994168a0bef9e5be6a8d5c2.jpg  \n",
            " extracting: train/759a86e63667ca033255c4ab438dd392_jpg.rf.aec0831369eb571dbe73a6342206a8bc.jpg  \n",
            " extracting: train/76d01bada90581f55f1ae64c062cafcf_jpg.rf.7104e065b387e61376bafda059671616.jpg  \n",
            " extracting: train/76d01bada90581f55f1ae64c062cafcf_jpg.rf.f2bd2d4d062181b36c9a9159de7090ae.jpg  \n",
            " extracting: train/76d01bada90581f55f1ae64c062cafcf_jpg.rf.f3d7a25fb4f47eb56b7affa5673c14f7.jpg  \n",
            " extracting: train/76dbe2ccf986a2a0d399d3d8a47279ad_jpg.rf.26886d4d35f2aefff108d7aaf1cb37db.jpg  \n",
            " extracting: train/76dbe2ccf986a2a0d399d3d8a47279ad_jpg.rf.b1ca3d77f5a92e76eb13e448042398fb.jpg  \n",
            " extracting: train/76dbe2ccf986a2a0d399d3d8a47279ad_jpg.rf.b422f9fa12f7008b3ed897977e7d4948.jpg  \n",
            " extracting: train/76e118acf05a8ebe06957f8882cc06aa_jpg.rf.4d490b0b2c2371c0a5d3c41b258631d4.jpg  \n",
            " extracting: train/76e118acf05a8ebe06957f8882cc06aa_jpg.rf.e5dba6cdbb0e4b9636bb1a7b2eefdd5c.jpg  \n",
            " extracting: train/76e118acf05a8ebe06957f8882cc06aa_jpg.rf.ebc8f2857885aa9442f7817ea798f5ba.jpg  \n",
            " extracting: train/79e744a68d6e6f83be0a9e8761ea66a4_jpg.rf.1c2b3f87f6a51fb881178db2db0b228c.jpg  \n",
            " extracting: train/79e744a68d6e6f83be0a9e8761ea66a4_jpg.rf.92eb07a6d24d7f998cedd49a676bb621.jpg  \n",
            " extracting: train/79e744a68d6e6f83be0a9e8761ea66a4_jpg.rf.a7b671ff5bbf39d29460db7e874fe65e.jpg  \n",
            " extracting: train/7df16cd59fb40e0691948cc805e4801b_jpg.rf.286df02ab2343ae37cddc443b06feccd.jpg  \n",
            " extracting: train/7df16cd59fb40e0691948cc805e4801b_jpg.rf.69645d63d7ad1dcadfcb6fef8d88cbae.jpg  \n",
            " extracting: train/7df16cd59fb40e0691948cc805e4801b_jpg.rf.8c289f8d3498de860c1c990873892987.jpg  \n",
            " extracting: train/7ee8d13861bdc45e40a7cfe190a8d8a6_jpg.rf.a8231ed0a104c2558156dc1efa5deaa4.jpg  \n",
            " extracting: train/7ee8d13861bdc45e40a7cfe190a8d8a6_jpg.rf.a866a35bb9ecd0567a6123b53152565f.jpg  \n",
            " extracting: train/7ee8d13861bdc45e40a7cfe190a8d8a6_jpg.rf.d2b41f1d0bdb7f0bf1055dfa6902e7fd.jpg  \n",
            " extracting: train/81f5c542ffe0f9eae4df59d29acbcced_jpg.rf.0a5ee623a389c32b7ede54f7b9d1bd20.jpg  \n",
            " extracting: train/81f5c542ffe0f9eae4df59d29acbcced_jpg.rf.61fced727ced7c4956b023b20c423500.jpg  \n",
            " extracting: train/81f5c542ffe0f9eae4df59d29acbcced_jpg.rf.91a87f1144d3374bcc23d457e1499b50.jpg  \n",
            " extracting: train/859e7157c6d544236a67463c08169b6e_jpg.rf.4021cc08bfe2940ac1246a952028554f.jpg  \n",
            " extracting: train/859e7157c6d544236a67463c08169b6e_jpg.rf.4136782db50a3ab23736edbd04956068.jpg  \n",
            " extracting: train/859e7157c6d544236a67463c08169b6e_jpg.rf.ab489bf688838056d6bd5f713ada144a.jpg  \n",
            " extracting: train/8678864272a0a04c4c65ca96324105b4_jpg.rf.156a4b6b892a8823a481394ab0acdde2.jpg  \n",
            " extracting: train/8678864272a0a04c4c65ca96324105b4_jpg.rf.1bbe62626b8565d608b4ca8a66697d0a.jpg  \n",
            " extracting: train/8678864272a0a04c4c65ca96324105b4_jpg.rf.f14a6dc74582fe3e7649095c22d353ac.jpg  \n",
            " extracting: train/871597c145446cf58c1c2dd7db988864_jpg.rf.33a0386e35eceaf1f5ecca1169b3fe9f.jpg  \n",
            " extracting: train/871597c145446cf58c1c2dd7db988864_jpg.rf.418632a00632006cb8d4b1c72f9d7777.jpg  \n",
            " extracting: train/871597c145446cf58c1c2dd7db988864_jpg.rf.752f5219f9020f0070ef1aaa764901ed.jpg  \n",
            " extracting: train/889c420fb266b8d0e817306110042bda_jpg.rf.2b64d4f77790efe5b99a89dbc008d2fa.jpg  \n",
            " extracting: train/889c420fb266b8d0e817306110042bda_jpg.rf.8b7244d128b2eaa4e64c6bc4a1649911.jpg  \n",
            " extracting: train/889c420fb266b8d0e817306110042bda_jpg.rf.e94a6dd83fdb1bba12f4a84b1388fa86.jpg  \n",
            " extracting: train/8967433350d3b3043902603430fccaab_jpg.rf.144e0920a0999b5329faa86297b2511b.jpg  \n",
            " extracting: train/8967433350d3b3043902603430fccaab_jpg.rf.58236ac06d7679220b6db7050d8b783d.jpg  \n",
            " extracting: train/8967433350d3b3043902603430fccaab_jpg.rf.ed0a29dbaaa3cfed939b63f420cbe09e.jpg  \n",
            " extracting: train/8bb72e70f0560095885586deba37a524_jpg.rf.21a0d0568779e89d7ad0a4d38262c25c.jpg  \n",
            " extracting: train/8bb72e70f0560095885586deba37a524_jpg.rf.4998a4bf9c84c615a27d9247d6079f97.jpg  \n",
            " extracting: train/8bb72e70f0560095885586deba37a524_jpg.rf.b13dbc1ad8ed27fb0ad5edf06e990a22.jpg  \n",
            " extracting: train/8d6f722eadc015a393bd490f9b7a85e6_jpg.rf.599d92c366a926edbc15b3afd1d2317a.jpg  \n",
            " extracting: train/8d6f722eadc015a393bd490f9b7a85e6_jpg.rf.c7ef5eb61f666dd9651b0f2a23cf3f60.jpg  \n",
            " extracting: train/8d6f722eadc015a393bd490f9b7a85e6_jpg.rf.d54265714db43ff80c5b3616cc762935.jpg  \n",
            " extracting: train/8d796de64b9eed1ffd5ebe550d4ca807_jpg.rf.47e02933a0e4907473f52cb156d27a03.jpg  \n",
            " extracting: train/8d796de64b9eed1ffd5ebe550d4ca807_jpg.rf.4b299e7e3a7aff419e2a7693d52f5890.jpg  \n",
            " extracting: train/8d796de64b9eed1ffd5ebe550d4ca807_jpg.rf.7c37da2bd123ae11af92e6c4bfb37518.jpg  \n",
            " extracting: train/8dd12470c30e3b265e8933a6fee7ad28_jpg.rf.11ee9892a34c2b196cfa0cb55ecaaf73.jpg  \n",
            " extracting: train/8dd12470c30e3b265e8933a6fee7ad28_jpg.rf.83f5aa113ef37318fe16494fc6d836b0.jpg  \n",
            " extracting: train/8dd12470c30e3b265e8933a6fee7ad28_jpg.rf.e9434facbc330f439a3f33d614e18cb8.jpg  \n",
            " extracting: train/8de03901c64a80070048ead3fb0d32bd_jpg.rf.3bdcf5223918218765c685e65d8efd1e.jpg  \n",
            " extracting: train/8de03901c64a80070048ead3fb0d32bd_jpg.rf.84141f105064b57f9714500f7927f2a4.jpg  \n",
            " extracting: train/8de03901c64a80070048ead3fb0d32bd_jpg.rf.e4be065937a901b047ab7894c2fff35a.jpg  \n",
            " extracting: train/8f84f1945fd993facc3368d13345f333_jpg.rf.0b7d4817639d4820d53a3a92bff52578.jpg  \n",
            " extracting: train/8f84f1945fd993facc3368d13345f333_jpg.rf.2dd383bee798d213527485d1ca3243e9.jpg  \n",
            " extracting: train/8f84f1945fd993facc3368d13345f333_jpg.rf.506d20c9cd61cb9f88aa962af2e924f7.jpg  \n",
            " extracting: train/8ff64b3f770bfe96bdffc629efd16460_jpg.rf.09ed33a05bcda0d77e71b945d1e0475a.jpg  \n",
            " extracting: train/8ff64b3f770bfe96bdffc629efd16460_jpg.rf.7b4792b9f562b28d55342586be82fe91.jpg  \n",
            " extracting: train/8ff64b3f770bfe96bdffc629efd16460_jpg.rf.9dfbcd5dcdd10632e499e2305b970292.jpg  \n",
            " extracting: train/9146a6989dac08f1769e677064ebfb49_jpg.rf.2b88a96ff66c491128cf8c3f934d845d.jpg  \n",
            " extracting: train/9146a6989dac08f1769e677064ebfb49_jpg.rf.f479d3177bde0b8beb172fcd798971f2.jpg  \n",
            " extracting: train/9146a6989dac08f1769e677064ebfb49_jpg.rf.fa759e8f569722a7d3a9cea8eb790cbb.jpg  \n",
            " extracting: train/92992ff9c823e0420bf17e71db9ef4ef_jpg.rf.2e44da4eff077a078f5186fb461f5c2e.jpg  \n",
            " extracting: train/92992ff9c823e0420bf17e71db9ef4ef_jpg.rf.927b7a8d0224a92439c39e05b5b8f7f0.jpg  \n",
            " extracting: train/92992ff9c823e0420bf17e71db9ef4ef_jpg.rf.b3fc57a580cfbb9c3847712a48fa46a9.jpg  \n",
            " extracting: train/93557fc861304f7753089c244bc1e33e_jpg.rf.2eb582969dccb15da9e2a7436c58e214.jpg  \n",
            " extracting: train/93557fc861304f7753089c244bc1e33e_jpg.rf.81179eea89bb8b659cece59aefb29a3f.jpg  \n",
            " extracting: train/93557fc861304f7753089c244bc1e33e_jpg.rf.b322a75dd276455b652411e28eae9d28.jpg  \n",
            " extracting: train/969daa72bd7804ea1212e191820249b0_jpg.rf.416287a296a7712c4a7e15dfebe71ba6.jpg  \n",
            " extracting: train/969daa72bd7804ea1212e191820249b0_jpg.rf.ba89164a5a6707326ca30fa4d44c0414.jpg  \n",
            " extracting: train/969daa72bd7804ea1212e191820249b0_jpg.rf.d8d404aa7f784c9d9a80dd9a567b62f8.jpg  \n",
            " extracting: train/97aeb1f9b745a929e9ac0848acb53a1a_jpg.rf.3284f8666d6a9be6075774c73ec06ac4.jpg  \n",
            " extracting: train/97aeb1f9b745a929e9ac0848acb53a1a_jpg.rf.940a166aa673e2d31ccd5d2e2f21b3b2.jpg  \n",
            " extracting: train/97aeb1f9b745a929e9ac0848acb53a1a_jpg.rf.e56d342ac870ddbd53d31ee88c69f1be.jpg  \n",
            " extracting: train/9962a4d44388b9008aa0f466e4f4052c_jpg.rf.271e62fd6244a808feddc27148f4f5ab.jpg  \n",
            " extracting: train/9962a4d44388b9008aa0f466e4f4052c_jpg.rf.5335c3722d3fe9b709488d492cd5c49f.jpg  \n",
            " extracting: train/9962a4d44388b9008aa0f466e4f4052c_jpg.rf.e631892cbc08c42fce1df2203b2a0320.jpg  \n",
            " extracting: train/998222d9c93f1640829d4f0032dbf3e8_jpg.rf.96e7371e40c0f8f62167e9f459e7d457.jpg  \n",
            " extracting: train/998222d9c93f1640829d4f0032dbf3e8_jpg.rf.e6970890732ecad792fc36f8d5644d5f.jpg  \n",
            " extracting: train/998222d9c93f1640829d4f0032dbf3e8_jpg.rf.f8871eeb54a25358a97555c29fecadf4.jpg  \n",
            " extracting: train/99ee6574b2a7afc0bb06269bbcf49a4c_jpg.rf.72f0a52418f5c4883a0d240e47d10f63.jpg  \n",
            " extracting: train/99ee6574b2a7afc0bb06269bbcf49a4c_jpg.rf.b544a6e335dc26f90bd9bcd10bc2cd2b.jpg  \n",
            " extracting: train/99ee6574b2a7afc0bb06269bbcf49a4c_jpg.rf.be8193d6def80fbf6e353335fa2d7169.jpg  \n",
            " extracting: train/9a6b61a6d3b3e3ecddc201b097aa02d1_jpg.rf.56770b3733424cb8ed9bf50d15ff31ca.jpg  \n",
            " extracting: train/9a6b61a6d3b3e3ecddc201b097aa02d1_jpg.rf.b316792e863318d8477f61831379c096.jpg  \n",
            " extracting: train/9a6b61a6d3b3e3ecddc201b097aa02d1_jpg.rf.bb7f7ec0dc21ee5750a7f9a8924c0c84.jpg  \n",
            " extracting: train/9c153a9c9798dab948d4260eb109b315_jpg.rf.173225adc244d19c0342031fd17b26af.jpg  \n",
            " extracting: train/9c153a9c9798dab948d4260eb109b315_jpg.rf.70d24c98a13f6263522fb9228d4438ca.jpg  \n",
            " extracting: train/9c153a9c9798dab948d4260eb109b315_jpg.rf.c2e67b9c11e120380ba6e552636ea3f8.jpg  \n",
            " extracting: train/9c5fb0c3cfd7b334a247cd87c139e8e6_jpg.rf.325734823f668518210b618ac6d105e4.jpg  \n",
            " extracting: train/9c5fb0c3cfd7b334a247cd87c139e8e6_jpg.rf.904c4ab6f7ac3d6c2ab134394b00e632.jpg  \n",
            " extracting: train/9c5fb0c3cfd7b334a247cd87c139e8e6_jpg.rf.d1b91f7c6433bd582e4e4859d618aaa6.jpg  \n",
            " extracting: train/9d776e74e90c4f8092b060dd7567e2f8_jpg.rf.23bd3ffda19846a2c63afa0af7313f1c.jpg  \n",
            " extracting: train/9d776e74e90c4f8092b060dd7567e2f8_jpg.rf.660c681198650e419a8e8102c9353655.jpg  \n",
            " extracting: train/9d776e74e90c4f8092b060dd7567e2f8_jpg.rf.e56c4f14986b14ecae9d9693766bbb09.jpg  \n",
            " extracting: train/9e943906fba1ec89edfacb2dd7976504_jpg.rf.46907d92bd6aa9bf8f5f8ee5490f8186.jpg  \n",
            " extracting: train/9e943906fba1ec89edfacb2dd7976504_jpg.rf.6e9e4b1b2d5fb537ddde22c5fbbff591.jpg  \n",
            " extracting: train/9e943906fba1ec89edfacb2dd7976504_jpg.rf.eb41f79339eb1eb855a136c400b4a71f.jpg  \n",
            " extracting: train/9fc54a45feb5b01db8f6828d181fb075_jpg.rf.95558424f2db7361bbdb93e8e51e0581.jpg  \n",
            " extracting: train/9fc54a45feb5b01db8f6828d181fb075_jpg.rf.9c25b91d55b315043a095051fe813a9c.jpg  \n",
            " extracting: train/9fc54a45feb5b01db8f6828d181fb075_jpg.rf.dad9895160ce142893f2d50985161176.jpg  \n",
            " extracting: train/IMG_0166_JPG.rf.1b943996d63e88f793c9225b051e88aa.jpg  \n",
            " extracting: train/IMG_0166_JPG.rf.5496677843330113f25e1d96d9e5501c.jpg  \n",
            " extracting: train/IMG_0166_JPG.rf.866e83ca31acd30da2673fcb7e2abbfe.jpg  \n",
            " extracting: train/IMG_0167_JPG.rf.51e844ec48d744ea0d541c3978e68c8f.jpg  \n",
            " extracting: train/IMG_0167_JPG.rf.5ef94865f654a98f644c83ec15c0c7f0.jpg  \n",
            " extracting: train/IMG_0167_JPG.rf.700e471552dde4992d80e528387e102f.jpg  \n",
            " extracting: train/IMG_0291_JPG.rf.0c3ecbe3fa43d54ee4fbee9f4be3c957.jpg  \n",
            " extracting: train/IMG_0291_JPG.rf.d2ba6353082aa25c15708824c08dfb27.jpg  \n",
            " extracting: train/IMG_0291_JPG.rf.df9096730aa1a08ad2999bcd27d3ce48.jpg  \n",
            " extracting: train/IMG_0292_JPG.rf.430049672fd781b9df9e34badf1b48a8.jpg  \n",
            " extracting: train/IMG_0292_JPG.rf.5eba9597d38f1d22018bb5d619ef742e.jpg  \n",
            " extracting: train/IMG_0292_JPG.rf.baaccc7cf58cb3b0c9d1bc3f1ce32a3d.jpg  \n",
            " extracting: train/IMG_0294_JPG.rf.517f9201b72a4266d46b2954a0f80c14.jpg  \n",
            " extracting: train/IMG_0294_JPG.rf.bd8d20acd3d837e056c6714500e83270.jpg  \n",
            " extracting: train/IMG_0294_JPG.rf.cb349f708d70f8f46097636ec55f5419.jpg  \n",
            " extracting: train/IMG_0295_JPG.rf.282c3259eadee31b6cfd1548f0aa4e6d.jpg  \n",
            " extracting: train/IMG_0295_JPG.rf.32f999d96696f80ebe62ade6437b2fe2.jpg  \n",
            " extracting: train/IMG_0295_JPG.rf.939fab6c2495e85e1b177306373fbe6e.jpg  \n",
            " extracting: train/IMG_0296_JPG.rf.530c25c318deab34b53cadb7918fa500.jpg  \n",
            " extracting: train/IMG_0296_JPG.rf.e8332a65a587b3f337f25bca237988af.jpg  \n",
            " extracting: train/IMG_0296_JPG.rf.fe6246bc705bb866f527a6ae2efb1b99.jpg  \n",
            " extracting: train/IMG_0297_JPG.rf.47e3984909ef5581659ae1a350978094.jpg  \n",
            " extracting: train/IMG_0297_JPG.rf.5e635cca1323148499732eaf858ba2b2.jpg  \n",
            " extracting: train/IMG_0297_JPG.rf.a66ff62117c20eb55204281f042b32c7.jpg  \n",
            " extracting: train/IMG_0298_JPG.rf.5b5e7dd4118e128457567019a928e264.jpg  \n",
            " extracting: train/IMG_0298_JPG.rf.6d6ac51367b303c05c261e7e8b11de67.jpg  \n",
            " extracting: train/IMG_0298_JPG.rf.c72da1b09a38ec0adab3af9bb3abc0c1.jpg  \n",
            " extracting: train/IMG_0299_JPG.rf.4d6c7558e7fd08da45a6fabde3296e5b.jpg  \n",
            " extracting: train/IMG_0299_JPG.rf.9f796e9ea3695af07f61b110f53ee45f.jpg  \n",
            " extracting: train/IMG_0299_JPG.rf.ae4ab20b4db16431416f89b8d9582906.jpg  \n",
            " extracting: train/IMG_0317_JPG.rf.00207d2fe8c0a0f20715333d49d22b4f.jpg  \n",
            " extracting: train/IMG_0317_JPG.rf.b4f86e6c57fca84c485b3bbcde731959.jpg  \n",
            " extracting: train/IMG_0317_JPG.rf.c4575757a6e19ad9fb88d28b1a15193e.jpg  \n",
            " extracting: train/IMG_0318_JPG.rf.60de6e8f2c9365770ed11379dfd1cb55.jpg  \n",
            " extracting: train/IMG_0318_JPG.rf.8d091ab4bbe2cd70b92ad64592315ac8.jpg  \n",
            " extracting: train/IMG_0318_JPG.rf.f752cb565b0c634895506816ba026b7e.jpg  \n",
            " extracting: train/_annotations.txt  \n",
            " extracting: train/_classes.txt      \n",
            " extracting: train/a20eb4bb3cea2e394cfcf9ed969b628e_jpg.rf.44943c777028499045c1f45216838729.jpg  \n",
            " extracting: train/a20eb4bb3cea2e394cfcf9ed969b628e_jpg.rf.7e25c324029c6bddd1375645580f3009.jpg  \n",
            " extracting: train/a20eb4bb3cea2e394cfcf9ed969b628e_jpg.rf.8e7941154e8218bc5c60a42ec75cfbf3.jpg  \n",
            " extracting: train/a4028b2361ce7ead654a86b07ac39d52_jpg.rf.55bd810c2826cd5fbda470f36df47735.jpg  \n",
            " extracting: train/a4028b2361ce7ead654a86b07ac39d52_jpg.rf.687ddaa40b48884e559d3606486fa7e8.jpg  \n",
            " extracting: train/a4028b2361ce7ead654a86b07ac39d52_jpg.rf.f18fa4c1dce2f0387c451354d1e535c0.jpg  \n",
            " extracting: train/a4ebf4c268d80c4fe329331ea981b3a1_jpg.rf.12e469ca411a793fab88746c49f8f790.jpg  \n",
            " extracting: train/a4ebf4c268d80c4fe329331ea981b3a1_jpg.rf.31a38518592003e6e81426d0090bd58a.jpg  \n",
            " extracting: train/a4ebf4c268d80c4fe329331ea981b3a1_jpg.rf.f2ae1ea570213bb9acdec41a1a6bcd09.jpg  \n",
            " extracting: train/a5c65b40e0be3480c0ecfacaab399a87_jpg.rf.6147a8d031e8344d640e447c4ba2dbb9.jpg  \n",
            " extracting: train/a5c65b40e0be3480c0ecfacaab399a87_jpg.rf.647ac6c3b9611f89b1a7a757f7051b9f.jpg  \n",
            " extracting: train/a5c65b40e0be3480c0ecfacaab399a87_jpg.rf.d1364905ffdbf3466eff747cf5948b36.jpg  \n",
            " extracting: train/a8847f8fe8eaaa1c97bf83027a901760_jpg.rf.69b91785d4aea8f4199f9c847b918428.jpg  \n",
            " extracting: train/a8847f8fe8eaaa1c97bf83027a901760_jpg.rf.6df2ccc6498e99df8337ffb8ab9c488a.jpg  \n",
            " extracting: train/a8847f8fe8eaaa1c97bf83027a901760_jpg.rf.cb0f3b1463e92615083e75629be7c4ee.jpg  \n",
            " extracting: train/a932287da44b9dfacd0d16a5c1d27923_jpg.rf.76d1125d6c63d8f0206bfcbd6dc6df99.jpg  \n",
            " extracting: train/a932287da44b9dfacd0d16a5c1d27923_jpg.rf.d75b9b5fea5a4c7e5b066d3caae98f9b.jpg  \n",
            " extracting: train/a932287da44b9dfacd0d16a5c1d27923_jpg.rf.e6af160c98e230c8130c17ccd6787efa.jpg  \n",
            " extracting: train/a9768de3fceeeae2618f362870fb9a88_jpg.rf.07e7239539431dfa4ad1282152ccad21.jpg  \n",
            " extracting: train/a9768de3fceeeae2618f362870fb9a88_jpg.rf.444b950f0b329aa6e7ed17a86383606d.jpg  \n",
            " extracting: train/a9768de3fceeeae2618f362870fb9a88_jpg.rf.ef561195bb5bb73478b957d2958db087.jpg  \n",
            " extracting: train/a9987cf6cc5c6545818ec294d4a5bb9b_jpg.rf.562eed600b4725f0697896672ae6ddb2.jpg  \n",
            " extracting: train/a9987cf6cc5c6545818ec294d4a5bb9b_jpg.rf.7d8b64ebafca42e4a7e4594d41700858.jpg  \n",
            " extracting: train/a9987cf6cc5c6545818ec294d4a5bb9b_jpg.rf.ecb9987509a91f5df7b6dd308fb5edb8.jpg  \n",
            " extracting: train/b0f3d66c8be13f5f6aa25b67a06bdcfa_jpg.rf.2400a74d8ca898058bbfa7a4b2fad3ed.jpg  \n",
            " extracting: train/b0f3d66c8be13f5f6aa25b67a06bdcfa_jpg.rf.be26c1b3f90ad3ce201f81d39ce2c7a3.jpg  \n",
            " extracting: train/b0f3d66c8be13f5f6aa25b67a06bdcfa_jpg.rf.e2479f30377a357d8c2d24488c666a98.jpg  \n",
            " extracting: train/b3b002461f1c6b432e22964549767e5f_jpg.rf.89c6cd251768bebd0f1f27ffa57a4350.jpg  \n",
            " extracting: train/b3b002461f1c6b432e22964549767e5f_jpg.rf.a0d7beba87e87043554e0885b9b86897.jpg  \n",
            " extracting: train/b3b002461f1c6b432e22964549767e5f_jpg.rf.b2ec1cf3b8d3d761e56314df208ff584.jpg  \n",
            " extracting: train/b5102d7f9740eee7754ed268becb2163_jpg.rf.1753afe30d3a07555d21ff985d2b38e9.jpg  \n",
            " extracting: train/b5102d7f9740eee7754ed268becb2163_jpg.rf.91e588905afe5d7d801eda5ca9dcd21e.jpg  \n",
            " extracting: train/b5102d7f9740eee7754ed268becb2163_jpg.rf.b40f1fbd9b2855b7fa5234eb32c8bb15.jpg  \n",
            " extracting: train/b5bcde459ca36f0d1f3c20e751336672_jpg.rf.22bea80464ccb6e4d31ab5c10d11c0f9.jpg  \n",
            " extracting: train/b5bcde459ca36f0d1f3c20e751336672_jpg.rf.aaa30a1910b6b485f2feb1daeaac3bde.jpg  \n",
            " extracting: train/b5bcde459ca36f0d1f3c20e751336672_jpg.rf.bcad4ddc397a9e93e8f5049dc7d2ac20.jpg  \n",
            " extracting: train/b79ae5b70de58089ead6e32b235e30d3_jpg.rf.70249336c8f66aeb7cd2c808d7e0a255.jpg  \n",
            " extracting: train/b79ae5b70de58089ead6e32b235e30d3_jpg.rf.df8a88cab326fc33376d82c562d0b45f.jpg  \n",
            " extracting: train/b79ae5b70de58089ead6e32b235e30d3_jpg.rf.e843446cbb3275d85d46432364a2d867.jpg  \n",
            " extracting: train/b7a8c7de4fe1382d69f58ac97e819b5c_jpg.rf.3c92a450faed773b5607e082e798c7fa.jpg  \n",
            " extracting: train/b7a8c7de4fe1382d69f58ac97e819b5c_jpg.rf.a896caf123ecc925575d9922df742758.jpg  \n",
            " extracting: train/b7a8c7de4fe1382d69f58ac97e819b5c_jpg.rf.d9033064a02df12bad0b60bda98b1ff6.jpg  \n",
            " extracting: train/bb54af2f0b83b174aecc29328c8fa001_jpg.rf.6023d601e15572d6990554f644bb1bfe.jpg  \n",
            " extracting: train/bb54af2f0b83b174aecc29328c8fa001_jpg.rf.905a8ad083e59c277bca2ebd076a9ad1.jpg  \n",
            " extracting: train/bb54af2f0b83b174aecc29328c8fa001_jpg.rf.a95d3e7492be3741322db734980e4372.jpg  \n",
            " extracting: train/bc5decab88861286dcf78a367b4377cb_jpg.rf.118253b02b72c34a332d2bd78746c795.jpg  \n",
            " extracting: train/bc5decab88861286dcf78a367b4377cb_jpg.rf.88da334f69a7c36333bc65576f4ffdfe.jpg  \n",
            " extracting: train/bc5decab88861286dcf78a367b4377cb_jpg.rf.a4fe058da39ab9ff0b210ff464124bb2.jpg  \n",
            " extracting: train/beb11566e59775b61f0ca369952067cc_jpg.rf.56493b995a4c4ae16d241c7e1120a53e.jpg  \n",
            " extracting: train/beb11566e59775b61f0ca369952067cc_jpg.rf.5d2e0331a1ac2070a72fc4c12a036f53.jpg  \n",
            " extracting: train/beb11566e59775b61f0ca369952067cc_jpg.rf.f912967037a2c28db9c37a7564017dd4.jpg  \n",
            " extracting: train/c0d68e012bb93c14bc333fc1d5e52621_jpg.rf.1644855d8e7c4e07a615e02cdd6eb550.jpg  \n",
            " extracting: train/c0d68e012bb93c14bc333fc1d5e52621_jpg.rf.7a3c7ca8c5ccc4d7b307f188bbfb0c85.jpg  \n",
            " extracting: train/c0d68e012bb93c14bc333fc1d5e52621_jpg.rf.fea60abd21071433619d9002cac1d6c5.jpg  \n",
            " extracting: train/c3e9e81ba1540aae7961a4d8d96600ba_jpg.rf.159b3ae18cb81620929e5e4847ab9ed8.jpg  \n",
            " extracting: train/c3e9e81ba1540aae7961a4d8d96600ba_jpg.rf.32f7438c342e397838be8189c204446f.jpg  \n",
            " extracting: train/c3e9e81ba1540aae7961a4d8d96600ba_jpg.rf.d0ef355e121a971f315ab22160109b11.jpg  \n",
            " extracting: train/c46bf04050a2a9323dfe563e8813602f_jpg.rf.2bce3ad335a7be28858cd00cb3f40567.jpg  \n",
            " extracting: train/c46bf04050a2a9323dfe563e8813602f_jpg.rf.3c67770c7bc1ae2f34811acc4fea44c1.jpg  \n",
            " extracting: train/c46bf04050a2a9323dfe563e8813602f_jpg.rf.ff5a4cfb28be5ab4636539e081efb107.jpg  \n",
            " extracting: train/c733616ab773817dd1a356dbbdf2ee33_jpg.rf.8bc96d3c3f94c91defbbb399aeb94bd0.jpg  \n",
            " extracting: train/c733616ab773817dd1a356dbbdf2ee33_jpg.rf.8c2d39cca659bfec090ee10dd8062ef5.jpg  \n",
            " extracting: train/c733616ab773817dd1a356dbbdf2ee33_jpg.rf.f0637765e389d17285e20d9e98d707bf.jpg  \n",
            " extracting: train/c76c79e40bd9839a05237934cfa89ca3_jpg.rf.1bc63c348e985893973dea8fa15569ad.jpg  \n",
            " extracting: train/c76c79e40bd9839a05237934cfa89ca3_jpg.rf.9a8aff67f0474c909c78cb647d887169.jpg  \n",
            " extracting: train/c76c79e40bd9839a05237934cfa89ca3_jpg.rf.dee57a5076074452c76467e0c19d0ae3.jpg  \n",
            " extracting: train/c7890b749d14d3488066cbdfac4620fd_jpg.rf.1efa9f080f6e933d2f5831041808e244.jpg  \n",
            " extracting: train/c7890b749d14d3488066cbdfac4620fd_jpg.rf.257e75b14b6cfba7dfa565acc4e09aee.jpg  \n",
            " extracting: train/c7890b749d14d3488066cbdfac4620fd_jpg.rf.76f2ad22e2a1c25bc8df3e234a2875e4.jpg  \n",
            " extracting: train/ca869123d8a0cbcc6e54f4a445e5a78a_jpg.rf.1b0eec370b291dd2002d949abe4d9786.jpg  \n",
            " extracting: train/ca869123d8a0cbcc6e54f4a445e5a78a_jpg.rf.5a9d4bcaf2ccf730c794bb7d57d77524.jpg  \n",
            " extracting: train/ca869123d8a0cbcc6e54f4a445e5a78a_jpg.rf.cb3d9d5a5fd961cfb91b7cb00efeab83.jpg  \n",
            " extracting: train/cae099fe41d6aa30033d71e433c33c8d_jpg.rf.2c5556b5ec9b5e12bef8a8135dbd3db6.jpg  \n",
            " extracting: train/cae099fe41d6aa30033d71e433c33c8d_jpg.rf.4a845b5a7d4639700ca427c1099a1acc.jpg  \n",
            " extracting: train/cae099fe41d6aa30033d71e433c33c8d_jpg.rf.e244d328c4a1dc04bdd511daa54a5bcb.jpg  \n",
            " extracting: train/ce54969567273b9b8a275812ff56e16c_jpg.rf.29c743680e34c742cc77893515011b9e.jpg  \n",
            " extracting: train/ce54969567273b9b8a275812ff56e16c_jpg.rf.9dcc1b3107606542dc0633cbc7ff5026.jpg  \n",
            " extracting: train/ce54969567273b9b8a275812ff56e16c_jpg.rf.c314f1d0e3f3e5009805961ff05a7934.jpg  \n",
            " extracting: train/cf2784fa97151d5316b2961b1e62dc45_jpg.rf.5d084fce203d3441c10c50c670717b07.jpg  \n",
            " extracting: train/cf2784fa97151d5316b2961b1e62dc45_jpg.rf.5e86f14e3c821254e4afac25e3ade2b1.jpg  \n",
            " extracting: train/cf2784fa97151d5316b2961b1e62dc45_jpg.rf.fe672984de7dabfff5b9cde323862f11.jpg  \n",
            " extracting: train/d079f4e77b2445abceca7534356db743_jpg.rf.15980e0041c274dd182fc8a6bdd25047.jpg  \n",
            " extracting: train/d079f4e77b2445abceca7534356db743_jpg.rf.86f033e983acf1e547451e03dee0e582.jpg  \n",
            " extracting: train/d079f4e77b2445abceca7534356db743_jpg.rf.e7fc6fdfea0d14dc4c82a6068b9e4159.jpg  \n",
            " extracting: train/d0cc2420bce5b14dfd39e55dc3737e57_jpg.rf.798223ce68149c49db97b6936b162fea.jpg  \n",
            " extracting: train/d0cc2420bce5b14dfd39e55dc3737e57_jpg.rf.88c1e9b2ecc41404c643afeae66588e3.jpg  \n",
            " extracting: train/d0cc2420bce5b14dfd39e55dc3737e57_jpg.rf.a1e5deac03ed76b34211a0db4f49de60.jpg  \n",
            " extracting: train/d29148a2233950a7777285281cbfccff_jpg.rf.20e8ed774b4d58497375cf75613ce12f.jpg  \n",
            " extracting: train/d29148a2233950a7777285281cbfccff_jpg.rf.40093760ef1ab3612d0c64743229660a.jpg  \n",
            " extracting: train/d29148a2233950a7777285281cbfccff_jpg.rf.ac8323d05a30dae895f9f6b84d20ea68.jpg  \n",
            " extracting: train/d33c33de41dbe1a95a43212c58fd12b7_jpg.rf.39ad6f496db1c7983d23577c21d6b498.jpg  \n",
            " extracting: train/d33c33de41dbe1a95a43212c58fd12b7_jpg.rf.97eb2e7fe56237be37aa16911f677084.jpg  \n",
            " extracting: train/d33c33de41dbe1a95a43212c58fd12b7_jpg.rf.b8aeaddf76563fcb8e403f431c8f746f.jpg  \n",
            " extracting: train/d3a4e1b8f13ef89f419251f5c5839d0d_jpg.rf.0eac09b57ab66fc36635004e7f2124de.jpg  \n",
            " extracting: train/d3a4e1b8f13ef89f419251f5c5839d0d_jpg.rf.12d1445a2e7628e803d679154eafd783.jpg  \n",
            " extracting: train/d3a4e1b8f13ef89f419251f5c5839d0d_jpg.rf.52991bd24deab85602f52dda5aca25d4.jpg  \n",
            " extracting: train/d415969922564f317be0d1433330626f_jpg.rf.28d3ae6c7470773e33b2e1d8ab45d13b.jpg  \n",
            " extracting: train/d415969922564f317be0d1433330626f_jpg.rf.5bc5eaf797dffc2a83bca91da5ebcd80.jpg  \n",
            " extracting: train/d415969922564f317be0d1433330626f_jpg.rf.ea52055e8d217e2f8c5f785c5b114aea.jpg  \n",
            " extracting: train/d494cb268ad7f9f55587de138edc1dc4_jpg.rf.0b7a384e3d2d7cd15c45edce54fd465a.jpg  \n",
            " extracting: train/d494cb268ad7f9f55587de138edc1dc4_jpg.rf.1225ba2bab92010c41fd82111da127c5.jpg  \n",
            " extracting: train/d494cb268ad7f9f55587de138edc1dc4_jpg.rf.3b871f28d54bdb72507fb3451f231850.jpg  \n",
            " extracting: train/d67b5b9e900409b050dd9bd594f90709_jpg.rf.4ee38829bdf99d869ea4efb62d7b268f.jpg  \n",
            " extracting: train/d67b5b9e900409b050dd9bd594f90709_jpg.rf.c8f40141d74f9737a0979fb96b6f34d2.jpg  \n",
            " extracting: train/d67b5b9e900409b050dd9bd594f90709_jpg.rf.d4b4698f0544628c496bee35512f21e2.jpg  \n",
            " extracting: train/d795f84f39716798482fb2937868ed8a_jpg.rf.3eb9d5c21be9982bc0438b394988ec12.jpg  \n",
            " extracting: train/d795f84f39716798482fb2937868ed8a_jpg.rf.62de48b291ec4dab492ffd28d07e46e2.jpg  \n",
            " extracting: train/d795f84f39716798482fb2937868ed8a_jpg.rf.cad9a430bd9734f8a4d5a7bbefe008db.jpg  \n",
            " extracting: train/d9acc69c5d57623cda22786e309201c9_jpg.rf.163bbc086efbf7cedbb02c4b36c83a28.jpg  \n",
            " extracting: train/d9acc69c5d57623cda22786e309201c9_jpg.rf.5ee63a61ee05ff129fdbccefc3a0162e.jpg  \n",
            " extracting: train/d9acc69c5d57623cda22786e309201c9_jpg.rf.68535cd44500e60be8d5d02bc2ff3c71.jpg  \n",
            " extracting: train/dd6b5c3cb2d7e77f38f1dfeb2bff0431_jpg.rf.9a8ea23dbdf192fee0434dbb0eb0f22c.jpg  \n",
            " extracting: train/dd6b5c3cb2d7e77f38f1dfeb2bff0431_jpg.rf.cc1ce4e567e8abf653acf2434e59ebdf.jpg  \n",
            " extracting: train/dd6b5c3cb2d7e77f38f1dfeb2bff0431_jpg.rf.d5e6c00de132b8eb8ba382332327fb37.jpg  \n",
            " extracting: train/ddad9dc4d945006d66f5349d64498559_jpg.rf.36d31b7cdbbe48577906109fa1edf766.jpg  \n",
            " extracting: train/ddad9dc4d945006d66f5349d64498559_jpg.rf.48e7a4d1dbc55402801f6f3eb2515561.jpg  \n",
            " extracting: train/ddad9dc4d945006d66f5349d64498559_jpg.rf.4a027c535d57e5c9ec84c9180a32c196.jpg  \n",
            " extracting: train/de60ba81aa78387928e4bdc11f3be301_jpg.rf.6681071e793fdbd2f46b2f15c20db879.jpg  \n",
            " extracting: train/de60ba81aa78387928e4bdc11f3be301_jpg.rf.a7cd83b2e02587367bb3305dbda0b78b.jpg  \n",
            " extracting: train/de60ba81aa78387928e4bdc11f3be301_jpg.rf.d5ff9b3d612bf126db5f6959d6bf5cee.jpg  \n",
            " extracting: train/e40003d4bbcdac7196b9502bfe2fb6ed_jpg.rf.b847f770b71b7f853198176ef25b8516.jpg  \n",
            " extracting: train/e40003d4bbcdac7196b9502bfe2fb6ed_jpg.rf.d6bf64a0bd417c7ffc6c45fc60fb02a5.jpg  \n",
            " extracting: train/e40003d4bbcdac7196b9502bfe2fb6ed_jpg.rf.fff02b8d5496821ff5b6def111287362.jpg  \n",
            " extracting: train/e6e3a2ff2c75970490079f00136885ad_jpg.rf.196dbeb361aea01da0d89796ee64e56b.jpg  \n",
            " extracting: train/e6e3a2ff2c75970490079f00136885ad_jpg.rf.a604bf09d249b5f66896ab2dbadd1a85.jpg  \n",
            " extracting: train/e6e3a2ff2c75970490079f00136885ad_jpg.rf.bf5f02039da79608e7ba637b0f18b8dc.jpg  \n",
            " extracting: train/e79deba8fe520409790b601ad61da4ee_jpg.rf.4d07e4475f01148efb81bd6fa74b14ea.jpg  \n",
            " extracting: train/e79deba8fe520409790b601ad61da4ee_jpg.rf.83a6e8ba2d0d752b3ab81886c1c838bf.jpg  \n",
            " extracting: train/e79deba8fe520409790b601ad61da4ee_jpg.rf.c5ace9198f249698fecd9cd44699ad3e.jpg  \n",
            " extracting: train/e8480d7fb9881d8a0e88b7be4d103f6d_jpg.rf.45bdf3534f70d8ac1475f0521b4480b0.jpg  \n",
            " extracting: train/e8480d7fb9881d8a0e88b7be4d103f6d_jpg.rf.928686545c1fc6e46d2b584750b57d37.jpg  \n",
            " extracting: train/e8480d7fb9881d8a0e88b7be4d103f6d_jpg.rf.f5a8297fdaadf713f5aa50520a5aae2f.jpg  \n",
            " extracting: train/ea799d77875c399618c45cd9409f34ee_jpg.rf.20f1e302ce66ba51ba16dd954123378d.jpg  \n",
            " extracting: train/ea799d77875c399618c45cd9409f34ee_jpg.rf.3cbbfad204c76abb175b51ac851c1b6b.jpg  \n",
            " extracting: train/ea799d77875c399618c45cd9409f34ee_jpg.rf.73793ae5eedc9e1a2ec843305741e27c.jpg  \n",
            " extracting: train/eb9e7928e756c3cf9164e7afc08c4653_jpg.rf.268e96829cc026a5763f0182c1e8b842.jpg  \n",
            " extracting: train/eb9e7928e756c3cf9164e7afc08c4653_jpg.rf.746289ad0d0f3f589717876a2b835faa.jpg  \n",
            " extracting: train/eb9e7928e756c3cf9164e7afc08c4653_jpg.rf.7f6a60da5223783cc3525b307708142a.jpg  \n",
            " extracting: train/ec4c30d88ecc70b6a3e76dbd9b17324a_jpg.rf.334f863b8bb588cb413d6f23e5c572e3.jpg  \n",
            " extracting: train/ec4c30d88ecc70b6a3e76dbd9b17324a_jpg.rf.a3a828973a59e98475fa9d4c9b3bc6b0.jpg  \n",
            " extracting: train/ec4c30d88ecc70b6a3e76dbd9b17324a_jpg.rf.aaf770cf8e03c34de0727104563ac2ee.jpg  \n",
            " extracting: train/ec5ab1930d6aa16fff2582b48f82cada_jpg.rf.9ed7a8384c58e621e1bd8d199c9911eb.jpg  \n",
            " extracting: train/ec5ab1930d6aa16fff2582b48f82cada_jpg.rf.a4317db23e4c499293ae36f9fd900360.jpg  \n",
            " extracting: train/ec5ab1930d6aa16fff2582b48f82cada_jpg.rf.aae26a4e7732a2ecb663aca13ca5e2be.jpg  \n",
            " extracting: train/edd285915356686fb53fb52c1ded0e53_jpg.rf.575ba04e0fde0ae4a7556799951ffb28.jpg  \n",
            " extracting: train/edd285915356686fb53fb52c1ded0e53_jpg.rf.c889f2395a10814f1b3bc7c2eff34762.jpg  \n",
            " extracting: train/edd285915356686fb53fb52c1ded0e53_jpg.rf.db25cbd151cf96bddaea8e570c74aa8a.jpg  \n",
            " extracting: train/ef1d425fd5370fbf8b7adea43b755304_jpg.rf.098e333d5b6303fdc9c280fbaf5a79c4.jpg  \n",
            " extracting: train/ef1d425fd5370fbf8b7adea43b755304_jpg.rf.c511c91a1669993209db75e7013631ba.jpg  \n",
            " extracting: train/ef1d425fd5370fbf8b7adea43b755304_jpg.rf.f7787e4a869bce3acd75d98f934e857e.jpg  \n",
            " extracting: train/f02d615907c77dc15f02bd1372e4398f_jpg.rf.30b6af213aeb1691056f9bdf8c568ffc.jpg  \n",
            " extracting: train/f02d615907c77dc15f02bd1372e4398f_jpg.rf.8557a2e6c1a157a570333dd454271cb0.jpg  \n",
            " extracting: train/f02d615907c77dc15f02bd1372e4398f_jpg.rf.ba5c8eb326916870dab8aeef50cd91ec.jpg  \n",
            " extracting: train/f041d3171dfe3137390c85fc5437e447_jpg.rf.3020fee02bc4def16c99bed406ad8671.jpg  \n",
            " extracting: train/f041d3171dfe3137390c85fc5437e447_jpg.rf.594627e68a410fbed5266fde10811a18.jpg  \n",
            " extracting: train/f041d3171dfe3137390c85fc5437e447_jpg.rf.a4744a0326d7d31d016563fd0ab94aea.jpg  \n",
            " extracting: train/f1ea0167087976926d4fe0aa36b961ce_jpg.rf.792c747c6116ade848581cd7c6be27e2.jpg  \n",
            " extracting: train/f1ea0167087976926d4fe0aa36b961ce_jpg.rf.7cfb591bdf3cb30001cfecb3b153724e.jpg  \n",
            " extracting: train/f1ea0167087976926d4fe0aa36b961ce_jpg.rf.afe8570c46a7a9651d7353b8f753e9c7.jpg  \n",
            " extracting: train/f2672cdc28767484b556da3ab6f1003e_jpg.rf.1e58ffa93dd27f57436a6b49d82d98e7.jpg  \n",
            " extracting: train/f2672cdc28767484b556da3ab6f1003e_jpg.rf.3509d0a9193d954d2cef5fc1371760c4.jpg  \n",
            " extracting: train/f2672cdc28767484b556da3ab6f1003e_jpg.rf.eb54d003a3fad58875432fdfef1764bc.jpg  \n",
            " extracting: train/f3302c754c6fd42130014199ee327d10_jpg.rf.5a539486e56c8a43d6c4eb79bf8390cf.jpg  \n",
            " extracting: train/f3302c754c6fd42130014199ee327d10_jpg.rf.ac1176b46e92b65a435b4c64bde17da7.jpg  \n",
            " extracting: train/f3302c754c6fd42130014199ee327d10_jpg.rf.f184e1e646cf33f3fa880c05ab94984c.jpg  \n",
            " extracting: train/f3a5df526393445c6e2d38f66c1f5c27_jpg.rf.30434c68a81ca711cc012fba179621fb.jpg  \n",
            " extracting: train/f3a5df526393445c6e2d38f66c1f5c27_jpg.rf.4318c9a5d50fd309db266f4e848a1202.jpg  \n",
            " extracting: train/f3a5df526393445c6e2d38f66c1f5c27_jpg.rf.7313c3f78aaf7e508f685612f68538c7.jpg  \n",
            " extracting: train/f52e1873b8583f8bf4f7ddf6e9649f07_jpg.rf.2537eb51bebf5c74c4bd317859fdeae6.jpg  \n",
            " extracting: train/f52e1873b8583f8bf4f7ddf6e9649f07_jpg.rf.501bcfa0d1fb2050080a5caa9ce7ee07.jpg  \n",
            " extracting: train/f52e1873b8583f8bf4f7ddf6e9649f07_jpg.rf.f49dc0690959dadeb1524da1a3cb38f7.jpg  \n",
            " extracting: train/f587402be410b424bcbbac06e1dc6162_jpg.rf.23f779c5fef0d59e809103bf5bd3b7a3.jpg  \n",
            " extracting: train/f587402be410b424bcbbac06e1dc6162_jpg.rf.b4179f89a43522928b4423c1bf422e3e.jpg  \n",
            " extracting: train/f587402be410b424bcbbac06e1dc6162_jpg.rf.e827e0b68851bce5ae35b7bc5e7c0c4e.jpg  \n",
            " extracting: train/f9a9a175f26d4b26bca3a5338cc1405e_jpg.rf.1bfc00ef85611686b0566f4ea49a4c9f.jpg  \n",
            " extracting: train/f9a9a175f26d4b26bca3a5338cc1405e_jpg.rf.3260d2b6441db8b3e01beb6e26540341.jpg  \n",
            " extracting: train/f9a9a175f26d4b26bca3a5338cc1405e_jpg.rf.d028744643f733777684eace4ef99cd6.jpg  \n",
            " extracting: train/fa3cf2724c1648a8822b59ac0759475f_jpg.rf.2503a3b4a48386cdce9d069893234e2b.jpg  \n",
            " extracting: train/fa3cf2724c1648a8822b59ac0759475f_jpg.rf.577379a932d9dff33794eba38ee6340d.jpg  \n",
            " extracting: train/fa3cf2724c1648a8822b59ac0759475f_jpg.rf.89df60eac6ac5c0f593914ab045233d0.jpg  \n",
            " extracting: train/fa4e2b9a8cf58f405f69a56c662834f2_jpg.rf.29021f89f2a16c44ecb9f34623bd3a9a.jpg  \n",
            " extracting: train/fa4e2b9a8cf58f405f69a56c662834f2_jpg.rf.97f7416f560f73f366f58f69446c9287.jpg  \n",
            " extracting: train/fa4e2b9a8cf58f405f69a56c662834f2_jpg.rf.d612185e16b2f1e8680764ed00dd4711.jpg  \n",
            " extracting: train/fb586797e8ad818c7e3e3a6411f73d84_jpg.rf.57db9c805851d5fdc9e3a5f28e9717bb.jpg  \n",
            " extracting: train/fb586797e8ad818c7e3e3a6411f73d84_jpg.rf.85d8f5b9e28cd8b994d730f9e135ab6d.jpg  \n",
            " extracting: train/fb586797e8ad818c7e3e3a6411f73d84_jpg.rf.ed5a5085ee7d3245a50079b0e080ab12.jpg  \n",
            " extracting: train/fc9d7bc0453cb3324406401c00224d30_jpg.rf.172aecee627f7179de58fbbc01d619f8.jpg  \n",
            " extracting: train/fc9d7bc0453cb3324406401c00224d30_jpg.rf.d5b9739fe980fcc412eb535b6d177524.jpg  \n",
            " extracting: train/fc9d7bc0453cb3324406401c00224d30_jpg.rf.e9e48a12d9bcbcb2a03df0571e7617b6.jpg  \n",
            "   creating: valid/\n",
            " extracting: valid/05ad7223827a29a8283f6c4b2490f52f_jpg.rf.7c134acea5ef5e18aa75defc069dc1ee.jpg  \n",
            " extracting: valid/0b2252c93c53e1b2e61d485b22328e2e_jpg.rf.0a885b88adc72caa71b0aa0ec20b863e.jpg  \n",
            " extracting: valid/0c09b79cff39932c59ecc745dd827906_jpg.rf.dd62f1f1d28dd2209e0cfe61288f6438.jpg  \n",
            " extracting: valid/0d9afc3d23392c3958f53d7fe71fd2f1_jpg.rf.ca639b6fd216ff59ed8fd5572c13985f.jpg  \n",
            " extracting: valid/15cc23c777b00d0e123f9df468f2852b_jpg.rf.ec883ea8696547433314cdd8f2c177bf.jpg  \n",
            " extracting: valid/18742c87a03866e042c5659ba04d1180_jpg.rf.ec846d30e3eebb02abb8056342b9de32.jpg  \n",
            " extracting: valid/1b7c1c9570e900f75eb974f99cbb3c60_jpg.rf.ec7b31959243b9f7a54b7c3ea89dbce6.jpg  \n",
            " extracting: valid/1be2a621f309c7482e9a79ad5b23ecbe_jpg.rf.e4117f6396582d8058dbd15974e30b04.jpg  \n",
            " extracting: valid/26fa37995fa5b18ec40e0a94e6d91104_jpg.rf.2e6b063142cfe7cbcc21b0a236e5699f.jpg  \n",
            " extracting: valid/302e7c10664be32b4fc000452149027c_jpg.rf.9e3b8da2de02c1fe13ae9b9bf0d28d00.jpg  \n",
            " extracting: valid/31b83afa654d5dd874c3f0111126ab7f_jpg.rf.3b3c671f839cb2dd6a6a21e3f5c5c195.jpg  \n",
            " extracting: valid/3312e3bb60e338e9c1a614f0f8960dd8_jpg.rf.f85b2ac2635f38532147b8c2c8888562.jpg  \n",
            " extracting: valid/33b66ede234715fb46db40b33c4e26c1_jpg.rf.d931a220452e1914ad5a8cf80bdd5b9a.jpg  \n",
            " extracting: valid/3aafc2d38807dddd1b43a54cb70f500d_jpg.rf.ed2b0d06c11e2ecfad6a696932579d82.jpg  \n",
            " extracting: valid/3baf85c957b9d28a16c0b65cb2ef0d29_jpg.rf.712429bc0be682ad0038cbc6beb3fd30.jpg  \n",
            " extracting: valid/3e0c67f38992fe16dfc163f7f5336263_jpg.rf.4a1c5c9f4cfd6b460d9af2d4c7a870bb.jpg  \n",
            " extracting: valid/424d6506342fa2471e71586675ed092c_jpg.rf.bc9f3f76f36c5ba58869c652f918bd12.jpg  \n",
            " extracting: valid/495019998442ddf85b59e387d4916cd3_jpg.rf.3d9dd252951539310c6d9e3db7d3a058.jpg  \n",
            " extracting: valid/4b8f93069270a9f7bb523518a5088b9e_jpg.rf.7d0d7a337008fbfde0ab2c55715e7782.jpg  \n",
            " extracting: valid/55be99616328f83dcbfe8c18e1387c0e_jpg.rf.bb349a21b80bcc7480f4d405a6a3e212.jpg  \n",
            " extracting: valid/578029c06939a788cd5606ad17b49fb9_jpg.rf.4e9ef7a78c1923865c9bdd316a04a31e.jpg  \n",
            " extracting: valid/57d1d1fb35ed875f9e770660bb03b6d7_jpg.rf.35a16500fc22fb8c6e59b86172462258.jpg  \n",
            " extracting: valid/5c19d3260762f5daa632d952bc0074d6_jpg.rf.250c45a5fed7c606ee8fe28810a219a2.jpg  \n",
            " extracting: valid/64061fd2e0e35bdf9ac4681eddf5fa2a_jpg.rf.507d0638d0f0eabeb8c7227bb0041d0c.jpg  \n",
            " extracting: valid/6859628a422c1b72be8b074841cd943e_jpg.rf.968f3643f5879a632d14b7707ee9ae3a.jpg  \n",
            " extracting: valid/6a41b6c8201604216ad196f842c6a2c6_jpg.rf.60a06c4ff4af59f4f5f269361528d41d.jpg  \n",
            " extracting: valid/6e2dd4604b3a51d9be11b8809ed03803_jpg.rf.f1371efe107cc6d72c36f2b5d4702d66.jpg  \n",
            " extracting: valid/73e6a751c50604d017541c11b28d8417_jpg.rf.cdbbf1901e916db82ec096334e0306f9.jpg  \n",
            " extracting: valid/793c79d55c8a252b7a954d074b1d6498_jpg.rf.7ce67d4997eb368ce3bfea9242c64c22.jpg  \n",
            " extracting: valid/7e862b85e33cd247ed66447d129e5fb4_jpg.rf.7d29881ed3ccce2f9e308e2aa3b20671.jpg  \n",
            " extracting: valid/7e97f49e613a59a70b833e4c0b2c1c04_jpg.rf.4521f7f4426d59e3817609ee10e78393.jpg  \n",
            " extracting: valid/86afe95de5471af5cef08e6ae4d9acbb_jpg.rf.7fab5dee0bfa346e21a5d46fa4735718.jpg  \n",
            " extracting: valid/8ec14357f5f18fb98db86e0283623150_jpg.rf.e596c4a36a89232f3732dc54b8248b78.jpg  \n",
            " extracting: valid/9453c2097cb4ccc676e273939894b3da_jpg.rf.e4bb464448488954193bf6be4f4735bb.jpg  \n",
            " extracting: valid/97ed198b00b5491747d3b425df8e7096_jpg.rf.8a8bce7ab7eabebb86cfb86bd4046c6e.jpg  \n",
            " extracting: valid/IMG_0293_JPG.rf.e208f5cdf5e993c552be7f96e86c4890.jpg  \n",
            " extracting: valid/IMG_0310_JPG.rf.fa4dfa05ea9b136a2afc53556d90adb9.jpg  \n",
            " extracting: valid/IMG_0311_JPG.rf.60bdeddd1d81863f576805705dee0049.jpg  \n",
            " extracting: valid/IMG_0319_JPG.rf.d526046fd4cf10ed7b549a10fa4424eb.jpg  \n",
            " extracting: valid/IMG_0320_JPG.rf.2a69b00c4e2299736c81954089818448.jpg  \n",
            " extracting: valid/_annotations.txt  \n",
            " extracting: valid/_classes.txt      \n",
            " extracting: valid/abd65798d9952a27e087710eb8bddf32_jpg.rf.4c9ed4ea8f55c6b3b1b007060029a15f.jpg  \n",
            " extracting: valid/aec1aa6773dbbe004554f405cdef2bea_jpg.rf.2775fd3d7d8d1dfacea70de121d91437.jpg  \n",
            " extracting: valid/bb0de9761d16eee258ae09d8de32002c_jpg.rf.f97067be0b27db05f0ac03d9d8cb1185.jpg  \n",
            " extracting: valid/c1f800417bc42263d141b5ed785e7707_jpg.rf.f06111d09b042ba2d50e1ec17282bcf4.jpg  \n",
            " extracting: valid/c20ca9283ea51ac7707905894a7da703_jpg.rf.f54294c5288d49c907732317c5702df8.jpg  \n",
            " extracting: valid/c5172afbdad90854b3d0f21a923c0c69_jpg.rf.386387aecfb48c3a8a6650741541186e.jpg  \n",
            " extracting: valid/ca6484c259f286c5bdf1afefc868b753_jpg.rf.eea24b286861e0da208ff0b8eb49e1c9.jpg  \n",
            " extracting: valid/d114edc5cb4cae0ceb2f152afd15f57d_jpg.rf.fa2760e7c7663ed523265248c14b35ea.jpg  \n",
            " extracting: valid/d3b9309d00a2b671407b918ea867a935_jpg.rf.5e1400d76ea181788b7defd2f5d64254.jpg  \n",
            " extracting: valid/d4f7caf01359b9a757c930140f746fad_jpg.rf.888c6dd3e17e20ce9ed6ec4023fec3c0.jpg  \n",
            " extracting: valid/d6e283a49b0395a6d5867c9e98e32045_jpg.rf.78b022c1aa0a30727326b7962789a9aa.jpg  \n",
            " extracting: valid/d9ef98145d7d35393c75a51331a20e2c_jpg.rf.44441521d89767a579e4c3f3ab44d4a8.jpg  \n",
            " extracting: valid/e1616dc9962fed075576ac4ea3553f51_jpg.rf.23145974270bfe4d2f07d2a73ead9923.jpg  \n",
            " extracting: valid/e53bf8a0e692a4ccd5f1dc2bc19e7751_jpg.rf.a8b866893eddbe54b209aa055984e2e6.jpg  \n",
            " extracting: valid/e7edc4f1b8d3cc1069b96d0358e066c9_jpg.rf.6583bdfbb3f6a620fe8776c0d853b09d.jpg  \n",
            " extracting: valid/ec418cafd39d7c5a69cc0642a08b2a08_jpg.rf.5839dd7f1ccc537af7096a6b0bd49c56.jpg  \n",
            " extracting: valid/eca42980852e6c5db10ee84aac23f9c6_jpg.rf.db5f4506ccda27fa11dd4ff5a08c584f.jpg  \n",
            " extracting: valid/fb7d97265a22bb1c1f908dadc6f9e7dc_jpg.rf.c13e9b9b285eb421655b59cef73afe1d.jpg  \n"
          ]
        }
      ],
      "source": [
        "# Paste Roboflow code from snippet here from above to here! eg !curl -L https://app.roboflow.ai/ds/eOSXbt7KWu?key=YOURKEY | jar -x\n",
        "!curl -L https://public.roboflow.com/ds/rNA0QGnC5I?key=Xx0IVwBLzi > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izGzSaeJzqAl",
        "outputId": "f68b1050-1072-49ef-b371-f347b975d3d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "coco_annotation.py  LICENSE              \u001b[0m\u001b[01;34mtest\u001b[0m/                \u001b[01;34mvalid\u001b[0m/             yolov3-tiny.cfg\n",
            "convert.py          \u001b[01;34mmodel_data\u001b[0m/          \u001b[01;34mtrain\u001b[0m/               voc_annotation.py  yolo_video.py\n",
            "darknet53.cfg       README.dataset.txt   train_bottleneck.py  \u001b[01;34myolo3\u001b[0m/\n",
            "\u001b[01;34mfont\u001b[0m/               README.md            train.py             yolo.py\n",
            "kmeans.py           README.roboflow.txt  Tutorial.ipynb       yolov3.cfg\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1PagPopmUIG",
        "outputId": "10f5ad4f-bbe7-42eb-f079-bf3e9ab02b9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/keras-yolo3/train\n"
          ]
        }
      ],
      "source": [
        "# change directory into our export folder from Roboflow\n",
        "%cd train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ372c7gWN_p",
        "outputId": "454b5b23-91f7-4005-9bbe-de9c228b112a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "00bc0cacffdebe6b11bdeec56f63ee49_jpg.rf.1a1407058a6170f001f2c269411d31d3.jpg\n",
            "00bc0cacffdebe6b11bdeec56f63ee49_jpg.rf.20e061b75dc554ebe40b33189e320831.jpg\n",
            "00bc0cacffdebe6b11bdeec56f63ee49_jpg.rf.38c0bb7971151bf4cb185f5498fddcc0.jpg\n",
            "0115e4df73475b550e5c6f7a88b2474f_jpg.rf.22f030d1bd7a26c987f287d2de4b19c7.jpg\n",
            "0115e4df73475b550e5c6f7a88b2474f_jpg.rf.254cb905329fee7e2df63d14b15368db.jpg\n",
            "0115e4df73475b550e5c6f7a88b2474f_jpg.rf.9d4f5de6e48861cf9108e46aee8dbb8f.jpg\n",
            "02f0931b536dfba10affc3231a3d64fb_jpg.rf.087fbe5ea178dd757f4eb065ae5cf941.jpg\n",
            "02f0931b536dfba10affc3231a3d64fb_jpg.rf.51d15aa9df1efc29ceca818ecbce37e1.jpg\n",
            "02f0931b536dfba10affc3231a3d64fb_jpg.rf.d1c527f45625192911705f97416af54b.jpg\n",
            "0301b7f9ed4d5ba503fda79fc4370c29_jpg.rf.56da1174519560712119d3fc195068cb.jpg\n",
            "0301b7f9ed4d5ba503fda79fc4370c29_jpg.rf.7871491670bed0423e3beceb3fae8016.jpg\n",
            "0301b7f9ed4d5ba503fda79fc4370c29_jpg.rf.91a1164b0c74bbe8ab32435e44b990a4.jpg\n",
            "03886821377011fec599e8fa12d86e89_jpg.rf.44fb00bcea92435e28c1ea1a89595b32.jpg\n",
            "03886821377011fec599e8fa12d86e89_jpg.rf.7ec3f29be4f3793b35a2c4a9880d831c.jpg\n",
            "03886821377011fec599e8fa12d86e89_jpg.rf.98865e45954a6f1a7c8cdd2c0be465e2.jpg\n",
            "03d3ff4582c8125d69c19a72f846bec8_jpg.rf.0abd6e8d01091ac5396f7a9cf390bdc9.jpg\n",
            "03d3ff4582c8125d69c19a72f846bec8_jpg.rf.7a003146bd5c6847a71accae7e87bf3b.jpg\n",
            "03d3ff4582c8125d69c19a72f846bec8_jpg.rf.8cfdbdc73a4c6149758151715b2e8b44.jpg\n",
            "040f2bcba5afce3afafdd5bbf36d2ca5_jpg.rf.41718e1241c9b432c1aef73937e12feb.jpg\n",
            "040f2bcba5afce3afafdd5bbf36d2ca5_jpg.rf.4b3a8c8430ecaaf5d31ff3b6ff994876.jpg\n",
            "040f2bcba5afce3afafdd5bbf36d2ca5_jpg.rf.76f9bf46e314e3671d2b9a9fe1eff19f.jpg\n",
            "04aed88a8d23cf27e47806eb23948495_jpg.rf.0afccd002b73949b13d75032bca2828b.jpg\n",
            "04aed88a8d23cf27e47806eb23948495_jpg.rf.5b2ede62cd0912672150d67bc6ed8ead.jpg\n",
            "04aed88a8d23cf27e47806eb23948495_jpg.rf.b2b9c08d458461669627c4976b744f46.jpg\n",
            "055b79dd8db4c43e1a23be6095aaf624_jpg.rf.0cecb46a274c53aaaf172c0fbe0e6eaa.jpg\n",
            "055b79dd8db4c43e1a23be6095aaf624_jpg.rf.cd15336671f029c9f3319e08f54705e5.jpg\n",
            "055b79dd8db4c43e1a23be6095aaf624_jpg.rf.cf511a337b73cbbe392f4830229e03be.jpg\n",
            "05de676d5078dc0a13796f3f627993ef_jpg.rf.1ae70c9f54b2825eb3a4d0c4e43d7213.jpg\n",
            "05de676d5078dc0a13796f3f627993ef_jpg.rf.c37fdbdb3b34643c655814729cc944eb.jpg\n",
            "05de676d5078dc0a13796f3f627993ef_jpg.rf.cc83e123e6905474c14e40a7a06b3fbb.jpg\n",
            "06770ce99d4866165c0dfb104179c361_jpg.rf.30f74da3f9fb816762fe128339f2b880.jpg\n",
            "06770ce99d4866165c0dfb104179c361_jpg.rf.4e1731dc330bcc7c45afae38ba2a6b66.jpg\n",
            "06770ce99d4866165c0dfb104179c361_jpg.rf.6e91bc2ccd7b43b371771f4aa6565d58.jpg\n",
            "0798bfb058da59d189c1bfadcf814f29_jpg.rf.1e4fca7542b10b91f6436d8b1b3cb08f.jpg\n",
            "0798bfb058da59d189c1bfadcf814f29_jpg.rf.d15086fbba4dea88618e8da79d0e52fc.jpg\n",
            "0798bfb058da59d189c1bfadcf814f29_jpg.rf.f416b21fe1523c919632ecb16aace2e2.jpg\n",
            "0b4ba28f0c759a11750a6430649b52e3_jpg.rf.360b52c8b8fb20ebbe87ca4a63d454a4.jpg\n",
            "0b4ba28f0c759a11750a6430649b52e3_jpg.rf.79ce979766c7725eac584a892f2af5b1.jpg\n",
            "0b4ba28f0c759a11750a6430649b52e3_jpg.rf.a385c2a65e0d9faff02ab153556cd00b.jpg\n",
            "0cf670506bf9e0fe587647cd62caa232_jpg.rf.45dd2d1228e8eeb0d736bc53b3246b7c.jpg\n",
            "0cf670506bf9e0fe587647cd62caa232_jpg.rf.87a892b7346e822c1255df1993d0cb80.jpg\n",
            "0cf670506bf9e0fe587647cd62caa232_jpg.rf.e44dd3107c47246d4ec175ac16e91830.jpg\n",
            "0d9dbf62d5ee42b92bf55197bba4254d_jpg.rf.214eb5f360891da5197e1900013439ec.jpg\n",
            "0d9dbf62d5ee42b92bf55197bba4254d_jpg.rf.820147842f33369719d3eeca69bb6769.jpg\n",
            "0d9dbf62d5ee42b92bf55197bba4254d_jpg.rf.b159d61997f9dc9fdf926f76aa9c273f.jpg\n",
            "104ec0199cb67e1a359b1b0845ee66f3_jpg.rf.04dc1a59935ead8705530bd4583a1222.jpg\n",
            "104ec0199cb67e1a359b1b0845ee66f3_jpg.rf.13fe6ec9290d49ca950115c142c76d57.jpg\n",
            "104ec0199cb67e1a359b1b0845ee66f3_jpg.rf.c8750ec52c3ade1aca9de15694cf9eb5.jpg\n",
            "13106bbc80a01cc413c2ab5052d2ec25_jpg.rf.137d13b354dafa0c28ae4d8136031f6b.jpg\n",
            "13106bbc80a01cc413c2ab5052d2ec25_jpg.rf.19c72bddcf32faef8dbe854f65ec3e6f.jpg\n",
            "13106bbc80a01cc413c2ab5052d2ec25_jpg.rf.b232d48e25d062c5d25a5be4e1f81021.jpg\n",
            "1595777dfa66e954ae23655743e24809_jpg.rf.5dc97daf85a90e102fd9454665288eb5.jpg\n",
            "1595777dfa66e954ae23655743e24809_jpg.rf.86c2d8bf856a3470877532a75c12a144.jpg\n",
            "1595777dfa66e954ae23655743e24809_jpg.rf.b60c3a36f35dd1eba3d57d815d930d67.jpg\n",
            "1728cd731489df8bb8e0396e178fe393_jpg.rf.72e14139be3f1f663f1512324adbe0cd.jpg\n",
            "1728cd731489df8bb8e0396e178fe393_jpg.rf.7ef76473b0a2962c632997f2fd7570eb.jpg\n",
            "1728cd731489df8bb8e0396e178fe393_jpg.rf.cf3127987c30548d691295953a2326db.jpg\n",
            "1877a28e4c5f5c1ea68aca66f4e85d95_jpg.rf.8214b540ec0fb6594f0a37059176df33.jpg\n",
            "1877a28e4c5f5c1ea68aca66f4e85d95_jpg.rf.9e17aead7bdfecd30e23fcbd0cdf9305.jpg\n",
            "1877a28e4c5f5c1ea68aca66f4e85d95_jpg.rf.c65abe6a33f5679f8c1e84d9029a77e4.jpg\n",
            "196829feb704a34a4e471155f14bdd80_jpg.rf.344f88ded341e5b5351c31ddc7e07fdb.jpg\n",
            "196829feb704a34a4e471155f14bdd80_jpg.rf.6c682963e8e934a976fb4a4373bf05b4.jpg\n",
            "196829feb704a34a4e471155f14bdd80_jpg.rf.7f5d3545dcb27e896e6f68208ca86dcd.jpg\n",
            "1a530d578f3f0bf3497bfeff3d953025_jpg.rf.a03681d6dbbeb2e50eac9e1feabbd309.jpg\n",
            "1a530d578f3f0bf3497bfeff3d953025_jpg.rf.a920532b8b005cc545bc368ad3c8f2ef.jpg\n",
            "1a530d578f3f0bf3497bfeff3d953025_jpg.rf.b8a3b1a645357b4ab6dc8daa540ba89d.jpg\n",
            "1a8a4abcba7c4ead35c01f05b9fae8e5_jpg.rf.442f136a399a1f9fe7ebdbfb4ba111a1.jpg\n",
            "1a8a4abcba7c4ead35c01f05b9fae8e5_jpg.rf.d4317263bf28a3b3e8a9e0f6618e9745.jpg\n",
            "1a8a4abcba7c4ead35c01f05b9fae8e5_jpg.rf.e7ce7cfefb2970bf066ee8409dafc31f.jpg\n",
            "1b4ccdf7d5ff45dc6c3885243bde5af2_jpg.rf.26b8553d31c5667b5ac5c7249bf80642.jpg\n",
            "1b4ccdf7d5ff45dc6c3885243bde5af2_jpg.rf.31d77a84d3d6370bc2aed5ffd3e6f2e8.jpg\n",
            "1b4ccdf7d5ff45dc6c3885243bde5af2_jpg.rf.92bd5a7bb83cb5d8639db85d02fe7511.jpg\n",
            "22e74efb18b2d88fba63d25a61bf5f97_jpg.rf.385b3e9a3203fff03fb378e343ccff7b.jpg\n",
            "22e74efb18b2d88fba63d25a61bf5f97_jpg.rf.a3d860399c54e7d955b2235f44679f53.jpg\n",
            "22e74efb18b2d88fba63d25a61bf5f97_jpg.rf.e472c82b49f6f6da28b302bda8ecc4d4.jpg\n",
            "23988893ef7381fece6d1ef32ef5428f_jpg.rf.bde765e553747a196d113f9fec702805.jpg\n",
            "23988893ef7381fece6d1ef32ef5428f_jpg.rf.c17c56f4463bd4def9641c0218c16471.jpg\n",
            "23988893ef7381fece6d1ef32ef5428f_jpg.rf.dd1332a601e86a4f219edb4145bdf239.jpg\n",
            "239c409d5c09b493fed01a70a3cda4bc_jpg.rf.01a3333223abb899709f52303c100d19.jpg\n",
            "239c409d5c09b493fed01a70a3cda4bc_jpg.rf.0da84dd41081b1d68b3eed86259f4927.jpg\n",
            "239c409d5c09b493fed01a70a3cda4bc_jpg.rf.8f3596ebdf348f77b1bde7b51557bf0f.jpg\n",
            "247f9cf35a263dc7dd7886b187fd5480_jpg.rf.21d5039624e6deb14401c708a2ebcdcb.jpg\n",
            "247f9cf35a263dc7dd7886b187fd5480_jpg.rf.d77746d6c6ff2592f94f08d808a5947d.jpg\n",
            "247f9cf35a263dc7dd7886b187fd5480_jpg.rf.f0572fa5484481b70ca83d63a3d7e184.jpg\n",
            "254f92b18b2a81f88b85e7aed3cabc61_jpg.rf.040f2bb097a768c0c16d459430205a70.jpg\n",
            "254f92b18b2a81f88b85e7aed3cabc61_jpg.rf.4c7568df4f838db750f7d7b54122210b.jpg\n",
            "254f92b18b2a81f88b85e7aed3cabc61_jpg.rf.a55e3d26992b9f4d43e7f317a078689b.jpg\n",
            "26d663ab5ffbec49f9dc8e592982cfd4_jpg.rf.0fe973299ff9e73874d9e684cba4e406.jpg\n",
            "26d663ab5ffbec49f9dc8e592982cfd4_jpg.rf.5e1a9d49ad09f5a7549225a05e1f66a6.jpg\n",
            "26d663ab5ffbec49f9dc8e592982cfd4_jpg.rf.bb226be189ee3a6399fbbd5080852e5b.jpg\n",
            "285d7c487a4e20ad832a74acb527b77f_jpg.rf.3dc659a479a4644b5a633a089379b94c.jpg\n",
            "285d7c487a4e20ad832a74acb527b77f_jpg.rf.5898c8f286182a8e159cb26d009defc3.jpg\n",
            "285d7c487a4e20ad832a74acb527b77f_jpg.rf.df00faf5828d265a002f42c16f6aab0a.jpg\n",
            "292b0ddcacad7de06a628980954b6993_jpg.rf.67f9ea5e7adf1465fa4334d3cad42707.jpg\n",
            "292b0ddcacad7de06a628980954b6993_jpg.rf.f38c3bb31f5e00206f9dd1882d9aa1b1.jpg\n",
            "292b0ddcacad7de06a628980954b6993_jpg.rf.ffb6b085a9d60c9f2c2e7524963000a4.jpg\n",
            "2c32afd520cc8bf076dfa5b6e2e1c4c1_jpg.rf.85581a8cd489d624f76364df69817031.jpg\n",
            "2c32afd520cc8bf076dfa5b6e2e1c4c1_jpg.rf.87c42395d755e8a3dd8c496a501efa69.jpg\n",
            "2c32afd520cc8bf076dfa5b6e2e1c4c1_jpg.rf.df50bc6bf291f7313cae27c09bb9c8a0.jpg\n",
            "2ee0fd0963465ba29d8f27c6e605c55d_jpg.rf.744c9a5ed432b0fccbd744ba3fe4b247.jpg\n",
            "2ee0fd0963465ba29d8f27c6e605c55d_jpg.rf.ab3d6a72f56e3d0a0fb341073880b760.jpg\n",
            "2ee0fd0963465ba29d8f27c6e605c55d_jpg.rf.b725ad9181e61d96753ab8a50c4b0aa9.jpg\n",
            "2fe75c34fd54e960146fb8b0ad8b3fd6_jpg.rf.46b8727756f5cbdf9d26a07bf9ee78d7.jpg\n",
            "2fe75c34fd54e960146fb8b0ad8b3fd6_jpg.rf.5b4da5b9403cb9506ae3e52de96842fc.jpg\n",
            "2fe75c34fd54e960146fb8b0ad8b3fd6_jpg.rf.693b072eeb2a9b531b0857ce94b0fedc.jpg\n",
            "300f80826bbb7dc4bf83e148614f2f77_jpg.rf.145cd48465162eac7e40dfeca236f55b.jpg\n",
            "300f80826bbb7dc4bf83e148614f2f77_jpg.rf.5281cacb5e3bcfc6bc9056ce0acc5e70.jpg\n",
            "300f80826bbb7dc4bf83e148614f2f77_jpg.rf.9839ccdb0a608ad3c703bc90147df6ca.jpg\n",
            "3057eba7e9b0221ddbdc96a01f39ab79_jpg.rf.2447ca37ec7de9b84cadcbbe539525e9.jpg\n",
            "3057eba7e9b0221ddbdc96a01f39ab79_jpg.rf.349a5aaf97f4108589df81010c7c4bde.jpg\n",
            "3057eba7e9b0221ddbdc96a01f39ab79_jpg.rf.787d84dddfa8b765df03c4b1af8fa18c.jpg\n",
            "3091c9b25d76e9cbd0af83ced9f354e5_jpg.rf.8df700ac741b6284988ebf22aabf95e9.jpg\n",
            "3091c9b25d76e9cbd0af83ced9f354e5_jpg.rf.afa51006174811b7734f491d2d6ad2b7.jpg\n",
            "3091c9b25d76e9cbd0af83ced9f354e5_jpg.rf.bfe4874bf78f4241bf8a602aef15c352.jpg\n",
            "31419854b103ca6becc4cc394c449e95_jpg.rf.1d33687e2a30c2496be1818a82863686.jpg\n",
            "31419854b103ca6becc4cc394c449e95_jpg.rf.4fcab5207dfc54387d4589fbc69c7a47.jpg\n",
            "31419854b103ca6becc4cc394c449e95_jpg.rf.9640ba223176f79f1fc49b0258a4da86.jpg\n",
            "3161933dffedf8a859d6623a99492c53_jpg.rf.8cff35ee63144dcc204352db8773f590.jpg\n",
            "3161933dffedf8a859d6623a99492c53_jpg.rf.972fd8a3af30fa01316510fbb84cccc6.jpg\n",
            "3161933dffedf8a859d6623a99492c53_jpg.rf.b3cca32040dcb031002296f83298f3d1.jpg\n",
            "3474d785b1b21d68163f56aa00a92bc9_jpg.rf.526eb41b7d4b9055bcd36adc5d65734a.jpg\n",
            "3474d785b1b21d68163f56aa00a92bc9_jpg.rf.6ae75801d3082ec64235d399987e2f2d.jpg\n",
            "3474d785b1b21d68163f56aa00a92bc9_jpg.rf.dc30237c228a1ef77d0fa95a2836791e.jpg\n",
            "34ad1966ae7a17d4502ca141413ed8d2_jpg.rf.33e7286b5e4b1d97dc8521130bfbb381.jpg\n",
            "34ad1966ae7a17d4502ca141413ed8d2_jpg.rf.b4e802ae4c541fc3c17ccf55d8653abe.jpg\n",
            "34ad1966ae7a17d4502ca141413ed8d2_jpg.rf.e8667dbbad2ad13b03ae4e809af01fda.jpg\n",
            "36066ba85572ce99198f1a21c2c8bbff_jpg.rf.0e1fe87ccd50187773a1725f684648e4.jpg\n",
            "36066ba85572ce99198f1a21c2c8bbff_jpg.rf.7cc3238420fd4fdce4e67d256d487f9f.jpg\n",
            "36066ba85572ce99198f1a21c2c8bbff_jpg.rf.b2440aa8c27cef761d6f79eb24689ca9.jpg\n",
            "3730ef213ac6aad431475a9ab28f349a_jpg.rf.077f757828e9ff709c4e1e8b90f2bd52.jpg\n",
            "3730ef213ac6aad431475a9ab28f349a_jpg.rf.7529be3c45ccff8446d9464f88f8d1ae.jpg\n",
            "3730ef213ac6aad431475a9ab28f349a_jpg.rf.94811f6e8a9f59622e25c0ccc4b39c91.jpg\n",
            "3796db002cba7265bd32b0161ddd9127_jpg.rf.41aa0068bba0c15b03cb7a681aa6533c.jpg\n",
            "3796db002cba7265bd32b0161ddd9127_jpg.rf.7b8109ee9b9e4dc55b72ec056ee8a747.jpg\n",
            "3796db002cba7265bd32b0161ddd9127_jpg.rf.e6cc5ba486f5c2010b53ccfa048a0c66.jpg\n",
            "37fe05bcf7d8568a9e55b569afdbccbd_jpg.rf.024d7337fe60aa8e79bdefe7b2a3bb9b.jpg\n",
            "37fe05bcf7d8568a9e55b569afdbccbd_jpg.rf.3a8156b29c22bf3e8a0a9fb0e019b005.jpg\n",
            "37fe05bcf7d8568a9e55b569afdbccbd_jpg.rf.9f9e465232a4c7b586422397223786e9.jpg\n",
            "383c2ed7bbe2d327ab55a871db497c33_jpg.rf.86e4f3f7434d212f1874685d71056f1a.jpg\n",
            "383c2ed7bbe2d327ab55a871db497c33_jpg.rf.9d983827ab445085bc8eef5da0b96932.jpg\n",
            "383c2ed7bbe2d327ab55a871db497c33_jpg.rf.bb72df5de81f3e76ee75e36e99566217.jpg\n",
            "389b4c47568c78c44df11dbb1377ffea_jpg.rf.0185f6bf38d82f7cbf9365edd7b2bfc7.jpg\n",
            "389b4c47568c78c44df11dbb1377ffea_jpg.rf.4105215a89a9e91f39916aabf7bd3724.jpg\n",
            "389b4c47568c78c44df11dbb1377ffea_jpg.rf.8ecdacfacb51a1088354bbae4d6a0731.jpg\n",
            "38f26ee82e38d332b2a831aa47bd363b_jpg.rf.70eebaf376a7a948c757715dad519b41.jpg\n",
            "38f26ee82e38d332b2a831aa47bd363b_jpg.rf.8e046f6c557a95effc7ca1d7e69c2dee.jpg\n",
            "38f26ee82e38d332b2a831aa47bd363b_jpg.rf.9531ac0c4855e848bb2d188218efe2ed.jpg\n",
            "3914be0cea4aa8a6bbd1081ec3b034a7_jpg.rf.95fd9107c63ea71989cd7fddd5d9e033.jpg\n",
            "3914be0cea4aa8a6bbd1081ec3b034a7_jpg.rf.a2edb468c84f94882c8d1ed4b983d810.jpg\n",
            "3914be0cea4aa8a6bbd1081ec3b034a7_jpg.rf.dc33766dd5985aee3962019edd74dd7a.jpg\n",
            "3bab0eaaeb63a2ac9ae4942df4006a25_jpg.rf.8fd1c7b01ae630cdb96546469e0c742d.jpg\n",
            "3bab0eaaeb63a2ac9ae4942df4006a25_jpg.rf.b78947d5207c15119ee81058a1b75c1e.jpg\n",
            "3bab0eaaeb63a2ac9ae4942df4006a25_jpg.rf.d137ab448f3c219896325f1e464c9cdc.jpg\n",
            "3e8fb24addda1a0945bd6b7777bc4018_jpg.rf.57548fe2320bf43321fcf4372bfe6e2f.jpg\n",
            "3e8fb24addda1a0945bd6b7777bc4018_jpg.rf.bc9daf0bd452e0c7dfd9167761e02135.jpg\n",
            "3e8fb24addda1a0945bd6b7777bc4018_jpg.rf.f842c9757bdb85fddeddce5fddd65bc0.jpg\n",
            "446e75de1ffefc2115e79696bcf0e357_jpg.rf.378829d017d56bcfbe81248206ba928d.jpg\n",
            "446e75de1ffefc2115e79696bcf0e357_jpg.rf.c74c5023e09478494c8b41aa67f070fe.jpg\n",
            "446e75de1ffefc2115e79696bcf0e357_jpg.rf.fc5ddb0686d3ecafa3b5a0c5ae084777.jpg\n",
            "4667110b61b16e786673ed6126ccc35d_jpg.rf.3dc2ee18962afee7c0f61083d17ed411.jpg\n",
            "4667110b61b16e786673ed6126ccc35d_jpg.rf.a4f83fe2f7c74d0fde01c1fcb729af7c.jpg\n",
            "4667110b61b16e786673ed6126ccc35d_jpg.rf.b58c56605fbe3e496fa3a357f3dce9b7.jpg\n",
            "479459fe5c8213a84fd55ba82f2670b1_jpg.rf.a4c7681de134fd46a3463e388f1e48ec.jpg\n",
            "479459fe5c8213a84fd55ba82f2670b1_jpg.rf.aed5813593dffed834ffe36cd1a2e976.jpg\n",
            "479459fe5c8213a84fd55ba82f2670b1_jpg.rf.d7c8eb7af0feef6985de36ee54a50f84.jpg\n",
            "47e842dd95735a11cf92c0ddf1161193_jpg.rf.550ba2f2bb261d19394fa2973ec4480a.jpg\n",
            "47e842dd95735a11cf92c0ddf1161193_jpg.rf.60c38d132c7d19cb8454be79650d53a5.jpg\n",
            "47e842dd95735a11cf92c0ddf1161193_jpg.rf.a08d492a1f68458ff0d6eb299c6a8478.jpg\n",
            "4807629b8df9c7eb4366b7feccd72e6a_jpg.rf.3a08163076ee5b06be9828b63ec69139.jpg\n",
            "4807629b8df9c7eb4366b7feccd72e6a_jpg.rf.478258d366ce8053d7b5400071103a8b.jpg\n",
            "4807629b8df9c7eb4366b7feccd72e6a_jpg.rf.52cd2115863114b29306879f88bb2650.jpg\n",
            "4894f034a55eaa9252cd261a62b11d27_jpg.rf.bcd60bd54187dbd564c6d84e8a4d3cb9.jpg\n",
            "4894f034a55eaa9252cd261a62b11d27_jpg.rf.e153d650cc91ee8985dbc0f9b5050e98.jpg\n",
            "4894f034a55eaa9252cd261a62b11d27_jpg.rf.ec15ec6e91a0367ded74d29495beadca.jpg\n",
            "48d3c59a99b2b5a5b9f1eb7d5ba63b60_jpg.rf.03a5018519fa45d9439d5716a03d3d02.jpg\n",
            "48d3c59a99b2b5a5b9f1eb7d5ba63b60_jpg.rf.303fc026ea7df3c5cafd1f551ed75390.jpg\n",
            "48d3c59a99b2b5a5b9f1eb7d5ba63b60_jpg.rf.d798956fd75f2a961a741523c14d932b.jpg\n",
            "48e115dcbf1b3a67ca47a75a92da3f33_jpg.rf.213e4eb4f61d74e9b61d8c7032da1766.jpg\n",
            "48e115dcbf1b3a67ca47a75a92da3f33_jpg.rf.5b14a17bd1d17edb532b6b6db9c35077.jpg\n",
            "48e115dcbf1b3a67ca47a75a92da3f33_jpg.rf.957bf6dd4345aa7c771e116ba8273385.jpg\n",
            "4939035108d04ee672570a7cc937e270_jpg.rf.0bb1cc45c05e40db8106b53800168de6.jpg\n",
            "4939035108d04ee672570a7cc937e270_jpg.rf.665362625fea5d5db13389cfa7a51e28.jpg\n",
            "4939035108d04ee672570a7cc937e270_jpg.rf.c676ffd8b63ca7b82aeb3348c032c768.jpg\n",
            "49c2afbbe5726160b289f7c0c62cdace_jpg.rf.18b76575c39d8cf45f9a9a8b6c6b6646.jpg\n",
            "49c2afbbe5726160b289f7c0c62cdace_jpg.rf.518f9a645071b5dfd9104711c09c2b49.jpg\n",
            "49c2afbbe5726160b289f7c0c62cdace_jpg.rf.c09e87097759a1f3c86cfc83a677ee7d.jpg\n",
            "49d365236ee4fb6bd982b0f00bff007e_jpg.rf.526a1568df59ddce6050cf2bce92f260.jpg\n",
            "49d365236ee4fb6bd982b0f00bff007e_jpg.rf.64f40e96e43baa404c6341ccd672ca08.jpg\n",
            "49d365236ee4fb6bd982b0f00bff007e_jpg.rf.da164da26c512372f70e3090200361a9.jpg\n",
            "49f78dc9aaeadd0c76ed2def75c358f3_jpg.rf.8df70d46b69b46482c5a2bab67b045b2.jpg\n",
            "49f78dc9aaeadd0c76ed2def75c358f3_jpg.rf.c79a51cf35ad3e236c3ea41e5a659b31.jpg\n",
            "49f78dc9aaeadd0c76ed2def75c358f3_jpg.rf.f80f03233e3dea74dbb92e5f2340f29a.jpg\n",
            "4ae38537a74c5ed10d5223f8066659fc_jpg.rf.2a3fc30eafd01a0c64b484b6082ded39.jpg\n",
            "4ae38537a74c5ed10d5223f8066659fc_jpg.rf.b01826258e0bba0f3ad3f79f161ca106.jpg\n",
            "4ae38537a74c5ed10d5223f8066659fc_jpg.rf.c07420cc60cdf3ede129a75dec9678e6.jpg\n",
            "4bf38c062fa7b5796d15ba90d6c3a456_jpg.rf.54d7350f0b18e8ec51cc8b9c351f6dce.jpg\n",
            "4bf38c062fa7b5796d15ba90d6c3a456_jpg.rf.5dc82d8843d5593359743fb73bd57edd.jpg\n",
            "4bf38c062fa7b5796d15ba90d6c3a456_jpg.rf.91410d81d86b82171fe7b271b94a4f58.jpg\n",
            "4d6b667ecbd41ebd603b38848366d9d0_jpg.rf.316c7f9af0955c14bc8303c62d5f0cd6.jpg\n",
            "4d6b667ecbd41ebd603b38848366d9d0_jpg.rf.4e30bb8f1b1048c822c448c40663b90d.jpg\n",
            "4d6b667ecbd41ebd603b38848366d9d0_jpg.rf.7cc24cb0d6e9d83179bc05d30f21bb49.jpg\n",
            "4d7820ad9fb4fe69d5168e1d7317dd02_jpg.rf.64764ea1b78a8aec014ead34271137f7.jpg\n",
            "4d7820ad9fb4fe69d5168e1d7317dd02_jpg.rf.8cb302097c3cd4d1488ba6ed0b6c0abf.jpg\n",
            "4d7820ad9fb4fe69d5168e1d7317dd02_jpg.rf.fe26c65d9b961251ae7dc598e45679b8.jpg\n",
            "4de23afff63bc169b4ebe547a9c9b692_jpg.rf.958dc90b7cb5eeb2bdc66b0356537d03.jpg\n",
            "4de23afff63bc169b4ebe547a9c9b692_jpg.rf.b16d4e221a3c932898f7efac57ab331f.jpg\n",
            "4de23afff63bc169b4ebe547a9c9b692_jpg.rf.d5caca6c6352c358873e2bcbe08dcb3e.jpg\n",
            "4eb630d4dd38528dacf72355caf5c06d_jpg.rf.542d02f24b1238b2b8ddf7e63669c6f1.jpg\n",
            "4eb630d4dd38528dacf72355caf5c06d_jpg.rf.aa4d36c64699330596d6503653e43b00.jpg\n",
            "4eb630d4dd38528dacf72355caf5c06d_jpg.rf.d291d9ff254a5001b29ef8ce2d722509.jpg\n",
            "53de0674524ae6d77bdfff48136dec2a_jpg.rf.108f3dd477ce61cd4f9251ab967b9ed5.jpg\n",
            "53de0674524ae6d77bdfff48136dec2a_jpg.rf.418e577139ae88cec5118571c10db894.jpg\n",
            "53de0674524ae6d77bdfff48136dec2a_jpg.rf.bd9646f1a26121fe3ab5d9ee21242c82.jpg\n",
            "54a90aab8c73562975cc560d51a9d2d1_jpg.rf.3de5a183732df4464edd9264ff210593.jpg\n",
            "54a90aab8c73562975cc560d51a9d2d1_jpg.rf.6d2f9f9d7b95d619880e632d994d535f.jpg\n",
            "54a90aab8c73562975cc560d51a9d2d1_jpg.rf.f081bba0a3c5e5e14c0b6bd94992465f.jpg\n",
            "5758322233deed7ae7adc23536db2a4f_jpg.rf.07a3d3e2244da0cdeddc6bf88e0d86a1.jpg\n",
            "5758322233deed7ae7adc23536db2a4f_jpg.rf.469940331ca0c0fbabd2eaad8348ed71.jpg\n",
            "5758322233deed7ae7adc23536db2a4f_jpg.rf.b16cd14d6af50949e7efe4fffdf0a1d1.jpg\n",
            "5825608dccde6544eef91822136079d0_jpg.rf.7978595f8c77d14fd89ab7a6f37a165d.jpg\n",
            "5825608dccde6544eef91822136079d0_jpg.rf.8eb618cb2ddaa495dce8b3c21edb5a03.jpg\n",
            "5825608dccde6544eef91822136079d0_jpg.rf.dc066eb4cb44e69c2e98df8a874f613e.jpg\n",
            "59727dce26aaa6100078810b61404069_jpg.rf.133f5f4c2d66f3c1cb83e25323606c51.jpg\n",
            "59727dce26aaa6100078810b61404069_jpg.rf.7921f54d55b72950940731ff0736852a.jpg\n",
            "59727dce26aaa6100078810b61404069_jpg.rf.86632bfcf9c96df565417f9cb5e54245.jpg\n",
            "5a8433ec79c881f84ef19a07dc73665d_jpg.rf.00544a8110f323e0d7721b3acf2a9e1e.jpg\n",
            "5a8433ec79c881f84ef19a07dc73665d_jpg.rf.4f609e90d2f6cf6dfdc09b85b8540822.jpg\n",
            "5a8433ec79c881f84ef19a07dc73665d_jpg.rf.ff374a0e164f5d51813ebbdb38ae9167.jpg\n",
            "5cecd3b3946aac5c713a51e0bd4617c9_jpg.rf.95fed532326e22f1bc20ee6f4768fb46.jpg\n",
            "5cecd3b3946aac5c713a51e0bd4617c9_jpg.rf.b6acbacc6e21614897ae17bfc1610149.jpg\n",
            "5cecd3b3946aac5c713a51e0bd4617c9_jpg.rf.e3e350b59dff7927d46041502756c8f3.jpg\n",
            "5e71cb8d41c333a18e799ef0004b040c_jpg.rf.05d2a8f977945663a18db2cc223250d3.jpg\n",
            "5e71cb8d41c333a18e799ef0004b040c_jpg.rf.3b081eddaeaa4d9e1da3f8990354d2b8.jpg\n",
            "5e71cb8d41c333a18e799ef0004b040c_jpg.rf.8a014b0d0195c6cc3a046974a1fec787.jpg\n",
            "614811e933a680fd6535ac8bf06bf530_jpg.rf.283f06fa4884ea55a91410d9ca4f937c.jpg\n",
            "614811e933a680fd6535ac8bf06bf530_jpg.rf.a3ef46761353d060a2693bb7ada2ab7e.jpg\n",
            "614811e933a680fd6535ac8bf06bf530_jpg.rf.fb18ccc88d4752a62d47a3260f9e0cf9.jpg\n",
            "614aadadb4a7f5b475b027b8e11398ee_jpg.rf.01b40c037e8cf1ff49c740244753af5a.jpg\n",
            "614aadadb4a7f5b475b027b8e11398ee_jpg.rf.04c134d966574ad5fdcacfb8ab619fd6.jpg\n",
            "614aadadb4a7f5b475b027b8e11398ee_jpg.rf.9c328189083b33832b90aa43f1de101d.jpg\n",
            "61567b97353acc18ba9e8aac0f111326_jpg.rf.5765711e8acd7531ab0b7c5df47febf7.jpg\n",
            "61567b97353acc18ba9e8aac0f111326_jpg.rf.94cec1f562c9e5d3eb3b3544eecc72a0.jpg\n",
            "61567b97353acc18ba9e8aac0f111326_jpg.rf.9744632c3305a0e7db1b8035a4cd3f5f.jpg\n",
            "6179b463c8f503445e213b706d2a4de5_jpg.rf.60047d46835605a44d1373c2fbc9d86a.jpg\n",
            "6179b463c8f503445e213b706d2a4de5_jpg.rf.6dad401212f974d778d11ec908ef1845.jpg\n",
            "6179b463c8f503445e213b706d2a4de5_jpg.rf.8d422c23f907d10ba6ce02a34fc3e32e.jpg\n",
            "6403b91d63799cb9b5531c47b195d088_jpg.rf.5cc9e50f7632e7938bead4a10e5fff77.jpg\n",
            "6403b91d63799cb9b5531c47b195d088_jpg.rf.c98b6f1a55887b0abf43a46704ffce4a.jpg\n",
            "6403b91d63799cb9b5531c47b195d088_jpg.rf.f88dea07bfc6c748c9b2bbdb9142935b.jpg\n",
            "6589f4cfb37439d7d276f0d70f7ee1f0_jpg.rf.5e07c88452d0555565cf271ea458a66e.jpg\n",
            "6589f4cfb37439d7d276f0d70f7ee1f0_jpg.rf.7cd0c647da853363af83fd4223c78dee.jpg\n",
            "6589f4cfb37439d7d276f0d70f7ee1f0_jpg.rf.fb12b9c28e07eb3813f431bca229ef56.jpg\n",
            "65ba27557c78850168b1df70a3ce4ff7_jpg.rf.1431d99ebaf30d4ecb2764af7d18a452.jpg\n",
            "65ba27557c78850168b1df70a3ce4ff7_jpg.rf.30a3ce572eb4c0a6cdbc01380dd7e390.jpg\n",
            "65ba27557c78850168b1df70a3ce4ff7_jpg.rf.81006b590b068c8c93153e7f18a20c1f.jpg\n",
            "66f3c2c7c10a9263de9c6e056ba5c1b9_jpg.rf.14a1fa7ff39bebb52c565e529d7c4d21.jpg\n",
            "66f3c2c7c10a9263de9c6e056ba5c1b9_jpg.rf.b4bc9d32ccb677ebb9789a4b99869931.jpg\n",
            "66f3c2c7c10a9263de9c6e056ba5c1b9_jpg.rf.fd49e15d41262253b45c5bab05240902.jpg\n",
            "673bcd0d44f495fbe9dd88d5cacfceb3_jpg.rf.06788087ab120edd9cfeb3dde2ec559f.jpg\n",
            "673bcd0d44f495fbe9dd88d5cacfceb3_jpg.rf.3b647f8c3bb9f3fc64a0d0edf806f691.jpg\n",
            "673bcd0d44f495fbe9dd88d5cacfceb3_jpg.rf.c3db2d6f80603a8fdd150776e4a74da0.jpg\n",
            "675619f2c8078824cfd182cec2eeba95_jpg.rf.0130e3c26b1bf275bf240894ba73ed7c.jpg\n",
            "675619f2c8078824cfd182cec2eeba95_jpg.rf.13e6aede17ac36e46af40237b2af1717.jpg\n",
            "675619f2c8078824cfd182cec2eeba95_jpg.rf.5a41f34953687f23f2a1a38a223eb333.jpg\n",
            "699edbacbfee5e6d4d6d2189bc88990a_jpg.rf.05759b66a63504389df87f76ea3e1bb3.jpg\n",
            "699edbacbfee5e6d4d6d2189bc88990a_jpg.rf.57b3e5ffba66e0e4c1e7ecb65a422249.jpg\n",
            "699edbacbfee5e6d4d6d2189bc88990a_jpg.rf.ecdf9c3d5f17c0c43930335adcd9ffef.jpg\n",
            "6ba74e310dd824af891d057d674cedb9_jpg.rf.08dafde0b81de46e57122cc80a5cdc80.jpg\n",
            "6ba74e310dd824af891d057d674cedb9_jpg.rf.1a5dc9d3dcc29d0b47f898d0d5c06868.jpg\n",
            "6ba74e310dd824af891d057d674cedb9_jpg.rf.2538782d08f7ce2bebeb479450f67a8b.jpg\n",
            "6bb6f7cb96bf37230681d12ff7882f61_jpg.rf.0735069f44fbf300bb0824ee46630bd4.jpg\n",
            "6bb6f7cb96bf37230681d12ff7882f61_jpg.rf.391d72bf1073621fe3eac397ae4e34d9.jpg\n",
            "6bb6f7cb96bf37230681d12ff7882f61_jpg.rf.77cbc9c645b41068d312e144d05d3792.jpg\n",
            "6f0a888f9e5aed9516e336fd04723ce1_jpg.rf.190df401c6ca3dfa7bec7c5704ad4727.jpg\n",
            "6f0a888f9e5aed9516e336fd04723ce1_jpg.rf.8151961a5cf2cebf38ce030f7eec1b68.jpg\n",
            "6f0a888f9e5aed9516e336fd04723ce1_jpg.rf.96cb5b0fd28087f53914ec4b992a849c.jpg\n",
            "6f0de9b594de9f9b92c6a20daa51a28a_jpg.rf.8f172ec0ccc12d54f9e13be42c61f072.jpg\n",
            "6f0de9b594de9f9b92c6a20daa51a28a_jpg.rf.9716020a6b1eeb6980969dc359031f66.jpg\n",
            "6f0de9b594de9f9b92c6a20daa51a28a_jpg.rf.d10980ee6f2a7a600d16ff48d980a15c.jpg\n",
            "759a86e63667ca033255c4ab438dd392_jpg.rf.0caf155d6d5d35c723fb6b362c8c1493.jpg\n",
            "759a86e63667ca033255c4ab438dd392_jpg.rf.a5cd6d950994168a0bef9e5be6a8d5c2.jpg\n",
            "759a86e63667ca033255c4ab438dd392_jpg.rf.aec0831369eb571dbe73a6342206a8bc.jpg\n",
            "76d01bada90581f55f1ae64c062cafcf_jpg.rf.7104e065b387e61376bafda059671616.jpg\n",
            "76d01bada90581f55f1ae64c062cafcf_jpg.rf.f2bd2d4d062181b36c9a9159de7090ae.jpg\n",
            "76d01bada90581f55f1ae64c062cafcf_jpg.rf.f3d7a25fb4f47eb56b7affa5673c14f7.jpg\n",
            "76dbe2ccf986a2a0d399d3d8a47279ad_jpg.rf.26886d4d35f2aefff108d7aaf1cb37db.jpg\n",
            "76dbe2ccf986a2a0d399d3d8a47279ad_jpg.rf.b1ca3d77f5a92e76eb13e448042398fb.jpg\n",
            "76dbe2ccf986a2a0d399d3d8a47279ad_jpg.rf.b422f9fa12f7008b3ed897977e7d4948.jpg\n",
            "76e118acf05a8ebe06957f8882cc06aa_jpg.rf.4d490b0b2c2371c0a5d3c41b258631d4.jpg\n",
            "76e118acf05a8ebe06957f8882cc06aa_jpg.rf.e5dba6cdbb0e4b9636bb1a7b2eefdd5c.jpg\n",
            "76e118acf05a8ebe06957f8882cc06aa_jpg.rf.ebc8f2857885aa9442f7817ea798f5ba.jpg\n",
            "79e744a68d6e6f83be0a9e8761ea66a4_jpg.rf.1c2b3f87f6a51fb881178db2db0b228c.jpg\n",
            "79e744a68d6e6f83be0a9e8761ea66a4_jpg.rf.92eb07a6d24d7f998cedd49a676bb621.jpg\n",
            "79e744a68d6e6f83be0a9e8761ea66a4_jpg.rf.a7b671ff5bbf39d29460db7e874fe65e.jpg\n",
            "7df16cd59fb40e0691948cc805e4801b_jpg.rf.286df02ab2343ae37cddc443b06feccd.jpg\n",
            "7df16cd59fb40e0691948cc805e4801b_jpg.rf.69645d63d7ad1dcadfcb6fef8d88cbae.jpg\n",
            "7df16cd59fb40e0691948cc805e4801b_jpg.rf.8c289f8d3498de860c1c990873892987.jpg\n",
            "7ee8d13861bdc45e40a7cfe190a8d8a6_jpg.rf.a8231ed0a104c2558156dc1efa5deaa4.jpg\n",
            "7ee8d13861bdc45e40a7cfe190a8d8a6_jpg.rf.a866a35bb9ecd0567a6123b53152565f.jpg\n",
            "7ee8d13861bdc45e40a7cfe190a8d8a6_jpg.rf.d2b41f1d0bdb7f0bf1055dfa6902e7fd.jpg\n",
            "81f5c542ffe0f9eae4df59d29acbcced_jpg.rf.0a5ee623a389c32b7ede54f7b9d1bd20.jpg\n",
            "81f5c542ffe0f9eae4df59d29acbcced_jpg.rf.61fced727ced7c4956b023b20c423500.jpg\n",
            "81f5c542ffe0f9eae4df59d29acbcced_jpg.rf.91a87f1144d3374bcc23d457e1499b50.jpg\n",
            "859e7157c6d544236a67463c08169b6e_jpg.rf.4021cc08bfe2940ac1246a952028554f.jpg\n",
            "859e7157c6d544236a67463c08169b6e_jpg.rf.4136782db50a3ab23736edbd04956068.jpg\n",
            "859e7157c6d544236a67463c08169b6e_jpg.rf.ab489bf688838056d6bd5f713ada144a.jpg\n",
            "8678864272a0a04c4c65ca96324105b4_jpg.rf.156a4b6b892a8823a481394ab0acdde2.jpg\n",
            "8678864272a0a04c4c65ca96324105b4_jpg.rf.1bbe62626b8565d608b4ca8a66697d0a.jpg\n",
            "8678864272a0a04c4c65ca96324105b4_jpg.rf.f14a6dc74582fe3e7649095c22d353ac.jpg\n",
            "871597c145446cf58c1c2dd7db988864_jpg.rf.33a0386e35eceaf1f5ecca1169b3fe9f.jpg\n",
            "871597c145446cf58c1c2dd7db988864_jpg.rf.418632a00632006cb8d4b1c72f9d7777.jpg\n",
            "871597c145446cf58c1c2dd7db988864_jpg.rf.752f5219f9020f0070ef1aaa764901ed.jpg\n",
            "889c420fb266b8d0e817306110042bda_jpg.rf.2b64d4f77790efe5b99a89dbc008d2fa.jpg\n",
            "889c420fb266b8d0e817306110042bda_jpg.rf.8b7244d128b2eaa4e64c6bc4a1649911.jpg\n",
            "889c420fb266b8d0e817306110042bda_jpg.rf.e94a6dd83fdb1bba12f4a84b1388fa86.jpg\n",
            "8967433350d3b3043902603430fccaab_jpg.rf.144e0920a0999b5329faa86297b2511b.jpg\n",
            "8967433350d3b3043902603430fccaab_jpg.rf.58236ac06d7679220b6db7050d8b783d.jpg\n",
            "8967433350d3b3043902603430fccaab_jpg.rf.ed0a29dbaaa3cfed939b63f420cbe09e.jpg\n",
            "8bb72e70f0560095885586deba37a524_jpg.rf.21a0d0568779e89d7ad0a4d38262c25c.jpg\n",
            "8bb72e70f0560095885586deba37a524_jpg.rf.4998a4bf9c84c615a27d9247d6079f97.jpg\n",
            "8bb72e70f0560095885586deba37a524_jpg.rf.b13dbc1ad8ed27fb0ad5edf06e990a22.jpg\n",
            "8d6f722eadc015a393bd490f9b7a85e6_jpg.rf.599d92c366a926edbc15b3afd1d2317a.jpg\n",
            "8d6f722eadc015a393bd490f9b7a85e6_jpg.rf.c7ef5eb61f666dd9651b0f2a23cf3f60.jpg\n",
            "8d6f722eadc015a393bd490f9b7a85e6_jpg.rf.d54265714db43ff80c5b3616cc762935.jpg\n",
            "8d796de64b9eed1ffd5ebe550d4ca807_jpg.rf.47e02933a0e4907473f52cb156d27a03.jpg\n",
            "8d796de64b9eed1ffd5ebe550d4ca807_jpg.rf.4b299e7e3a7aff419e2a7693d52f5890.jpg\n",
            "8d796de64b9eed1ffd5ebe550d4ca807_jpg.rf.7c37da2bd123ae11af92e6c4bfb37518.jpg\n",
            "8dd12470c30e3b265e8933a6fee7ad28_jpg.rf.11ee9892a34c2b196cfa0cb55ecaaf73.jpg\n",
            "8dd12470c30e3b265e8933a6fee7ad28_jpg.rf.83f5aa113ef37318fe16494fc6d836b0.jpg\n",
            "8dd12470c30e3b265e8933a6fee7ad28_jpg.rf.e9434facbc330f439a3f33d614e18cb8.jpg\n",
            "8de03901c64a80070048ead3fb0d32bd_jpg.rf.3bdcf5223918218765c685e65d8efd1e.jpg\n",
            "8de03901c64a80070048ead3fb0d32bd_jpg.rf.84141f105064b57f9714500f7927f2a4.jpg\n",
            "8de03901c64a80070048ead3fb0d32bd_jpg.rf.e4be065937a901b047ab7894c2fff35a.jpg\n",
            "8f84f1945fd993facc3368d13345f333_jpg.rf.0b7d4817639d4820d53a3a92bff52578.jpg\n",
            "8f84f1945fd993facc3368d13345f333_jpg.rf.2dd383bee798d213527485d1ca3243e9.jpg\n",
            "8f84f1945fd993facc3368d13345f333_jpg.rf.506d20c9cd61cb9f88aa962af2e924f7.jpg\n",
            "8ff64b3f770bfe96bdffc629efd16460_jpg.rf.09ed33a05bcda0d77e71b945d1e0475a.jpg\n",
            "8ff64b3f770bfe96bdffc629efd16460_jpg.rf.7b4792b9f562b28d55342586be82fe91.jpg\n",
            "8ff64b3f770bfe96bdffc629efd16460_jpg.rf.9dfbcd5dcdd10632e499e2305b970292.jpg\n",
            "9146a6989dac08f1769e677064ebfb49_jpg.rf.2b88a96ff66c491128cf8c3f934d845d.jpg\n",
            "9146a6989dac08f1769e677064ebfb49_jpg.rf.f479d3177bde0b8beb172fcd798971f2.jpg\n",
            "9146a6989dac08f1769e677064ebfb49_jpg.rf.fa759e8f569722a7d3a9cea8eb790cbb.jpg\n",
            "92992ff9c823e0420bf17e71db9ef4ef_jpg.rf.2e44da4eff077a078f5186fb461f5c2e.jpg\n",
            "92992ff9c823e0420bf17e71db9ef4ef_jpg.rf.927b7a8d0224a92439c39e05b5b8f7f0.jpg\n",
            "92992ff9c823e0420bf17e71db9ef4ef_jpg.rf.b3fc57a580cfbb9c3847712a48fa46a9.jpg\n",
            "93557fc861304f7753089c244bc1e33e_jpg.rf.2eb582969dccb15da9e2a7436c58e214.jpg\n",
            "93557fc861304f7753089c244bc1e33e_jpg.rf.81179eea89bb8b659cece59aefb29a3f.jpg\n",
            "93557fc861304f7753089c244bc1e33e_jpg.rf.b322a75dd276455b652411e28eae9d28.jpg\n",
            "969daa72bd7804ea1212e191820249b0_jpg.rf.416287a296a7712c4a7e15dfebe71ba6.jpg\n",
            "969daa72bd7804ea1212e191820249b0_jpg.rf.ba89164a5a6707326ca30fa4d44c0414.jpg\n",
            "969daa72bd7804ea1212e191820249b0_jpg.rf.d8d404aa7f784c9d9a80dd9a567b62f8.jpg\n",
            "97aeb1f9b745a929e9ac0848acb53a1a_jpg.rf.3284f8666d6a9be6075774c73ec06ac4.jpg\n",
            "97aeb1f9b745a929e9ac0848acb53a1a_jpg.rf.940a166aa673e2d31ccd5d2e2f21b3b2.jpg\n",
            "97aeb1f9b745a929e9ac0848acb53a1a_jpg.rf.e56d342ac870ddbd53d31ee88c69f1be.jpg\n",
            "9962a4d44388b9008aa0f466e4f4052c_jpg.rf.271e62fd6244a808feddc27148f4f5ab.jpg\n",
            "9962a4d44388b9008aa0f466e4f4052c_jpg.rf.5335c3722d3fe9b709488d492cd5c49f.jpg\n",
            "9962a4d44388b9008aa0f466e4f4052c_jpg.rf.e631892cbc08c42fce1df2203b2a0320.jpg\n",
            "998222d9c93f1640829d4f0032dbf3e8_jpg.rf.96e7371e40c0f8f62167e9f459e7d457.jpg\n",
            "998222d9c93f1640829d4f0032dbf3e8_jpg.rf.e6970890732ecad792fc36f8d5644d5f.jpg\n",
            "998222d9c93f1640829d4f0032dbf3e8_jpg.rf.f8871eeb54a25358a97555c29fecadf4.jpg\n",
            "99ee6574b2a7afc0bb06269bbcf49a4c_jpg.rf.72f0a52418f5c4883a0d240e47d10f63.jpg\n",
            "99ee6574b2a7afc0bb06269bbcf49a4c_jpg.rf.b544a6e335dc26f90bd9bcd10bc2cd2b.jpg\n",
            "99ee6574b2a7afc0bb06269bbcf49a4c_jpg.rf.be8193d6def80fbf6e353335fa2d7169.jpg\n",
            "9a6b61a6d3b3e3ecddc201b097aa02d1_jpg.rf.56770b3733424cb8ed9bf50d15ff31ca.jpg\n",
            "9a6b61a6d3b3e3ecddc201b097aa02d1_jpg.rf.b316792e863318d8477f61831379c096.jpg\n",
            "9a6b61a6d3b3e3ecddc201b097aa02d1_jpg.rf.bb7f7ec0dc21ee5750a7f9a8924c0c84.jpg\n",
            "9c153a9c9798dab948d4260eb109b315_jpg.rf.173225adc244d19c0342031fd17b26af.jpg\n",
            "9c153a9c9798dab948d4260eb109b315_jpg.rf.70d24c98a13f6263522fb9228d4438ca.jpg\n",
            "9c153a9c9798dab948d4260eb109b315_jpg.rf.c2e67b9c11e120380ba6e552636ea3f8.jpg\n",
            "9c5fb0c3cfd7b334a247cd87c139e8e6_jpg.rf.325734823f668518210b618ac6d105e4.jpg\n",
            "9c5fb0c3cfd7b334a247cd87c139e8e6_jpg.rf.904c4ab6f7ac3d6c2ab134394b00e632.jpg\n",
            "9c5fb0c3cfd7b334a247cd87c139e8e6_jpg.rf.d1b91f7c6433bd582e4e4859d618aaa6.jpg\n",
            "9d776e74e90c4f8092b060dd7567e2f8_jpg.rf.23bd3ffda19846a2c63afa0af7313f1c.jpg\n",
            "9d776e74e90c4f8092b060dd7567e2f8_jpg.rf.660c681198650e419a8e8102c9353655.jpg\n",
            "9d776e74e90c4f8092b060dd7567e2f8_jpg.rf.e56c4f14986b14ecae9d9693766bbb09.jpg\n",
            "9e943906fba1ec89edfacb2dd7976504_jpg.rf.46907d92bd6aa9bf8f5f8ee5490f8186.jpg\n",
            "9e943906fba1ec89edfacb2dd7976504_jpg.rf.6e9e4b1b2d5fb537ddde22c5fbbff591.jpg\n",
            "9e943906fba1ec89edfacb2dd7976504_jpg.rf.eb41f79339eb1eb855a136c400b4a71f.jpg\n",
            "9fc54a45feb5b01db8f6828d181fb075_jpg.rf.95558424f2db7361bbdb93e8e51e0581.jpg\n",
            "9fc54a45feb5b01db8f6828d181fb075_jpg.rf.9c25b91d55b315043a095051fe813a9c.jpg\n",
            "9fc54a45feb5b01db8f6828d181fb075_jpg.rf.dad9895160ce142893f2d50985161176.jpg\n",
            "a20eb4bb3cea2e394cfcf9ed969b628e_jpg.rf.44943c777028499045c1f45216838729.jpg\n",
            "a20eb4bb3cea2e394cfcf9ed969b628e_jpg.rf.7e25c324029c6bddd1375645580f3009.jpg\n",
            "a20eb4bb3cea2e394cfcf9ed969b628e_jpg.rf.8e7941154e8218bc5c60a42ec75cfbf3.jpg\n",
            "a4028b2361ce7ead654a86b07ac39d52_jpg.rf.55bd810c2826cd5fbda470f36df47735.jpg\n",
            "a4028b2361ce7ead654a86b07ac39d52_jpg.rf.687ddaa40b48884e559d3606486fa7e8.jpg\n",
            "a4028b2361ce7ead654a86b07ac39d52_jpg.rf.f18fa4c1dce2f0387c451354d1e535c0.jpg\n",
            "a4ebf4c268d80c4fe329331ea981b3a1_jpg.rf.12e469ca411a793fab88746c49f8f790.jpg\n",
            "a4ebf4c268d80c4fe329331ea981b3a1_jpg.rf.31a38518592003e6e81426d0090bd58a.jpg\n",
            "a4ebf4c268d80c4fe329331ea981b3a1_jpg.rf.f2ae1ea570213bb9acdec41a1a6bcd09.jpg\n",
            "a5c65b40e0be3480c0ecfacaab399a87_jpg.rf.6147a8d031e8344d640e447c4ba2dbb9.jpg\n",
            "a5c65b40e0be3480c0ecfacaab399a87_jpg.rf.647ac6c3b9611f89b1a7a757f7051b9f.jpg\n",
            "a5c65b40e0be3480c0ecfacaab399a87_jpg.rf.d1364905ffdbf3466eff747cf5948b36.jpg\n",
            "a8847f8fe8eaaa1c97bf83027a901760_jpg.rf.69b91785d4aea8f4199f9c847b918428.jpg\n",
            "a8847f8fe8eaaa1c97bf83027a901760_jpg.rf.6df2ccc6498e99df8337ffb8ab9c488a.jpg\n",
            "a8847f8fe8eaaa1c97bf83027a901760_jpg.rf.cb0f3b1463e92615083e75629be7c4ee.jpg\n",
            "a932287da44b9dfacd0d16a5c1d27923_jpg.rf.76d1125d6c63d8f0206bfcbd6dc6df99.jpg\n",
            "a932287da44b9dfacd0d16a5c1d27923_jpg.rf.d75b9b5fea5a4c7e5b066d3caae98f9b.jpg\n",
            "a932287da44b9dfacd0d16a5c1d27923_jpg.rf.e6af160c98e230c8130c17ccd6787efa.jpg\n",
            "a9768de3fceeeae2618f362870fb9a88_jpg.rf.07e7239539431dfa4ad1282152ccad21.jpg\n",
            "a9768de3fceeeae2618f362870fb9a88_jpg.rf.444b950f0b329aa6e7ed17a86383606d.jpg\n",
            "a9768de3fceeeae2618f362870fb9a88_jpg.rf.ef561195bb5bb73478b957d2958db087.jpg\n",
            "a9987cf6cc5c6545818ec294d4a5bb9b_jpg.rf.562eed600b4725f0697896672ae6ddb2.jpg\n",
            "a9987cf6cc5c6545818ec294d4a5bb9b_jpg.rf.7d8b64ebafca42e4a7e4594d41700858.jpg\n",
            "a9987cf6cc5c6545818ec294d4a5bb9b_jpg.rf.ecb9987509a91f5df7b6dd308fb5edb8.jpg\n",
            "_annotations.txt\n",
            "b0f3d66c8be13f5f6aa25b67a06bdcfa_jpg.rf.2400a74d8ca898058bbfa7a4b2fad3ed.jpg\n",
            "b0f3d66c8be13f5f6aa25b67a06bdcfa_jpg.rf.be26c1b3f90ad3ce201f81d39ce2c7a3.jpg\n",
            "b0f3d66c8be13f5f6aa25b67a06bdcfa_jpg.rf.e2479f30377a357d8c2d24488c666a98.jpg\n",
            "b3b002461f1c6b432e22964549767e5f_jpg.rf.89c6cd251768bebd0f1f27ffa57a4350.jpg\n",
            "b3b002461f1c6b432e22964549767e5f_jpg.rf.a0d7beba87e87043554e0885b9b86897.jpg\n",
            "b3b002461f1c6b432e22964549767e5f_jpg.rf.b2ec1cf3b8d3d761e56314df208ff584.jpg\n",
            "b5102d7f9740eee7754ed268becb2163_jpg.rf.1753afe30d3a07555d21ff985d2b38e9.jpg\n",
            "b5102d7f9740eee7754ed268becb2163_jpg.rf.91e588905afe5d7d801eda5ca9dcd21e.jpg\n",
            "b5102d7f9740eee7754ed268becb2163_jpg.rf.b40f1fbd9b2855b7fa5234eb32c8bb15.jpg\n",
            "b5bcde459ca36f0d1f3c20e751336672_jpg.rf.22bea80464ccb6e4d31ab5c10d11c0f9.jpg\n",
            "b5bcde459ca36f0d1f3c20e751336672_jpg.rf.aaa30a1910b6b485f2feb1daeaac3bde.jpg\n",
            "b5bcde459ca36f0d1f3c20e751336672_jpg.rf.bcad4ddc397a9e93e8f5049dc7d2ac20.jpg\n",
            "b79ae5b70de58089ead6e32b235e30d3_jpg.rf.70249336c8f66aeb7cd2c808d7e0a255.jpg\n",
            "b79ae5b70de58089ead6e32b235e30d3_jpg.rf.df8a88cab326fc33376d82c562d0b45f.jpg\n",
            "b79ae5b70de58089ead6e32b235e30d3_jpg.rf.e843446cbb3275d85d46432364a2d867.jpg\n",
            "b7a8c7de4fe1382d69f58ac97e819b5c_jpg.rf.3c92a450faed773b5607e082e798c7fa.jpg\n",
            "b7a8c7de4fe1382d69f58ac97e819b5c_jpg.rf.a896caf123ecc925575d9922df742758.jpg\n",
            "b7a8c7de4fe1382d69f58ac97e819b5c_jpg.rf.d9033064a02df12bad0b60bda98b1ff6.jpg\n",
            "bb54af2f0b83b174aecc29328c8fa001_jpg.rf.6023d601e15572d6990554f644bb1bfe.jpg\n",
            "bb54af2f0b83b174aecc29328c8fa001_jpg.rf.905a8ad083e59c277bca2ebd076a9ad1.jpg\n",
            "bb54af2f0b83b174aecc29328c8fa001_jpg.rf.a95d3e7492be3741322db734980e4372.jpg\n",
            "bc5decab88861286dcf78a367b4377cb_jpg.rf.118253b02b72c34a332d2bd78746c795.jpg\n",
            "bc5decab88861286dcf78a367b4377cb_jpg.rf.88da334f69a7c36333bc65576f4ffdfe.jpg\n",
            "bc5decab88861286dcf78a367b4377cb_jpg.rf.a4fe058da39ab9ff0b210ff464124bb2.jpg\n",
            "beb11566e59775b61f0ca369952067cc_jpg.rf.56493b995a4c4ae16d241c7e1120a53e.jpg\n",
            "beb11566e59775b61f0ca369952067cc_jpg.rf.5d2e0331a1ac2070a72fc4c12a036f53.jpg\n",
            "beb11566e59775b61f0ca369952067cc_jpg.rf.f912967037a2c28db9c37a7564017dd4.jpg\n",
            "c0d68e012bb93c14bc333fc1d5e52621_jpg.rf.1644855d8e7c4e07a615e02cdd6eb550.jpg\n",
            "c0d68e012bb93c14bc333fc1d5e52621_jpg.rf.7a3c7ca8c5ccc4d7b307f188bbfb0c85.jpg\n",
            "c0d68e012bb93c14bc333fc1d5e52621_jpg.rf.fea60abd21071433619d9002cac1d6c5.jpg\n",
            "c3e9e81ba1540aae7961a4d8d96600ba_jpg.rf.159b3ae18cb81620929e5e4847ab9ed8.jpg\n",
            "c3e9e81ba1540aae7961a4d8d96600ba_jpg.rf.32f7438c342e397838be8189c204446f.jpg\n",
            "c3e9e81ba1540aae7961a4d8d96600ba_jpg.rf.d0ef355e121a971f315ab22160109b11.jpg\n",
            "c46bf04050a2a9323dfe563e8813602f_jpg.rf.2bce3ad335a7be28858cd00cb3f40567.jpg\n",
            "c46bf04050a2a9323dfe563e8813602f_jpg.rf.3c67770c7bc1ae2f34811acc4fea44c1.jpg\n",
            "c46bf04050a2a9323dfe563e8813602f_jpg.rf.ff5a4cfb28be5ab4636539e081efb107.jpg\n",
            "c733616ab773817dd1a356dbbdf2ee33_jpg.rf.8bc96d3c3f94c91defbbb399aeb94bd0.jpg\n",
            "c733616ab773817dd1a356dbbdf2ee33_jpg.rf.8c2d39cca659bfec090ee10dd8062ef5.jpg\n",
            "c733616ab773817dd1a356dbbdf2ee33_jpg.rf.f0637765e389d17285e20d9e98d707bf.jpg\n",
            "c76c79e40bd9839a05237934cfa89ca3_jpg.rf.1bc63c348e985893973dea8fa15569ad.jpg\n",
            "c76c79e40bd9839a05237934cfa89ca3_jpg.rf.9a8aff67f0474c909c78cb647d887169.jpg\n",
            "c76c79e40bd9839a05237934cfa89ca3_jpg.rf.dee57a5076074452c76467e0c19d0ae3.jpg\n",
            "c7890b749d14d3488066cbdfac4620fd_jpg.rf.1efa9f080f6e933d2f5831041808e244.jpg\n",
            "c7890b749d14d3488066cbdfac4620fd_jpg.rf.257e75b14b6cfba7dfa565acc4e09aee.jpg\n",
            "c7890b749d14d3488066cbdfac4620fd_jpg.rf.76f2ad22e2a1c25bc8df3e234a2875e4.jpg\n",
            "ca869123d8a0cbcc6e54f4a445e5a78a_jpg.rf.1b0eec370b291dd2002d949abe4d9786.jpg\n",
            "ca869123d8a0cbcc6e54f4a445e5a78a_jpg.rf.5a9d4bcaf2ccf730c794bb7d57d77524.jpg\n",
            "ca869123d8a0cbcc6e54f4a445e5a78a_jpg.rf.cb3d9d5a5fd961cfb91b7cb00efeab83.jpg\n",
            "cae099fe41d6aa30033d71e433c33c8d_jpg.rf.2c5556b5ec9b5e12bef8a8135dbd3db6.jpg\n",
            "cae099fe41d6aa30033d71e433c33c8d_jpg.rf.4a845b5a7d4639700ca427c1099a1acc.jpg\n",
            "cae099fe41d6aa30033d71e433c33c8d_jpg.rf.e244d328c4a1dc04bdd511daa54a5bcb.jpg\n",
            "ce54969567273b9b8a275812ff56e16c_jpg.rf.29c743680e34c742cc77893515011b9e.jpg\n",
            "ce54969567273b9b8a275812ff56e16c_jpg.rf.9dcc1b3107606542dc0633cbc7ff5026.jpg\n",
            "ce54969567273b9b8a275812ff56e16c_jpg.rf.c314f1d0e3f3e5009805961ff05a7934.jpg\n",
            "cf2784fa97151d5316b2961b1e62dc45_jpg.rf.5d084fce203d3441c10c50c670717b07.jpg\n",
            "cf2784fa97151d5316b2961b1e62dc45_jpg.rf.5e86f14e3c821254e4afac25e3ade2b1.jpg\n",
            "cf2784fa97151d5316b2961b1e62dc45_jpg.rf.fe672984de7dabfff5b9cde323862f11.jpg\n",
            "_classes.txt\n",
            "d079f4e77b2445abceca7534356db743_jpg.rf.15980e0041c274dd182fc8a6bdd25047.jpg\n",
            "d079f4e77b2445abceca7534356db743_jpg.rf.86f033e983acf1e547451e03dee0e582.jpg\n",
            "d079f4e77b2445abceca7534356db743_jpg.rf.e7fc6fdfea0d14dc4c82a6068b9e4159.jpg\n",
            "d0cc2420bce5b14dfd39e55dc3737e57_jpg.rf.798223ce68149c49db97b6936b162fea.jpg\n",
            "d0cc2420bce5b14dfd39e55dc3737e57_jpg.rf.88c1e9b2ecc41404c643afeae66588e3.jpg\n",
            "d0cc2420bce5b14dfd39e55dc3737e57_jpg.rf.a1e5deac03ed76b34211a0db4f49de60.jpg\n",
            "d29148a2233950a7777285281cbfccff_jpg.rf.20e8ed774b4d58497375cf75613ce12f.jpg\n",
            "d29148a2233950a7777285281cbfccff_jpg.rf.40093760ef1ab3612d0c64743229660a.jpg\n",
            "d29148a2233950a7777285281cbfccff_jpg.rf.ac8323d05a30dae895f9f6b84d20ea68.jpg\n",
            "d33c33de41dbe1a95a43212c58fd12b7_jpg.rf.39ad6f496db1c7983d23577c21d6b498.jpg\n",
            "d33c33de41dbe1a95a43212c58fd12b7_jpg.rf.97eb2e7fe56237be37aa16911f677084.jpg\n",
            "d33c33de41dbe1a95a43212c58fd12b7_jpg.rf.b8aeaddf76563fcb8e403f431c8f746f.jpg\n",
            "d3a4e1b8f13ef89f419251f5c5839d0d_jpg.rf.0eac09b57ab66fc36635004e7f2124de.jpg\n",
            "d3a4e1b8f13ef89f419251f5c5839d0d_jpg.rf.12d1445a2e7628e803d679154eafd783.jpg\n",
            "d3a4e1b8f13ef89f419251f5c5839d0d_jpg.rf.52991bd24deab85602f52dda5aca25d4.jpg\n",
            "d415969922564f317be0d1433330626f_jpg.rf.28d3ae6c7470773e33b2e1d8ab45d13b.jpg\n",
            "d415969922564f317be0d1433330626f_jpg.rf.5bc5eaf797dffc2a83bca91da5ebcd80.jpg\n",
            "d415969922564f317be0d1433330626f_jpg.rf.ea52055e8d217e2f8c5f785c5b114aea.jpg\n",
            "d494cb268ad7f9f55587de138edc1dc4_jpg.rf.0b7a384e3d2d7cd15c45edce54fd465a.jpg\n",
            "d494cb268ad7f9f55587de138edc1dc4_jpg.rf.1225ba2bab92010c41fd82111da127c5.jpg\n",
            "d494cb268ad7f9f55587de138edc1dc4_jpg.rf.3b871f28d54bdb72507fb3451f231850.jpg\n",
            "d67b5b9e900409b050dd9bd594f90709_jpg.rf.4ee38829bdf99d869ea4efb62d7b268f.jpg\n",
            "d67b5b9e900409b050dd9bd594f90709_jpg.rf.c8f40141d74f9737a0979fb96b6f34d2.jpg\n",
            "d67b5b9e900409b050dd9bd594f90709_jpg.rf.d4b4698f0544628c496bee35512f21e2.jpg\n",
            "d795f84f39716798482fb2937868ed8a_jpg.rf.3eb9d5c21be9982bc0438b394988ec12.jpg\n",
            "d795f84f39716798482fb2937868ed8a_jpg.rf.62de48b291ec4dab492ffd28d07e46e2.jpg\n",
            "d795f84f39716798482fb2937868ed8a_jpg.rf.cad9a430bd9734f8a4d5a7bbefe008db.jpg\n",
            "d9acc69c5d57623cda22786e309201c9_jpg.rf.163bbc086efbf7cedbb02c4b36c83a28.jpg\n",
            "d9acc69c5d57623cda22786e309201c9_jpg.rf.5ee63a61ee05ff129fdbccefc3a0162e.jpg\n",
            "d9acc69c5d57623cda22786e309201c9_jpg.rf.68535cd44500e60be8d5d02bc2ff3c71.jpg\n",
            "dd6b5c3cb2d7e77f38f1dfeb2bff0431_jpg.rf.9a8ea23dbdf192fee0434dbb0eb0f22c.jpg\n",
            "dd6b5c3cb2d7e77f38f1dfeb2bff0431_jpg.rf.cc1ce4e567e8abf653acf2434e59ebdf.jpg\n",
            "dd6b5c3cb2d7e77f38f1dfeb2bff0431_jpg.rf.d5e6c00de132b8eb8ba382332327fb37.jpg\n",
            "ddad9dc4d945006d66f5349d64498559_jpg.rf.36d31b7cdbbe48577906109fa1edf766.jpg\n",
            "ddad9dc4d945006d66f5349d64498559_jpg.rf.48e7a4d1dbc55402801f6f3eb2515561.jpg\n",
            "ddad9dc4d945006d66f5349d64498559_jpg.rf.4a027c535d57e5c9ec84c9180a32c196.jpg\n",
            "de60ba81aa78387928e4bdc11f3be301_jpg.rf.6681071e793fdbd2f46b2f15c20db879.jpg\n",
            "de60ba81aa78387928e4bdc11f3be301_jpg.rf.a7cd83b2e02587367bb3305dbda0b78b.jpg\n",
            "de60ba81aa78387928e4bdc11f3be301_jpg.rf.d5ff9b3d612bf126db5f6959d6bf5cee.jpg\n",
            "e40003d4bbcdac7196b9502bfe2fb6ed_jpg.rf.b847f770b71b7f853198176ef25b8516.jpg\n",
            "e40003d4bbcdac7196b9502bfe2fb6ed_jpg.rf.d6bf64a0bd417c7ffc6c45fc60fb02a5.jpg\n",
            "e40003d4bbcdac7196b9502bfe2fb6ed_jpg.rf.fff02b8d5496821ff5b6def111287362.jpg\n",
            "e6e3a2ff2c75970490079f00136885ad_jpg.rf.196dbeb361aea01da0d89796ee64e56b.jpg\n",
            "e6e3a2ff2c75970490079f00136885ad_jpg.rf.a604bf09d249b5f66896ab2dbadd1a85.jpg\n",
            "e6e3a2ff2c75970490079f00136885ad_jpg.rf.bf5f02039da79608e7ba637b0f18b8dc.jpg\n",
            "e79deba8fe520409790b601ad61da4ee_jpg.rf.4d07e4475f01148efb81bd6fa74b14ea.jpg\n",
            "e79deba8fe520409790b601ad61da4ee_jpg.rf.83a6e8ba2d0d752b3ab81886c1c838bf.jpg\n",
            "e79deba8fe520409790b601ad61da4ee_jpg.rf.c5ace9198f249698fecd9cd44699ad3e.jpg\n",
            "e8480d7fb9881d8a0e88b7be4d103f6d_jpg.rf.45bdf3534f70d8ac1475f0521b4480b0.jpg\n",
            "e8480d7fb9881d8a0e88b7be4d103f6d_jpg.rf.928686545c1fc6e46d2b584750b57d37.jpg\n",
            "e8480d7fb9881d8a0e88b7be4d103f6d_jpg.rf.f5a8297fdaadf713f5aa50520a5aae2f.jpg\n",
            "ea799d77875c399618c45cd9409f34ee_jpg.rf.20f1e302ce66ba51ba16dd954123378d.jpg\n",
            "ea799d77875c399618c45cd9409f34ee_jpg.rf.3cbbfad204c76abb175b51ac851c1b6b.jpg\n",
            "ea799d77875c399618c45cd9409f34ee_jpg.rf.73793ae5eedc9e1a2ec843305741e27c.jpg\n",
            "eb9e7928e756c3cf9164e7afc08c4653_jpg.rf.268e96829cc026a5763f0182c1e8b842.jpg\n",
            "eb9e7928e756c3cf9164e7afc08c4653_jpg.rf.746289ad0d0f3f589717876a2b835faa.jpg\n",
            "eb9e7928e756c3cf9164e7afc08c4653_jpg.rf.7f6a60da5223783cc3525b307708142a.jpg\n",
            "ec4c30d88ecc70b6a3e76dbd9b17324a_jpg.rf.334f863b8bb588cb413d6f23e5c572e3.jpg\n",
            "ec4c30d88ecc70b6a3e76dbd9b17324a_jpg.rf.a3a828973a59e98475fa9d4c9b3bc6b0.jpg\n",
            "ec4c30d88ecc70b6a3e76dbd9b17324a_jpg.rf.aaf770cf8e03c34de0727104563ac2ee.jpg\n",
            "ec5ab1930d6aa16fff2582b48f82cada_jpg.rf.9ed7a8384c58e621e1bd8d199c9911eb.jpg\n",
            "ec5ab1930d6aa16fff2582b48f82cada_jpg.rf.a4317db23e4c499293ae36f9fd900360.jpg\n",
            "ec5ab1930d6aa16fff2582b48f82cada_jpg.rf.aae26a4e7732a2ecb663aca13ca5e2be.jpg\n",
            "edd285915356686fb53fb52c1ded0e53_jpg.rf.575ba04e0fde0ae4a7556799951ffb28.jpg\n",
            "edd285915356686fb53fb52c1ded0e53_jpg.rf.c889f2395a10814f1b3bc7c2eff34762.jpg\n",
            "edd285915356686fb53fb52c1ded0e53_jpg.rf.db25cbd151cf96bddaea8e570c74aa8a.jpg\n",
            "ef1d425fd5370fbf8b7adea43b755304_jpg.rf.098e333d5b6303fdc9c280fbaf5a79c4.jpg\n",
            "ef1d425fd5370fbf8b7adea43b755304_jpg.rf.c511c91a1669993209db75e7013631ba.jpg\n",
            "ef1d425fd5370fbf8b7adea43b755304_jpg.rf.f7787e4a869bce3acd75d98f934e857e.jpg\n",
            "f02d615907c77dc15f02bd1372e4398f_jpg.rf.30b6af213aeb1691056f9bdf8c568ffc.jpg\n",
            "f02d615907c77dc15f02bd1372e4398f_jpg.rf.8557a2e6c1a157a570333dd454271cb0.jpg\n",
            "f02d615907c77dc15f02bd1372e4398f_jpg.rf.ba5c8eb326916870dab8aeef50cd91ec.jpg\n",
            "f041d3171dfe3137390c85fc5437e447_jpg.rf.3020fee02bc4def16c99bed406ad8671.jpg\n",
            "f041d3171dfe3137390c85fc5437e447_jpg.rf.594627e68a410fbed5266fde10811a18.jpg\n",
            "f041d3171dfe3137390c85fc5437e447_jpg.rf.a4744a0326d7d31d016563fd0ab94aea.jpg\n",
            "f1ea0167087976926d4fe0aa36b961ce_jpg.rf.792c747c6116ade848581cd7c6be27e2.jpg\n",
            "f1ea0167087976926d4fe0aa36b961ce_jpg.rf.7cfb591bdf3cb30001cfecb3b153724e.jpg\n",
            "f1ea0167087976926d4fe0aa36b961ce_jpg.rf.afe8570c46a7a9651d7353b8f753e9c7.jpg\n",
            "f2672cdc28767484b556da3ab6f1003e_jpg.rf.1e58ffa93dd27f57436a6b49d82d98e7.jpg\n",
            "f2672cdc28767484b556da3ab6f1003e_jpg.rf.3509d0a9193d954d2cef5fc1371760c4.jpg\n",
            "f2672cdc28767484b556da3ab6f1003e_jpg.rf.eb54d003a3fad58875432fdfef1764bc.jpg\n",
            "f3302c754c6fd42130014199ee327d10_jpg.rf.5a539486e56c8a43d6c4eb79bf8390cf.jpg\n",
            "f3302c754c6fd42130014199ee327d10_jpg.rf.ac1176b46e92b65a435b4c64bde17da7.jpg\n",
            "f3302c754c6fd42130014199ee327d10_jpg.rf.f184e1e646cf33f3fa880c05ab94984c.jpg\n",
            "f3a5df526393445c6e2d38f66c1f5c27_jpg.rf.30434c68a81ca711cc012fba179621fb.jpg\n",
            "f3a5df526393445c6e2d38f66c1f5c27_jpg.rf.4318c9a5d50fd309db266f4e848a1202.jpg\n",
            "f3a5df526393445c6e2d38f66c1f5c27_jpg.rf.7313c3f78aaf7e508f685612f68538c7.jpg\n",
            "f52e1873b8583f8bf4f7ddf6e9649f07_jpg.rf.2537eb51bebf5c74c4bd317859fdeae6.jpg\n",
            "f52e1873b8583f8bf4f7ddf6e9649f07_jpg.rf.501bcfa0d1fb2050080a5caa9ce7ee07.jpg\n",
            "f52e1873b8583f8bf4f7ddf6e9649f07_jpg.rf.f49dc0690959dadeb1524da1a3cb38f7.jpg\n",
            "f587402be410b424bcbbac06e1dc6162_jpg.rf.23f779c5fef0d59e809103bf5bd3b7a3.jpg\n",
            "f587402be410b424bcbbac06e1dc6162_jpg.rf.b4179f89a43522928b4423c1bf422e3e.jpg\n",
            "f587402be410b424bcbbac06e1dc6162_jpg.rf.e827e0b68851bce5ae35b7bc5e7c0c4e.jpg\n",
            "f9a9a175f26d4b26bca3a5338cc1405e_jpg.rf.1bfc00ef85611686b0566f4ea49a4c9f.jpg\n",
            "f9a9a175f26d4b26bca3a5338cc1405e_jpg.rf.3260d2b6441db8b3e01beb6e26540341.jpg\n",
            "f9a9a175f26d4b26bca3a5338cc1405e_jpg.rf.d028744643f733777684eace4ef99cd6.jpg\n",
            "fa3cf2724c1648a8822b59ac0759475f_jpg.rf.2503a3b4a48386cdce9d069893234e2b.jpg\n",
            "fa3cf2724c1648a8822b59ac0759475f_jpg.rf.577379a932d9dff33794eba38ee6340d.jpg\n",
            "fa3cf2724c1648a8822b59ac0759475f_jpg.rf.89df60eac6ac5c0f593914ab045233d0.jpg\n",
            "fa4e2b9a8cf58f405f69a56c662834f2_jpg.rf.29021f89f2a16c44ecb9f34623bd3a9a.jpg\n",
            "fa4e2b9a8cf58f405f69a56c662834f2_jpg.rf.97f7416f560f73f366f58f69446c9287.jpg\n",
            "fa4e2b9a8cf58f405f69a56c662834f2_jpg.rf.d612185e16b2f1e8680764ed00dd4711.jpg\n",
            "fb586797e8ad818c7e3e3a6411f73d84_jpg.rf.57db9c805851d5fdc9e3a5f28e9717bb.jpg\n",
            "fb586797e8ad818c7e3e3a6411f73d84_jpg.rf.85d8f5b9e28cd8b994d730f9e135ab6d.jpg\n",
            "fb586797e8ad818c7e3e3a6411f73d84_jpg.rf.ed5a5085ee7d3245a50079b0e080ab12.jpg\n",
            "fc9d7bc0453cb3324406401c00224d30_jpg.rf.172aecee627f7179de58fbbc01d619f8.jpg\n",
            "fc9d7bc0453cb3324406401c00224d30_jpg.rf.d5b9739fe980fcc412eb535b6d177524.jpg\n",
            "fc9d7bc0453cb3324406401c00224d30_jpg.rf.e9e48a12d9bcbcb2a03df0571e7617b6.jpg\n",
            "IMG_0166_JPG.rf.1b943996d63e88f793c9225b051e88aa.jpg\n",
            "IMG_0166_JPG.rf.5496677843330113f25e1d96d9e5501c.jpg\n",
            "IMG_0166_JPG.rf.866e83ca31acd30da2673fcb7e2abbfe.jpg\n",
            "IMG_0167_JPG.rf.51e844ec48d744ea0d541c3978e68c8f.jpg\n",
            "IMG_0167_JPG.rf.5ef94865f654a98f644c83ec15c0c7f0.jpg\n",
            "IMG_0167_JPG.rf.700e471552dde4992d80e528387e102f.jpg\n",
            "IMG_0291_JPG.rf.0c3ecbe3fa43d54ee4fbee9f4be3c957.jpg\n",
            "IMG_0291_JPG.rf.d2ba6353082aa25c15708824c08dfb27.jpg\n",
            "IMG_0291_JPG.rf.df9096730aa1a08ad2999bcd27d3ce48.jpg\n",
            "IMG_0292_JPG.rf.430049672fd781b9df9e34badf1b48a8.jpg\n",
            "IMG_0292_JPG.rf.5eba9597d38f1d22018bb5d619ef742e.jpg\n",
            "IMG_0292_JPG.rf.baaccc7cf58cb3b0c9d1bc3f1ce32a3d.jpg\n",
            "IMG_0294_JPG.rf.517f9201b72a4266d46b2954a0f80c14.jpg\n",
            "IMG_0294_JPG.rf.bd8d20acd3d837e056c6714500e83270.jpg\n",
            "IMG_0294_JPG.rf.cb349f708d70f8f46097636ec55f5419.jpg\n",
            "IMG_0295_JPG.rf.282c3259eadee31b6cfd1548f0aa4e6d.jpg\n",
            "IMG_0295_JPG.rf.32f999d96696f80ebe62ade6437b2fe2.jpg\n",
            "IMG_0295_JPG.rf.939fab6c2495e85e1b177306373fbe6e.jpg\n",
            "IMG_0296_JPG.rf.530c25c318deab34b53cadb7918fa500.jpg\n",
            "IMG_0296_JPG.rf.e8332a65a587b3f337f25bca237988af.jpg\n",
            "IMG_0296_JPG.rf.fe6246bc705bb866f527a6ae2efb1b99.jpg\n",
            "IMG_0297_JPG.rf.47e3984909ef5581659ae1a350978094.jpg\n",
            "IMG_0297_JPG.rf.5e635cca1323148499732eaf858ba2b2.jpg\n",
            "IMG_0297_JPG.rf.a66ff62117c20eb55204281f042b32c7.jpg\n",
            "IMG_0298_JPG.rf.5b5e7dd4118e128457567019a928e264.jpg\n",
            "IMG_0298_JPG.rf.6d6ac51367b303c05c261e7e8b11de67.jpg\n",
            "IMG_0298_JPG.rf.c72da1b09a38ec0adab3af9bb3abc0c1.jpg\n",
            "IMG_0299_JPG.rf.4d6c7558e7fd08da45a6fabde3296e5b.jpg\n",
            "IMG_0299_JPG.rf.9f796e9ea3695af07f61b110f53ee45f.jpg\n",
            "IMG_0299_JPG.rf.ae4ab20b4db16431416f89b8d9582906.jpg\n",
            "IMG_0317_JPG.rf.00207d2fe8c0a0f20715333d49d22b4f.jpg\n",
            "IMG_0317_JPG.rf.b4f86e6c57fca84c485b3bbcde731959.jpg\n",
            "IMG_0317_JPG.rf.c4575757a6e19ad9fb88d28b1a15193e.jpg\n",
            "IMG_0318_JPG.rf.60de6e8f2c9365770ed11379dfd1cb55.jpg\n",
            "IMG_0318_JPG.rf.8d091ab4bbe2cd70b92ad64592315ac8.jpg\n",
            "IMG_0318_JPG.rf.f752cb565b0c634895506816ba026b7e.jpg\n"
          ]
        }
      ],
      "source": [
        "# show what came with the Roboflow export\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUWFxHW_mjlT"
      },
      "outputs": [],
      "source": [
        "# move everything from the Roboflow export to the root of our keras-yolo3 folder\n",
        "%mv * ../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "200_8-VImWmK",
        "outputId": "6e46814f-3a5d-4097-980f-84bc5a0e1efa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/keras-yolo3\n"
          ]
        }
      ],
      "source": [
        "# change directory back to our\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQASf1hzmxE7",
        "outputId": "b8d36ea6-cb8f-498c-8b91-5c72562c8d85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "00bc0cacffdebe6b11bdeec56f63ee49_jpg.rf.1a1407058a6170f001f2c269411d31d3.jpg\n",
            "00bc0cacffdebe6b11bdeec56f63ee49_jpg.rf.20e061b75dc554ebe40b33189e320831.jpg\n",
            "00bc0cacffdebe6b11bdeec56f63ee49_jpg.rf.38c0bb7971151bf4cb185f5498fddcc0.jpg\n",
            "0115e4df73475b550e5c6f7a88b2474f_jpg.rf.22f030d1bd7a26c987f287d2de4b19c7.jpg\n",
            "0115e4df73475b550e5c6f7a88b2474f_jpg.rf.254cb905329fee7e2df63d14b15368db.jpg\n",
            "0115e4df73475b550e5c6f7a88b2474f_jpg.rf.9d4f5de6e48861cf9108e46aee8dbb8f.jpg\n",
            "02f0931b536dfba10affc3231a3d64fb_jpg.rf.087fbe5ea178dd757f4eb065ae5cf941.jpg\n",
            "02f0931b536dfba10affc3231a3d64fb_jpg.rf.51d15aa9df1efc29ceca818ecbce37e1.jpg\n",
            "02f0931b536dfba10affc3231a3d64fb_jpg.rf.d1c527f45625192911705f97416af54b.jpg\n",
            "0301b7f9ed4d5ba503fda79fc4370c29_jpg.rf.56da1174519560712119d3fc195068cb.jpg\n",
            "0301b7f9ed4d5ba503fda79fc4370c29_jpg.rf.7871491670bed0423e3beceb3fae8016.jpg\n",
            "0301b7f9ed4d5ba503fda79fc4370c29_jpg.rf.91a1164b0c74bbe8ab32435e44b990a4.jpg\n",
            "03886821377011fec599e8fa12d86e89_jpg.rf.44fb00bcea92435e28c1ea1a89595b32.jpg\n",
            "03886821377011fec599e8fa12d86e89_jpg.rf.7ec3f29be4f3793b35a2c4a9880d831c.jpg\n",
            "03886821377011fec599e8fa12d86e89_jpg.rf.98865e45954a6f1a7c8cdd2c0be465e2.jpg\n",
            "03d3ff4582c8125d69c19a72f846bec8_jpg.rf.0abd6e8d01091ac5396f7a9cf390bdc9.jpg\n",
            "03d3ff4582c8125d69c19a72f846bec8_jpg.rf.7a003146bd5c6847a71accae7e87bf3b.jpg\n",
            "03d3ff4582c8125d69c19a72f846bec8_jpg.rf.8cfdbdc73a4c6149758151715b2e8b44.jpg\n",
            "040f2bcba5afce3afafdd5bbf36d2ca5_jpg.rf.41718e1241c9b432c1aef73937e12feb.jpg\n",
            "040f2bcba5afce3afafdd5bbf36d2ca5_jpg.rf.4b3a8c8430ecaaf5d31ff3b6ff994876.jpg\n",
            "040f2bcba5afce3afafdd5bbf36d2ca5_jpg.rf.76f9bf46e314e3671d2b9a9fe1eff19f.jpg\n",
            "04aed88a8d23cf27e47806eb23948495_jpg.rf.0afccd002b73949b13d75032bca2828b.jpg\n",
            "04aed88a8d23cf27e47806eb23948495_jpg.rf.5b2ede62cd0912672150d67bc6ed8ead.jpg\n",
            "04aed88a8d23cf27e47806eb23948495_jpg.rf.b2b9c08d458461669627c4976b744f46.jpg\n",
            "055b79dd8db4c43e1a23be6095aaf624_jpg.rf.0cecb46a274c53aaaf172c0fbe0e6eaa.jpg\n",
            "055b79dd8db4c43e1a23be6095aaf624_jpg.rf.cd15336671f029c9f3319e08f54705e5.jpg\n",
            "055b79dd8db4c43e1a23be6095aaf624_jpg.rf.cf511a337b73cbbe392f4830229e03be.jpg\n",
            "05de676d5078dc0a13796f3f627993ef_jpg.rf.1ae70c9f54b2825eb3a4d0c4e43d7213.jpg\n",
            "05de676d5078dc0a13796f3f627993ef_jpg.rf.c37fdbdb3b34643c655814729cc944eb.jpg\n",
            "05de676d5078dc0a13796f3f627993ef_jpg.rf.cc83e123e6905474c14e40a7a06b3fbb.jpg\n",
            "06770ce99d4866165c0dfb104179c361_jpg.rf.30f74da3f9fb816762fe128339f2b880.jpg\n",
            "06770ce99d4866165c0dfb104179c361_jpg.rf.4e1731dc330bcc7c45afae38ba2a6b66.jpg\n",
            "06770ce99d4866165c0dfb104179c361_jpg.rf.6e91bc2ccd7b43b371771f4aa6565d58.jpg\n",
            "0798bfb058da59d189c1bfadcf814f29_jpg.rf.1e4fca7542b10b91f6436d8b1b3cb08f.jpg\n",
            "0798bfb058da59d189c1bfadcf814f29_jpg.rf.d15086fbba4dea88618e8da79d0e52fc.jpg\n",
            "0798bfb058da59d189c1bfadcf814f29_jpg.rf.f416b21fe1523c919632ecb16aace2e2.jpg\n",
            "0b4ba28f0c759a11750a6430649b52e3_jpg.rf.360b52c8b8fb20ebbe87ca4a63d454a4.jpg\n",
            "0b4ba28f0c759a11750a6430649b52e3_jpg.rf.79ce979766c7725eac584a892f2af5b1.jpg\n",
            "0b4ba28f0c759a11750a6430649b52e3_jpg.rf.a385c2a65e0d9faff02ab153556cd00b.jpg\n",
            "0cf670506bf9e0fe587647cd62caa232_jpg.rf.45dd2d1228e8eeb0d736bc53b3246b7c.jpg\n",
            "0cf670506bf9e0fe587647cd62caa232_jpg.rf.87a892b7346e822c1255df1993d0cb80.jpg\n",
            "0cf670506bf9e0fe587647cd62caa232_jpg.rf.e44dd3107c47246d4ec175ac16e91830.jpg\n",
            "0d9dbf62d5ee42b92bf55197bba4254d_jpg.rf.214eb5f360891da5197e1900013439ec.jpg\n",
            "0d9dbf62d5ee42b92bf55197bba4254d_jpg.rf.820147842f33369719d3eeca69bb6769.jpg\n",
            "0d9dbf62d5ee42b92bf55197bba4254d_jpg.rf.b159d61997f9dc9fdf926f76aa9c273f.jpg\n",
            "104ec0199cb67e1a359b1b0845ee66f3_jpg.rf.04dc1a59935ead8705530bd4583a1222.jpg\n",
            "104ec0199cb67e1a359b1b0845ee66f3_jpg.rf.13fe6ec9290d49ca950115c142c76d57.jpg\n",
            "104ec0199cb67e1a359b1b0845ee66f3_jpg.rf.c8750ec52c3ade1aca9de15694cf9eb5.jpg\n",
            "13106bbc80a01cc413c2ab5052d2ec25_jpg.rf.137d13b354dafa0c28ae4d8136031f6b.jpg\n",
            "13106bbc80a01cc413c2ab5052d2ec25_jpg.rf.19c72bddcf32faef8dbe854f65ec3e6f.jpg\n",
            "13106bbc80a01cc413c2ab5052d2ec25_jpg.rf.b232d48e25d062c5d25a5be4e1f81021.jpg\n",
            "1595777dfa66e954ae23655743e24809_jpg.rf.5dc97daf85a90e102fd9454665288eb5.jpg\n",
            "1595777dfa66e954ae23655743e24809_jpg.rf.86c2d8bf856a3470877532a75c12a144.jpg\n",
            "1595777dfa66e954ae23655743e24809_jpg.rf.b60c3a36f35dd1eba3d57d815d930d67.jpg\n",
            "1728cd731489df8bb8e0396e178fe393_jpg.rf.72e14139be3f1f663f1512324adbe0cd.jpg\n",
            "1728cd731489df8bb8e0396e178fe393_jpg.rf.7ef76473b0a2962c632997f2fd7570eb.jpg\n",
            "1728cd731489df8bb8e0396e178fe393_jpg.rf.cf3127987c30548d691295953a2326db.jpg\n",
            "1877a28e4c5f5c1ea68aca66f4e85d95_jpg.rf.8214b540ec0fb6594f0a37059176df33.jpg\n",
            "1877a28e4c5f5c1ea68aca66f4e85d95_jpg.rf.9e17aead7bdfecd30e23fcbd0cdf9305.jpg\n",
            "1877a28e4c5f5c1ea68aca66f4e85d95_jpg.rf.c65abe6a33f5679f8c1e84d9029a77e4.jpg\n",
            "196829feb704a34a4e471155f14bdd80_jpg.rf.344f88ded341e5b5351c31ddc7e07fdb.jpg\n",
            "196829feb704a34a4e471155f14bdd80_jpg.rf.6c682963e8e934a976fb4a4373bf05b4.jpg\n",
            "196829feb704a34a4e471155f14bdd80_jpg.rf.7f5d3545dcb27e896e6f68208ca86dcd.jpg\n",
            "1a530d578f3f0bf3497bfeff3d953025_jpg.rf.a03681d6dbbeb2e50eac9e1feabbd309.jpg\n",
            "1a530d578f3f0bf3497bfeff3d953025_jpg.rf.a920532b8b005cc545bc368ad3c8f2ef.jpg\n",
            "1a530d578f3f0bf3497bfeff3d953025_jpg.rf.b8a3b1a645357b4ab6dc8daa540ba89d.jpg\n",
            "1a8a4abcba7c4ead35c01f05b9fae8e5_jpg.rf.442f136a399a1f9fe7ebdbfb4ba111a1.jpg\n",
            "1a8a4abcba7c4ead35c01f05b9fae8e5_jpg.rf.d4317263bf28a3b3e8a9e0f6618e9745.jpg\n",
            "1a8a4abcba7c4ead35c01f05b9fae8e5_jpg.rf.e7ce7cfefb2970bf066ee8409dafc31f.jpg\n",
            "1b4ccdf7d5ff45dc6c3885243bde5af2_jpg.rf.26b8553d31c5667b5ac5c7249bf80642.jpg\n",
            "1b4ccdf7d5ff45dc6c3885243bde5af2_jpg.rf.31d77a84d3d6370bc2aed5ffd3e6f2e8.jpg\n",
            "1b4ccdf7d5ff45dc6c3885243bde5af2_jpg.rf.92bd5a7bb83cb5d8639db85d02fe7511.jpg\n",
            "22e74efb18b2d88fba63d25a61bf5f97_jpg.rf.385b3e9a3203fff03fb378e343ccff7b.jpg\n",
            "22e74efb18b2d88fba63d25a61bf5f97_jpg.rf.a3d860399c54e7d955b2235f44679f53.jpg\n",
            "22e74efb18b2d88fba63d25a61bf5f97_jpg.rf.e472c82b49f6f6da28b302bda8ecc4d4.jpg\n",
            "23988893ef7381fece6d1ef32ef5428f_jpg.rf.bde765e553747a196d113f9fec702805.jpg\n",
            "23988893ef7381fece6d1ef32ef5428f_jpg.rf.c17c56f4463bd4def9641c0218c16471.jpg\n",
            "23988893ef7381fece6d1ef32ef5428f_jpg.rf.dd1332a601e86a4f219edb4145bdf239.jpg\n",
            "239c409d5c09b493fed01a70a3cda4bc_jpg.rf.01a3333223abb899709f52303c100d19.jpg\n",
            "239c409d5c09b493fed01a70a3cda4bc_jpg.rf.0da84dd41081b1d68b3eed86259f4927.jpg\n",
            "239c409d5c09b493fed01a70a3cda4bc_jpg.rf.8f3596ebdf348f77b1bde7b51557bf0f.jpg\n",
            "247f9cf35a263dc7dd7886b187fd5480_jpg.rf.21d5039624e6deb14401c708a2ebcdcb.jpg\n",
            "247f9cf35a263dc7dd7886b187fd5480_jpg.rf.d77746d6c6ff2592f94f08d808a5947d.jpg\n",
            "247f9cf35a263dc7dd7886b187fd5480_jpg.rf.f0572fa5484481b70ca83d63a3d7e184.jpg\n",
            "254f92b18b2a81f88b85e7aed3cabc61_jpg.rf.040f2bb097a768c0c16d459430205a70.jpg\n",
            "254f92b18b2a81f88b85e7aed3cabc61_jpg.rf.4c7568df4f838db750f7d7b54122210b.jpg\n",
            "254f92b18b2a81f88b85e7aed3cabc61_jpg.rf.a55e3d26992b9f4d43e7f317a078689b.jpg\n",
            "26d663ab5ffbec49f9dc8e592982cfd4_jpg.rf.0fe973299ff9e73874d9e684cba4e406.jpg\n",
            "26d663ab5ffbec49f9dc8e592982cfd4_jpg.rf.5e1a9d49ad09f5a7549225a05e1f66a6.jpg\n",
            "26d663ab5ffbec49f9dc8e592982cfd4_jpg.rf.bb226be189ee3a6399fbbd5080852e5b.jpg\n",
            "285d7c487a4e20ad832a74acb527b77f_jpg.rf.3dc659a479a4644b5a633a089379b94c.jpg\n",
            "285d7c487a4e20ad832a74acb527b77f_jpg.rf.5898c8f286182a8e159cb26d009defc3.jpg\n",
            "285d7c487a4e20ad832a74acb527b77f_jpg.rf.df00faf5828d265a002f42c16f6aab0a.jpg\n",
            "292b0ddcacad7de06a628980954b6993_jpg.rf.67f9ea5e7adf1465fa4334d3cad42707.jpg\n",
            "292b0ddcacad7de06a628980954b6993_jpg.rf.f38c3bb31f5e00206f9dd1882d9aa1b1.jpg\n",
            "292b0ddcacad7de06a628980954b6993_jpg.rf.ffb6b085a9d60c9f2c2e7524963000a4.jpg\n",
            "2c32afd520cc8bf076dfa5b6e2e1c4c1_jpg.rf.85581a8cd489d624f76364df69817031.jpg\n",
            "2c32afd520cc8bf076dfa5b6e2e1c4c1_jpg.rf.87c42395d755e8a3dd8c496a501efa69.jpg\n",
            "2c32afd520cc8bf076dfa5b6e2e1c4c1_jpg.rf.df50bc6bf291f7313cae27c09bb9c8a0.jpg\n",
            "2ee0fd0963465ba29d8f27c6e605c55d_jpg.rf.744c9a5ed432b0fccbd744ba3fe4b247.jpg\n",
            "2ee0fd0963465ba29d8f27c6e605c55d_jpg.rf.ab3d6a72f56e3d0a0fb341073880b760.jpg\n",
            "2ee0fd0963465ba29d8f27c6e605c55d_jpg.rf.b725ad9181e61d96753ab8a50c4b0aa9.jpg\n",
            "2fe75c34fd54e960146fb8b0ad8b3fd6_jpg.rf.46b8727756f5cbdf9d26a07bf9ee78d7.jpg\n",
            "2fe75c34fd54e960146fb8b0ad8b3fd6_jpg.rf.5b4da5b9403cb9506ae3e52de96842fc.jpg\n",
            "2fe75c34fd54e960146fb8b0ad8b3fd6_jpg.rf.693b072eeb2a9b531b0857ce94b0fedc.jpg\n",
            "300f80826bbb7dc4bf83e148614f2f77_jpg.rf.145cd48465162eac7e40dfeca236f55b.jpg\n",
            "300f80826bbb7dc4bf83e148614f2f77_jpg.rf.5281cacb5e3bcfc6bc9056ce0acc5e70.jpg\n",
            "300f80826bbb7dc4bf83e148614f2f77_jpg.rf.9839ccdb0a608ad3c703bc90147df6ca.jpg\n",
            "3057eba7e9b0221ddbdc96a01f39ab79_jpg.rf.2447ca37ec7de9b84cadcbbe539525e9.jpg\n",
            "3057eba7e9b0221ddbdc96a01f39ab79_jpg.rf.349a5aaf97f4108589df81010c7c4bde.jpg\n",
            "3057eba7e9b0221ddbdc96a01f39ab79_jpg.rf.787d84dddfa8b765df03c4b1af8fa18c.jpg\n",
            "3091c9b25d76e9cbd0af83ced9f354e5_jpg.rf.8df700ac741b6284988ebf22aabf95e9.jpg\n",
            "3091c9b25d76e9cbd0af83ced9f354e5_jpg.rf.afa51006174811b7734f491d2d6ad2b7.jpg\n",
            "3091c9b25d76e9cbd0af83ced9f354e5_jpg.rf.bfe4874bf78f4241bf8a602aef15c352.jpg\n",
            "31419854b103ca6becc4cc394c449e95_jpg.rf.1d33687e2a30c2496be1818a82863686.jpg\n",
            "31419854b103ca6becc4cc394c449e95_jpg.rf.4fcab5207dfc54387d4589fbc69c7a47.jpg\n",
            "31419854b103ca6becc4cc394c449e95_jpg.rf.9640ba223176f79f1fc49b0258a4da86.jpg\n",
            "3161933dffedf8a859d6623a99492c53_jpg.rf.8cff35ee63144dcc204352db8773f590.jpg\n",
            "3161933dffedf8a859d6623a99492c53_jpg.rf.972fd8a3af30fa01316510fbb84cccc6.jpg\n",
            "3161933dffedf8a859d6623a99492c53_jpg.rf.b3cca32040dcb031002296f83298f3d1.jpg\n",
            "3474d785b1b21d68163f56aa00a92bc9_jpg.rf.526eb41b7d4b9055bcd36adc5d65734a.jpg\n",
            "3474d785b1b21d68163f56aa00a92bc9_jpg.rf.6ae75801d3082ec64235d399987e2f2d.jpg\n",
            "3474d785b1b21d68163f56aa00a92bc9_jpg.rf.dc30237c228a1ef77d0fa95a2836791e.jpg\n",
            "34ad1966ae7a17d4502ca141413ed8d2_jpg.rf.33e7286b5e4b1d97dc8521130bfbb381.jpg\n",
            "34ad1966ae7a17d4502ca141413ed8d2_jpg.rf.b4e802ae4c541fc3c17ccf55d8653abe.jpg\n",
            "34ad1966ae7a17d4502ca141413ed8d2_jpg.rf.e8667dbbad2ad13b03ae4e809af01fda.jpg\n",
            "36066ba85572ce99198f1a21c2c8bbff_jpg.rf.0e1fe87ccd50187773a1725f684648e4.jpg\n",
            "36066ba85572ce99198f1a21c2c8bbff_jpg.rf.7cc3238420fd4fdce4e67d256d487f9f.jpg\n",
            "36066ba85572ce99198f1a21c2c8bbff_jpg.rf.b2440aa8c27cef761d6f79eb24689ca9.jpg\n",
            "3730ef213ac6aad431475a9ab28f349a_jpg.rf.077f757828e9ff709c4e1e8b90f2bd52.jpg\n",
            "3730ef213ac6aad431475a9ab28f349a_jpg.rf.7529be3c45ccff8446d9464f88f8d1ae.jpg\n",
            "3730ef213ac6aad431475a9ab28f349a_jpg.rf.94811f6e8a9f59622e25c0ccc4b39c91.jpg\n",
            "3796db002cba7265bd32b0161ddd9127_jpg.rf.41aa0068bba0c15b03cb7a681aa6533c.jpg\n",
            "3796db002cba7265bd32b0161ddd9127_jpg.rf.7b8109ee9b9e4dc55b72ec056ee8a747.jpg\n",
            "3796db002cba7265bd32b0161ddd9127_jpg.rf.e6cc5ba486f5c2010b53ccfa048a0c66.jpg\n",
            "37fe05bcf7d8568a9e55b569afdbccbd_jpg.rf.024d7337fe60aa8e79bdefe7b2a3bb9b.jpg\n",
            "37fe05bcf7d8568a9e55b569afdbccbd_jpg.rf.3a8156b29c22bf3e8a0a9fb0e019b005.jpg\n",
            "37fe05bcf7d8568a9e55b569afdbccbd_jpg.rf.9f9e465232a4c7b586422397223786e9.jpg\n",
            "383c2ed7bbe2d327ab55a871db497c33_jpg.rf.86e4f3f7434d212f1874685d71056f1a.jpg\n",
            "383c2ed7bbe2d327ab55a871db497c33_jpg.rf.9d983827ab445085bc8eef5da0b96932.jpg\n",
            "383c2ed7bbe2d327ab55a871db497c33_jpg.rf.bb72df5de81f3e76ee75e36e99566217.jpg\n",
            "389b4c47568c78c44df11dbb1377ffea_jpg.rf.0185f6bf38d82f7cbf9365edd7b2bfc7.jpg\n",
            "389b4c47568c78c44df11dbb1377ffea_jpg.rf.4105215a89a9e91f39916aabf7bd3724.jpg\n",
            "389b4c47568c78c44df11dbb1377ffea_jpg.rf.8ecdacfacb51a1088354bbae4d6a0731.jpg\n",
            "38f26ee82e38d332b2a831aa47bd363b_jpg.rf.70eebaf376a7a948c757715dad519b41.jpg\n",
            "38f26ee82e38d332b2a831aa47bd363b_jpg.rf.8e046f6c557a95effc7ca1d7e69c2dee.jpg\n",
            "38f26ee82e38d332b2a831aa47bd363b_jpg.rf.9531ac0c4855e848bb2d188218efe2ed.jpg\n",
            "3914be0cea4aa8a6bbd1081ec3b034a7_jpg.rf.95fd9107c63ea71989cd7fddd5d9e033.jpg\n",
            "3914be0cea4aa8a6bbd1081ec3b034a7_jpg.rf.a2edb468c84f94882c8d1ed4b983d810.jpg\n",
            "3914be0cea4aa8a6bbd1081ec3b034a7_jpg.rf.dc33766dd5985aee3962019edd74dd7a.jpg\n",
            "3bab0eaaeb63a2ac9ae4942df4006a25_jpg.rf.8fd1c7b01ae630cdb96546469e0c742d.jpg\n",
            "3bab0eaaeb63a2ac9ae4942df4006a25_jpg.rf.b78947d5207c15119ee81058a1b75c1e.jpg\n",
            "3bab0eaaeb63a2ac9ae4942df4006a25_jpg.rf.d137ab448f3c219896325f1e464c9cdc.jpg\n",
            "3e8fb24addda1a0945bd6b7777bc4018_jpg.rf.57548fe2320bf43321fcf4372bfe6e2f.jpg\n",
            "3e8fb24addda1a0945bd6b7777bc4018_jpg.rf.bc9daf0bd452e0c7dfd9167761e02135.jpg\n",
            "3e8fb24addda1a0945bd6b7777bc4018_jpg.rf.f842c9757bdb85fddeddce5fddd65bc0.jpg\n",
            "446e75de1ffefc2115e79696bcf0e357_jpg.rf.378829d017d56bcfbe81248206ba928d.jpg\n",
            "446e75de1ffefc2115e79696bcf0e357_jpg.rf.c74c5023e09478494c8b41aa67f070fe.jpg\n",
            "446e75de1ffefc2115e79696bcf0e357_jpg.rf.fc5ddb0686d3ecafa3b5a0c5ae084777.jpg\n",
            "4667110b61b16e786673ed6126ccc35d_jpg.rf.3dc2ee18962afee7c0f61083d17ed411.jpg\n",
            "4667110b61b16e786673ed6126ccc35d_jpg.rf.a4f83fe2f7c74d0fde01c1fcb729af7c.jpg\n",
            "4667110b61b16e786673ed6126ccc35d_jpg.rf.b58c56605fbe3e496fa3a357f3dce9b7.jpg\n",
            "479459fe5c8213a84fd55ba82f2670b1_jpg.rf.a4c7681de134fd46a3463e388f1e48ec.jpg\n",
            "479459fe5c8213a84fd55ba82f2670b1_jpg.rf.aed5813593dffed834ffe36cd1a2e976.jpg\n",
            "479459fe5c8213a84fd55ba82f2670b1_jpg.rf.d7c8eb7af0feef6985de36ee54a50f84.jpg\n",
            "47e842dd95735a11cf92c0ddf1161193_jpg.rf.550ba2f2bb261d19394fa2973ec4480a.jpg\n",
            "47e842dd95735a11cf92c0ddf1161193_jpg.rf.60c38d132c7d19cb8454be79650d53a5.jpg\n",
            "47e842dd95735a11cf92c0ddf1161193_jpg.rf.a08d492a1f68458ff0d6eb299c6a8478.jpg\n",
            "4807629b8df9c7eb4366b7feccd72e6a_jpg.rf.3a08163076ee5b06be9828b63ec69139.jpg\n",
            "4807629b8df9c7eb4366b7feccd72e6a_jpg.rf.478258d366ce8053d7b5400071103a8b.jpg\n",
            "4807629b8df9c7eb4366b7feccd72e6a_jpg.rf.52cd2115863114b29306879f88bb2650.jpg\n",
            "4894f034a55eaa9252cd261a62b11d27_jpg.rf.bcd60bd54187dbd564c6d84e8a4d3cb9.jpg\n",
            "4894f034a55eaa9252cd261a62b11d27_jpg.rf.e153d650cc91ee8985dbc0f9b5050e98.jpg\n",
            "4894f034a55eaa9252cd261a62b11d27_jpg.rf.ec15ec6e91a0367ded74d29495beadca.jpg\n",
            "48d3c59a99b2b5a5b9f1eb7d5ba63b60_jpg.rf.03a5018519fa45d9439d5716a03d3d02.jpg\n",
            "48d3c59a99b2b5a5b9f1eb7d5ba63b60_jpg.rf.303fc026ea7df3c5cafd1f551ed75390.jpg\n",
            "48d3c59a99b2b5a5b9f1eb7d5ba63b60_jpg.rf.d798956fd75f2a961a741523c14d932b.jpg\n",
            "48e115dcbf1b3a67ca47a75a92da3f33_jpg.rf.213e4eb4f61d74e9b61d8c7032da1766.jpg\n",
            "48e115dcbf1b3a67ca47a75a92da3f33_jpg.rf.5b14a17bd1d17edb532b6b6db9c35077.jpg\n",
            "48e115dcbf1b3a67ca47a75a92da3f33_jpg.rf.957bf6dd4345aa7c771e116ba8273385.jpg\n",
            "4939035108d04ee672570a7cc937e270_jpg.rf.0bb1cc45c05e40db8106b53800168de6.jpg\n",
            "4939035108d04ee672570a7cc937e270_jpg.rf.665362625fea5d5db13389cfa7a51e28.jpg\n",
            "4939035108d04ee672570a7cc937e270_jpg.rf.c676ffd8b63ca7b82aeb3348c032c768.jpg\n",
            "49c2afbbe5726160b289f7c0c62cdace_jpg.rf.18b76575c39d8cf45f9a9a8b6c6b6646.jpg\n",
            "49c2afbbe5726160b289f7c0c62cdace_jpg.rf.518f9a645071b5dfd9104711c09c2b49.jpg\n",
            "49c2afbbe5726160b289f7c0c62cdace_jpg.rf.c09e87097759a1f3c86cfc83a677ee7d.jpg\n",
            "49d365236ee4fb6bd982b0f00bff007e_jpg.rf.526a1568df59ddce6050cf2bce92f260.jpg\n",
            "49d365236ee4fb6bd982b0f00bff007e_jpg.rf.64f40e96e43baa404c6341ccd672ca08.jpg\n",
            "49d365236ee4fb6bd982b0f00bff007e_jpg.rf.da164da26c512372f70e3090200361a9.jpg\n",
            "49f78dc9aaeadd0c76ed2def75c358f3_jpg.rf.8df70d46b69b46482c5a2bab67b045b2.jpg\n",
            "49f78dc9aaeadd0c76ed2def75c358f3_jpg.rf.c79a51cf35ad3e236c3ea41e5a659b31.jpg\n",
            "49f78dc9aaeadd0c76ed2def75c358f3_jpg.rf.f80f03233e3dea74dbb92e5f2340f29a.jpg\n",
            "4ae38537a74c5ed10d5223f8066659fc_jpg.rf.2a3fc30eafd01a0c64b484b6082ded39.jpg\n",
            "4ae38537a74c5ed10d5223f8066659fc_jpg.rf.b01826258e0bba0f3ad3f79f161ca106.jpg\n",
            "4ae38537a74c5ed10d5223f8066659fc_jpg.rf.c07420cc60cdf3ede129a75dec9678e6.jpg\n",
            "4bf38c062fa7b5796d15ba90d6c3a456_jpg.rf.54d7350f0b18e8ec51cc8b9c351f6dce.jpg\n",
            "4bf38c062fa7b5796d15ba90d6c3a456_jpg.rf.5dc82d8843d5593359743fb73bd57edd.jpg\n",
            "4bf38c062fa7b5796d15ba90d6c3a456_jpg.rf.91410d81d86b82171fe7b271b94a4f58.jpg\n",
            "4d6b667ecbd41ebd603b38848366d9d0_jpg.rf.316c7f9af0955c14bc8303c62d5f0cd6.jpg\n",
            "4d6b667ecbd41ebd603b38848366d9d0_jpg.rf.4e30bb8f1b1048c822c448c40663b90d.jpg\n",
            "4d6b667ecbd41ebd603b38848366d9d0_jpg.rf.7cc24cb0d6e9d83179bc05d30f21bb49.jpg\n",
            "4d7820ad9fb4fe69d5168e1d7317dd02_jpg.rf.64764ea1b78a8aec014ead34271137f7.jpg\n",
            "4d7820ad9fb4fe69d5168e1d7317dd02_jpg.rf.8cb302097c3cd4d1488ba6ed0b6c0abf.jpg\n",
            "4d7820ad9fb4fe69d5168e1d7317dd02_jpg.rf.fe26c65d9b961251ae7dc598e45679b8.jpg\n",
            "4de23afff63bc169b4ebe547a9c9b692_jpg.rf.958dc90b7cb5eeb2bdc66b0356537d03.jpg\n",
            "4de23afff63bc169b4ebe547a9c9b692_jpg.rf.b16d4e221a3c932898f7efac57ab331f.jpg\n",
            "4de23afff63bc169b4ebe547a9c9b692_jpg.rf.d5caca6c6352c358873e2bcbe08dcb3e.jpg\n",
            "4eb630d4dd38528dacf72355caf5c06d_jpg.rf.542d02f24b1238b2b8ddf7e63669c6f1.jpg\n",
            "4eb630d4dd38528dacf72355caf5c06d_jpg.rf.aa4d36c64699330596d6503653e43b00.jpg\n",
            "4eb630d4dd38528dacf72355caf5c06d_jpg.rf.d291d9ff254a5001b29ef8ce2d722509.jpg\n",
            "53de0674524ae6d77bdfff48136dec2a_jpg.rf.108f3dd477ce61cd4f9251ab967b9ed5.jpg\n",
            "53de0674524ae6d77bdfff48136dec2a_jpg.rf.418e577139ae88cec5118571c10db894.jpg\n",
            "53de0674524ae6d77bdfff48136dec2a_jpg.rf.bd9646f1a26121fe3ab5d9ee21242c82.jpg\n",
            "54a90aab8c73562975cc560d51a9d2d1_jpg.rf.3de5a183732df4464edd9264ff210593.jpg\n",
            "54a90aab8c73562975cc560d51a9d2d1_jpg.rf.6d2f9f9d7b95d619880e632d994d535f.jpg\n",
            "54a90aab8c73562975cc560d51a9d2d1_jpg.rf.f081bba0a3c5e5e14c0b6bd94992465f.jpg\n",
            "5758322233deed7ae7adc23536db2a4f_jpg.rf.07a3d3e2244da0cdeddc6bf88e0d86a1.jpg\n",
            "5758322233deed7ae7adc23536db2a4f_jpg.rf.469940331ca0c0fbabd2eaad8348ed71.jpg\n",
            "5758322233deed7ae7adc23536db2a4f_jpg.rf.b16cd14d6af50949e7efe4fffdf0a1d1.jpg\n",
            "5825608dccde6544eef91822136079d0_jpg.rf.7978595f8c77d14fd89ab7a6f37a165d.jpg\n",
            "5825608dccde6544eef91822136079d0_jpg.rf.8eb618cb2ddaa495dce8b3c21edb5a03.jpg\n",
            "5825608dccde6544eef91822136079d0_jpg.rf.dc066eb4cb44e69c2e98df8a874f613e.jpg\n",
            "59727dce26aaa6100078810b61404069_jpg.rf.133f5f4c2d66f3c1cb83e25323606c51.jpg\n",
            "59727dce26aaa6100078810b61404069_jpg.rf.7921f54d55b72950940731ff0736852a.jpg\n",
            "59727dce26aaa6100078810b61404069_jpg.rf.86632bfcf9c96df565417f9cb5e54245.jpg\n",
            "5a8433ec79c881f84ef19a07dc73665d_jpg.rf.00544a8110f323e0d7721b3acf2a9e1e.jpg\n",
            "5a8433ec79c881f84ef19a07dc73665d_jpg.rf.4f609e90d2f6cf6dfdc09b85b8540822.jpg\n",
            "5a8433ec79c881f84ef19a07dc73665d_jpg.rf.ff374a0e164f5d51813ebbdb38ae9167.jpg\n",
            "5cecd3b3946aac5c713a51e0bd4617c9_jpg.rf.95fed532326e22f1bc20ee6f4768fb46.jpg\n",
            "5cecd3b3946aac5c713a51e0bd4617c9_jpg.rf.b6acbacc6e21614897ae17bfc1610149.jpg\n",
            "5cecd3b3946aac5c713a51e0bd4617c9_jpg.rf.e3e350b59dff7927d46041502756c8f3.jpg\n",
            "5e71cb8d41c333a18e799ef0004b040c_jpg.rf.05d2a8f977945663a18db2cc223250d3.jpg\n",
            "5e71cb8d41c333a18e799ef0004b040c_jpg.rf.3b081eddaeaa4d9e1da3f8990354d2b8.jpg\n",
            "5e71cb8d41c333a18e799ef0004b040c_jpg.rf.8a014b0d0195c6cc3a046974a1fec787.jpg\n",
            "614811e933a680fd6535ac8bf06bf530_jpg.rf.283f06fa4884ea55a91410d9ca4f937c.jpg\n",
            "614811e933a680fd6535ac8bf06bf530_jpg.rf.a3ef46761353d060a2693bb7ada2ab7e.jpg\n",
            "614811e933a680fd6535ac8bf06bf530_jpg.rf.fb18ccc88d4752a62d47a3260f9e0cf9.jpg\n",
            "614aadadb4a7f5b475b027b8e11398ee_jpg.rf.01b40c037e8cf1ff49c740244753af5a.jpg\n",
            "614aadadb4a7f5b475b027b8e11398ee_jpg.rf.04c134d966574ad5fdcacfb8ab619fd6.jpg\n",
            "614aadadb4a7f5b475b027b8e11398ee_jpg.rf.9c328189083b33832b90aa43f1de101d.jpg\n",
            "61567b97353acc18ba9e8aac0f111326_jpg.rf.5765711e8acd7531ab0b7c5df47febf7.jpg\n",
            "61567b97353acc18ba9e8aac0f111326_jpg.rf.94cec1f562c9e5d3eb3b3544eecc72a0.jpg\n",
            "61567b97353acc18ba9e8aac0f111326_jpg.rf.9744632c3305a0e7db1b8035a4cd3f5f.jpg\n",
            "6179b463c8f503445e213b706d2a4de5_jpg.rf.60047d46835605a44d1373c2fbc9d86a.jpg\n",
            "6179b463c8f503445e213b706d2a4de5_jpg.rf.6dad401212f974d778d11ec908ef1845.jpg\n",
            "6179b463c8f503445e213b706d2a4de5_jpg.rf.8d422c23f907d10ba6ce02a34fc3e32e.jpg\n",
            "6403b91d63799cb9b5531c47b195d088_jpg.rf.5cc9e50f7632e7938bead4a10e5fff77.jpg\n",
            "6403b91d63799cb9b5531c47b195d088_jpg.rf.c98b6f1a55887b0abf43a46704ffce4a.jpg\n",
            "6403b91d63799cb9b5531c47b195d088_jpg.rf.f88dea07bfc6c748c9b2bbdb9142935b.jpg\n",
            "6589f4cfb37439d7d276f0d70f7ee1f0_jpg.rf.5e07c88452d0555565cf271ea458a66e.jpg\n",
            "6589f4cfb37439d7d276f0d70f7ee1f0_jpg.rf.7cd0c647da853363af83fd4223c78dee.jpg\n",
            "6589f4cfb37439d7d276f0d70f7ee1f0_jpg.rf.fb12b9c28e07eb3813f431bca229ef56.jpg\n",
            "65ba27557c78850168b1df70a3ce4ff7_jpg.rf.1431d99ebaf30d4ecb2764af7d18a452.jpg\n",
            "65ba27557c78850168b1df70a3ce4ff7_jpg.rf.30a3ce572eb4c0a6cdbc01380dd7e390.jpg\n",
            "65ba27557c78850168b1df70a3ce4ff7_jpg.rf.81006b590b068c8c93153e7f18a20c1f.jpg\n",
            "66f3c2c7c10a9263de9c6e056ba5c1b9_jpg.rf.14a1fa7ff39bebb52c565e529d7c4d21.jpg\n",
            "66f3c2c7c10a9263de9c6e056ba5c1b9_jpg.rf.b4bc9d32ccb677ebb9789a4b99869931.jpg\n",
            "66f3c2c7c10a9263de9c6e056ba5c1b9_jpg.rf.fd49e15d41262253b45c5bab05240902.jpg\n",
            "673bcd0d44f495fbe9dd88d5cacfceb3_jpg.rf.06788087ab120edd9cfeb3dde2ec559f.jpg\n",
            "673bcd0d44f495fbe9dd88d5cacfceb3_jpg.rf.3b647f8c3bb9f3fc64a0d0edf806f691.jpg\n",
            "673bcd0d44f495fbe9dd88d5cacfceb3_jpg.rf.c3db2d6f80603a8fdd150776e4a74da0.jpg\n",
            "675619f2c8078824cfd182cec2eeba95_jpg.rf.0130e3c26b1bf275bf240894ba73ed7c.jpg\n",
            "675619f2c8078824cfd182cec2eeba95_jpg.rf.13e6aede17ac36e46af40237b2af1717.jpg\n",
            "675619f2c8078824cfd182cec2eeba95_jpg.rf.5a41f34953687f23f2a1a38a223eb333.jpg\n",
            "699edbacbfee5e6d4d6d2189bc88990a_jpg.rf.05759b66a63504389df87f76ea3e1bb3.jpg\n",
            "699edbacbfee5e6d4d6d2189bc88990a_jpg.rf.57b3e5ffba66e0e4c1e7ecb65a422249.jpg\n",
            "699edbacbfee5e6d4d6d2189bc88990a_jpg.rf.ecdf9c3d5f17c0c43930335adcd9ffef.jpg\n",
            "6ba74e310dd824af891d057d674cedb9_jpg.rf.08dafde0b81de46e57122cc80a5cdc80.jpg\n",
            "6ba74e310dd824af891d057d674cedb9_jpg.rf.1a5dc9d3dcc29d0b47f898d0d5c06868.jpg\n",
            "6ba74e310dd824af891d057d674cedb9_jpg.rf.2538782d08f7ce2bebeb479450f67a8b.jpg\n",
            "6bb6f7cb96bf37230681d12ff7882f61_jpg.rf.0735069f44fbf300bb0824ee46630bd4.jpg\n",
            "6bb6f7cb96bf37230681d12ff7882f61_jpg.rf.391d72bf1073621fe3eac397ae4e34d9.jpg\n",
            "6bb6f7cb96bf37230681d12ff7882f61_jpg.rf.77cbc9c645b41068d312e144d05d3792.jpg\n",
            "6f0a888f9e5aed9516e336fd04723ce1_jpg.rf.190df401c6ca3dfa7bec7c5704ad4727.jpg\n",
            "6f0a888f9e5aed9516e336fd04723ce1_jpg.rf.8151961a5cf2cebf38ce030f7eec1b68.jpg\n",
            "6f0a888f9e5aed9516e336fd04723ce1_jpg.rf.96cb5b0fd28087f53914ec4b992a849c.jpg\n",
            "6f0de9b594de9f9b92c6a20daa51a28a_jpg.rf.8f172ec0ccc12d54f9e13be42c61f072.jpg\n",
            "6f0de9b594de9f9b92c6a20daa51a28a_jpg.rf.9716020a6b1eeb6980969dc359031f66.jpg\n",
            "6f0de9b594de9f9b92c6a20daa51a28a_jpg.rf.d10980ee6f2a7a600d16ff48d980a15c.jpg\n",
            "759a86e63667ca033255c4ab438dd392_jpg.rf.0caf155d6d5d35c723fb6b362c8c1493.jpg\n",
            "759a86e63667ca033255c4ab438dd392_jpg.rf.a5cd6d950994168a0bef9e5be6a8d5c2.jpg\n",
            "759a86e63667ca033255c4ab438dd392_jpg.rf.aec0831369eb571dbe73a6342206a8bc.jpg\n",
            "76d01bada90581f55f1ae64c062cafcf_jpg.rf.7104e065b387e61376bafda059671616.jpg\n",
            "76d01bada90581f55f1ae64c062cafcf_jpg.rf.f2bd2d4d062181b36c9a9159de7090ae.jpg\n",
            "76d01bada90581f55f1ae64c062cafcf_jpg.rf.f3d7a25fb4f47eb56b7affa5673c14f7.jpg\n",
            "76dbe2ccf986a2a0d399d3d8a47279ad_jpg.rf.26886d4d35f2aefff108d7aaf1cb37db.jpg\n",
            "76dbe2ccf986a2a0d399d3d8a47279ad_jpg.rf.b1ca3d77f5a92e76eb13e448042398fb.jpg\n",
            "76dbe2ccf986a2a0d399d3d8a47279ad_jpg.rf.b422f9fa12f7008b3ed897977e7d4948.jpg\n",
            "76e118acf05a8ebe06957f8882cc06aa_jpg.rf.4d490b0b2c2371c0a5d3c41b258631d4.jpg\n",
            "76e118acf05a8ebe06957f8882cc06aa_jpg.rf.e5dba6cdbb0e4b9636bb1a7b2eefdd5c.jpg\n",
            "76e118acf05a8ebe06957f8882cc06aa_jpg.rf.ebc8f2857885aa9442f7817ea798f5ba.jpg\n",
            "79e744a68d6e6f83be0a9e8761ea66a4_jpg.rf.1c2b3f87f6a51fb881178db2db0b228c.jpg\n",
            "79e744a68d6e6f83be0a9e8761ea66a4_jpg.rf.92eb07a6d24d7f998cedd49a676bb621.jpg\n",
            "79e744a68d6e6f83be0a9e8761ea66a4_jpg.rf.a7b671ff5bbf39d29460db7e874fe65e.jpg\n",
            "7df16cd59fb40e0691948cc805e4801b_jpg.rf.286df02ab2343ae37cddc443b06feccd.jpg\n",
            "7df16cd59fb40e0691948cc805e4801b_jpg.rf.69645d63d7ad1dcadfcb6fef8d88cbae.jpg\n",
            "7df16cd59fb40e0691948cc805e4801b_jpg.rf.8c289f8d3498de860c1c990873892987.jpg\n",
            "7ee8d13861bdc45e40a7cfe190a8d8a6_jpg.rf.a8231ed0a104c2558156dc1efa5deaa4.jpg\n",
            "7ee8d13861bdc45e40a7cfe190a8d8a6_jpg.rf.a866a35bb9ecd0567a6123b53152565f.jpg\n",
            "7ee8d13861bdc45e40a7cfe190a8d8a6_jpg.rf.d2b41f1d0bdb7f0bf1055dfa6902e7fd.jpg\n",
            "81f5c542ffe0f9eae4df59d29acbcced_jpg.rf.0a5ee623a389c32b7ede54f7b9d1bd20.jpg\n",
            "81f5c542ffe0f9eae4df59d29acbcced_jpg.rf.61fced727ced7c4956b023b20c423500.jpg\n",
            "81f5c542ffe0f9eae4df59d29acbcced_jpg.rf.91a87f1144d3374bcc23d457e1499b50.jpg\n",
            "859e7157c6d544236a67463c08169b6e_jpg.rf.4021cc08bfe2940ac1246a952028554f.jpg\n",
            "859e7157c6d544236a67463c08169b6e_jpg.rf.4136782db50a3ab23736edbd04956068.jpg\n",
            "859e7157c6d544236a67463c08169b6e_jpg.rf.ab489bf688838056d6bd5f713ada144a.jpg\n",
            "8678864272a0a04c4c65ca96324105b4_jpg.rf.156a4b6b892a8823a481394ab0acdde2.jpg\n",
            "8678864272a0a04c4c65ca96324105b4_jpg.rf.1bbe62626b8565d608b4ca8a66697d0a.jpg\n",
            "8678864272a0a04c4c65ca96324105b4_jpg.rf.f14a6dc74582fe3e7649095c22d353ac.jpg\n",
            "871597c145446cf58c1c2dd7db988864_jpg.rf.33a0386e35eceaf1f5ecca1169b3fe9f.jpg\n",
            "871597c145446cf58c1c2dd7db988864_jpg.rf.418632a00632006cb8d4b1c72f9d7777.jpg\n",
            "871597c145446cf58c1c2dd7db988864_jpg.rf.752f5219f9020f0070ef1aaa764901ed.jpg\n",
            "889c420fb266b8d0e817306110042bda_jpg.rf.2b64d4f77790efe5b99a89dbc008d2fa.jpg\n",
            "889c420fb266b8d0e817306110042bda_jpg.rf.8b7244d128b2eaa4e64c6bc4a1649911.jpg\n",
            "889c420fb266b8d0e817306110042bda_jpg.rf.e94a6dd83fdb1bba12f4a84b1388fa86.jpg\n",
            "8967433350d3b3043902603430fccaab_jpg.rf.144e0920a0999b5329faa86297b2511b.jpg\n",
            "8967433350d3b3043902603430fccaab_jpg.rf.58236ac06d7679220b6db7050d8b783d.jpg\n",
            "8967433350d3b3043902603430fccaab_jpg.rf.ed0a29dbaaa3cfed939b63f420cbe09e.jpg\n",
            "8bb72e70f0560095885586deba37a524_jpg.rf.21a0d0568779e89d7ad0a4d38262c25c.jpg\n",
            "8bb72e70f0560095885586deba37a524_jpg.rf.4998a4bf9c84c615a27d9247d6079f97.jpg\n",
            "8bb72e70f0560095885586deba37a524_jpg.rf.b13dbc1ad8ed27fb0ad5edf06e990a22.jpg\n",
            "8d6f722eadc015a393bd490f9b7a85e6_jpg.rf.599d92c366a926edbc15b3afd1d2317a.jpg\n",
            "8d6f722eadc015a393bd490f9b7a85e6_jpg.rf.c7ef5eb61f666dd9651b0f2a23cf3f60.jpg\n",
            "8d6f722eadc015a393bd490f9b7a85e6_jpg.rf.d54265714db43ff80c5b3616cc762935.jpg\n",
            "8d796de64b9eed1ffd5ebe550d4ca807_jpg.rf.47e02933a0e4907473f52cb156d27a03.jpg\n",
            "8d796de64b9eed1ffd5ebe550d4ca807_jpg.rf.4b299e7e3a7aff419e2a7693d52f5890.jpg\n",
            "8d796de64b9eed1ffd5ebe550d4ca807_jpg.rf.7c37da2bd123ae11af92e6c4bfb37518.jpg\n",
            "8dd12470c30e3b265e8933a6fee7ad28_jpg.rf.11ee9892a34c2b196cfa0cb55ecaaf73.jpg\n",
            "8dd12470c30e3b265e8933a6fee7ad28_jpg.rf.83f5aa113ef37318fe16494fc6d836b0.jpg\n",
            "8dd12470c30e3b265e8933a6fee7ad28_jpg.rf.e9434facbc330f439a3f33d614e18cb8.jpg\n",
            "8de03901c64a80070048ead3fb0d32bd_jpg.rf.3bdcf5223918218765c685e65d8efd1e.jpg\n",
            "8de03901c64a80070048ead3fb0d32bd_jpg.rf.84141f105064b57f9714500f7927f2a4.jpg\n",
            "8de03901c64a80070048ead3fb0d32bd_jpg.rf.e4be065937a901b047ab7894c2fff35a.jpg\n",
            "8f84f1945fd993facc3368d13345f333_jpg.rf.0b7d4817639d4820d53a3a92bff52578.jpg\n",
            "8f84f1945fd993facc3368d13345f333_jpg.rf.2dd383bee798d213527485d1ca3243e9.jpg\n",
            "8f84f1945fd993facc3368d13345f333_jpg.rf.506d20c9cd61cb9f88aa962af2e924f7.jpg\n",
            "8ff64b3f770bfe96bdffc629efd16460_jpg.rf.09ed33a05bcda0d77e71b945d1e0475a.jpg\n",
            "8ff64b3f770bfe96bdffc629efd16460_jpg.rf.7b4792b9f562b28d55342586be82fe91.jpg\n",
            "8ff64b3f770bfe96bdffc629efd16460_jpg.rf.9dfbcd5dcdd10632e499e2305b970292.jpg\n",
            "9146a6989dac08f1769e677064ebfb49_jpg.rf.2b88a96ff66c491128cf8c3f934d845d.jpg\n",
            "9146a6989dac08f1769e677064ebfb49_jpg.rf.f479d3177bde0b8beb172fcd798971f2.jpg\n",
            "9146a6989dac08f1769e677064ebfb49_jpg.rf.fa759e8f569722a7d3a9cea8eb790cbb.jpg\n",
            "92992ff9c823e0420bf17e71db9ef4ef_jpg.rf.2e44da4eff077a078f5186fb461f5c2e.jpg\n",
            "92992ff9c823e0420bf17e71db9ef4ef_jpg.rf.927b7a8d0224a92439c39e05b5b8f7f0.jpg\n",
            "92992ff9c823e0420bf17e71db9ef4ef_jpg.rf.b3fc57a580cfbb9c3847712a48fa46a9.jpg\n",
            "93557fc861304f7753089c244bc1e33e_jpg.rf.2eb582969dccb15da9e2a7436c58e214.jpg\n",
            "93557fc861304f7753089c244bc1e33e_jpg.rf.81179eea89bb8b659cece59aefb29a3f.jpg\n",
            "93557fc861304f7753089c244bc1e33e_jpg.rf.b322a75dd276455b652411e28eae9d28.jpg\n",
            "969daa72bd7804ea1212e191820249b0_jpg.rf.416287a296a7712c4a7e15dfebe71ba6.jpg\n",
            "969daa72bd7804ea1212e191820249b0_jpg.rf.ba89164a5a6707326ca30fa4d44c0414.jpg\n",
            "969daa72bd7804ea1212e191820249b0_jpg.rf.d8d404aa7f784c9d9a80dd9a567b62f8.jpg\n",
            "97aeb1f9b745a929e9ac0848acb53a1a_jpg.rf.3284f8666d6a9be6075774c73ec06ac4.jpg\n",
            "97aeb1f9b745a929e9ac0848acb53a1a_jpg.rf.940a166aa673e2d31ccd5d2e2f21b3b2.jpg\n",
            "97aeb1f9b745a929e9ac0848acb53a1a_jpg.rf.e56d342ac870ddbd53d31ee88c69f1be.jpg\n",
            "9962a4d44388b9008aa0f466e4f4052c_jpg.rf.271e62fd6244a808feddc27148f4f5ab.jpg\n",
            "9962a4d44388b9008aa0f466e4f4052c_jpg.rf.5335c3722d3fe9b709488d492cd5c49f.jpg\n",
            "9962a4d44388b9008aa0f466e4f4052c_jpg.rf.e631892cbc08c42fce1df2203b2a0320.jpg\n",
            "998222d9c93f1640829d4f0032dbf3e8_jpg.rf.96e7371e40c0f8f62167e9f459e7d457.jpg\n",
            "998222d9c93f1640829d4f0032dbf3e8_jpg.rf.e6970890732ecad792fc36f8d5644d5f.jpg\n",
            "998222d9c93f1640829d4f0032dbf3e8_jpg.rf.f8871eeb54a25358a97555c29fecadf4.jpg\n",
            "99ee6574b2a7afc0bb06269bbcf49a4c_jpg.rf.72f0a52418f5c4883a0d240e47d10f63.jpg\n",
            "99ee6574b2a7afc0bb06269bbcf49a4c_jpg.rf.b544a6e335dc26f90bd9bcd10bc2cd2b.jpg\n",
            "99ee6574b2a7afc0bb06269bbcf49a4c_jpg.rf.be8193d6def80fbf6e353335fa2d7169.jpg\n",
            "9a6b61a6d3b3e3ecddc201b097aa02d1_jpg.rf.56770b3733424cb8ed9bf50d15ff31ca.jpg\n",
            "9a6b61a6d3b3e3ecddc201b097aa02d1_jpg.rf.b316792e863318d8477f61831379c096.jpg\n",
            "9a6b61a6d3b3e3ecddc201b097aa02d1_jpg.rf.bb7f7ec0dc21ee5750a7f9a8924c0c84.jpg\n",
            "9c153a9c9798dab948d4260eb109b315_jpg.rf.173225adc244d19c0342031fd17b26af.jpg\n",
            "9c153a9c9798dab948d4260eb109b315_jpg.rf.70d24c98a13f6263522fb9228d4438ca.jpg\n",
            "9c153a9c9798dab948d4260eb109b315_jpg.rf.c2e67b9c11e120380ba6e552636ea3f8.jpg\n",
            "9c5fb0c3cfd7b334a247cd87c139e8e6_jpg.rf.325734823f668518210b618ac6d105e4.jpg\n",
            "9c5fb0c3cfd7b334a247cd87c139e8e6_jpg.rf.904c4ab6f7ac3d6c2ab134394b00e632.jpg\n",
            "9c5fb0c3cfd7b334a247cd87c139e8e6_jpg.rf.d1b91f7c6433bd582e4e4859d618aaa6.jpg\n",
            "9d776e74e90c4f8092b060dd7567e2f8_jpg.rf.23bd3ffda19846a2c63afa0af7313f1c.jpg\n",
            "9d776e74e90c4f8092b060dd7567e2f8_jpg.rf.660c681198650e419a8e8102c9353655.jpg\n",
            "9d776e74e90c4f8092b060dd7567e2f8_jpg.rf.e56c4f14986b14ecae9d9693766bbb09.jpg\n",
            "9e943906fba1ec89edfacb2dd7976504_jpg.rf.46907d92bd6aa9bf8f5f8ee5490f8186.jpg\n",
            "9e943906fba1ec89edfacb2dd7976504_jpg.rf.6e9e4b1b2d5fb537ddde22c5fbbff591.jpg\n",
            "9e943906fba1ec89edfacb2dd7976504_jpg.rf.eb41f79339eb1eb855a136c400b4a71f.jpg\n",
            "9fc54a45feb5b01db8f6828d181fb075_jpg.rf.95558424f2db7361bbdb93e8e51e0581.jpg\n",
            "9fc54a45feb5b01db8f6828d181fb075_jpg.rf.9c25b91d55b315043a095051fe813a9c.jpg\n",
            "9fc54a45feb5b01db8f6828d181fb075_jpg.rf.dad9895160ce142893f2d50985161176.jpg\n",
            "a20eb4bb3cea2e394cfcf9ed969b628e_jpg.rf.44943c777028499045c1f45216838729.jpg\n",
            "a20eb4bb3cea2e394cfcf9ed969b628e_jpg.rf.7e25c324029c6bddd1375645580f3009.jpg\n",
            "a20eb4bb3cea2e394cfcf9ed969b628e_jpg.rf.8e7941154e8218bc5c60a42ec75cfbf3.jpg\n",
            "a4028b2361ce7ead654a86b07ac39d52_jpg.rf.55bd810c2826cd5fbda470f36df47735.jpg\n",
            "a4028b2361ce7ead654a86b07ac39d52_jpg.rf.687ddaa40b48884e559d3606486fa7e8.jpg\n",
            "a4028b2361ce7ead654a86b07ac39d52_jpg.rf.f18fa4c1dce2f0387c451354d1e535c0.jpg\n",
            "a4ebf4c268d80c4fe329331ea981b3a1_jpg.rf.12e469ca411a793fab88746c49f8f790.jpg\n",
            "a4ebf4c268d80c4fe329331ea981b3a1_jpg.rf.31a38518592003e6e81426d0090bd58a.jpg\n",
            "a4ebf4c268d80c4fe329331ea981b3a1_jpg.rf.f2ae1ea570213bb9acdec41a1a6bcd09.jpg\n",
            "a5c65b40e0be3480c0ecfacaab399a87_jpg.rf.6147a8d031e8344d640e447c4ba2dbb9.jpg\n",
            "a5c65b40e0be3480c0ecfacaab399a87_jpg.rf.647ac6c3b9611f89b1a7a757f7051b9f.jpg\n",
            "a5c65b40e0be3480c0ecfacaab399a87_jpg.rf.d1364905ffdbf3466eff747cf5948b36.jpg\n",
            "a8847f8fe8eaaa1c97bf83027a901760_jpg.rf.69b91785d4aea8f4199f9c847b918428.jpg\n",
            "a8847f8fe8eaaa1c97bf83027a901760_jpg.rf.6df2ccc6498e99df8337ffb8ab9c488a.jpg\n",
            "a8847f8fe8eaaa1c97bf83027a901760_jpg.rf.cb0f3b1463e92615083e75629be7c4ee.jpg\n",
            "a932287da44b9dfacd0d16a5c1d27923_jpg.rf.76d1125d6c63d8f0206bfcbd6dc6df99.jpg\n",
            "a932287da44b9dfacd0d16a5c1d27923_jpg.rf.d75b9b5fea5a4c7e5b066d3caae98f9b.jpg\n",
            "a932287da44b9dfacd0d16a5c1d27923_jpg.rf.e6af160c98e230c8130c17ccd6787efa.jpg\n",
            "a9768de3fceeeae2618f362870fb9a88_jpg.rf.07e7239539431dfa4ad1282152ccad21.jpg\n",
            "a9768de3fceeeae2618f362870fb9a88_jpg.rf.444b950f0b329aa6e7ed17a86383606d.jpg\n",
            "a9768de3fceeeae2618f362870fb9a88_jpg.rf.ef561195bb5bb73478b957d2958db087.jpg\n",
            "a9987cf6cc5c6545818ec294d4a5bb9b_jpg.rf.562eed600b4725f0697896672ae6ddb2.jpg\n",
            "a9987cf6cc5c6545818ec294d4a5bb9b_jpg.rf.7d8b64ebafca42e4a7e4594d41700858.jpg\n",
            "a9987cf6cc5c6545818ec294d4a5bb9b_jpg.rf.ecb9987509a91f5df7b6dd308fb5edb8.jpg\n",
            "_annotations.txt\n",
            "b0f3d66c8be13f5f6aa25b67a06bdcfa_jpg.rf.2400a74d8ca898058bbfa7a4b2fad3ed.jpg\n",
            "b0f3d66c8be13f5f6aa25b67a06bdcfa_jpg.rf.be26c1b3f90ad3ce201f81d39ce2c7a3.jpg\n",
            "b0f3d66c8be13f5f6aa25b67a06bdcfa_jpg.rf.e2479f30377a357d8c2d24488c666a98.jpg\n",
            "b3b002461f1c6b432e22964549767e5f_jpg.rf.89c6cd251768bebd0f1f27ffa57a4350.jpg\n",
            "b3b002461f1c6b432e22964549767e5f_jpg.rf.a0d7beba87e87043554e0885b9b86897.jpg\n",
            "b3b002461f1c6b432e22964549767e5f_jpg.rf.b2ec1cf3b8d3d761e56314df208ff584.jpg\n",
            "b5102d7f9740eee7754ed268becb2163_jpg.rf.1753afe30d3a07555d21ff985d2b38e9.jpg\n",
            "b5102d7f9740eee7754ed268becb2163_jpg.rf.91e588905afe5d7d801eda5ca9dcd21e.jpg\n",
            "b5102d7f9740eee7754ed268becb2163_jpg.rf.b40f1fbd9b2855b7fa5234eb32c8bb15.jpg\n",
            "b5bcde459ca36f0d1f3c20e751336672_jpg.rf.22bea80464ccb6e4d31ab5c10d11c0f9.jpg\n",
            "b5bcde459ca36f0d1f3c20e751336672_jpg.rf.aaa30a1910b6b485f2feb1daeaac3bde.jpg\n",
            "b5bcde459ca36f0d1f3c20e751336672_jpg.rf.bcad4ddc397a9e93e8f5049dc7d2ac20.jpg\n",
            "b79ae5b70de58089ead6e32b235e30d3_jpg.rf.70249336c8f66aeb7cd2c808d7e0a255.jpg\n",
            "b79ae5b70de58089ead6e32b235e30d3_jpg.rf.df8a88cab326fc33376d82c562d0b45f.jpg\n",
            "b79ae5b70de58089ead6e32b235e30d3_jpg.rf.e843446cbb3275d85d46432364a2d867.jpg\n",
            "b7a8c7de4fe1382d69f58ac97e819b5c_jpg.rf.3c92a450faed773b5607e082e798c7fa.jpg\n",
            "b7a8c7de4fe1382d69f58ac97e819b5c_jpg.rf.a896caf123ecc925575d9922df742758.jpg\n",
            "b7a8c7de4fe1382d69f58ac97e819b5c_jpg.rf.d9033064a02df12bad0b60bda98b1ff6.jpg\n",
            "bb54af2f0b83b174aecc29328c8fa001_jpg.rf.6023d601e15572d6990554f644bb1bfe.jpg\n",
            "bb54af2f0b83b174aecc29328c8fa001_jpg.rf.905a8ad083e59c277bca2ebd076a9ad1.jpg\n",
            "bb54af2f0b83b174aecc29328c8fa001_jpg.rf.a95d3e7492be3741322db734980e4372.jpg\n",
            "bc5decab88861286dcf78a367b4377cb_jpg.rf.118253b02b72c34a332d2bd78746c795.jpg\n",
            "bc5decab88861286dcf78a367b4377cb_jpg.rf.88da334f69a7c36333bc65576f4ffdfe.jpg\n",
            "bc5decab88861286dcf78a367b4377cb_jpg.rf.a4fe058da39ab9ff0b210ff464124bb2.jpg\n",
            "beb11566e59775b61f0ca369952067cc_jpg.rf.56493b995a4c4ae16d241c7e1120a53e.jpg\n",
            "beb11566e59775b61f0ca369952067cc_jpg.rf.5d2e0331a1ac2070a72fc4c12a036f53.jpg\n",
            "beb11566e59775b61f0ca369952067cc_jpg.rf.f912967037a2c28db9c37a7564017dd4.jpg\n",
            "c0d68e012bb93c14bc333fc1d5e52621_jpg.rf.1644855d8e7c4e07a615e02cdd6eb550.jpg\n",
            "c0d68e012bb93c14bc333fc1d5e52621_jpg.rf.7a3c7ca8c5ccc4d7b307f188bbfb0c85.jpg\n",
            "c0d68e012bb93c14bc333fc1d5e52621_jpg.rf.fea60abd21071433619d9002cac1d6c5.jpg\n",
            "c3e9e81ba1540aae7961a4d8d96600ba_jpg.rf.159b3ae18cb81620929e5e4847ab9ed8.jpg\n",
            "c3e9e81ba1540aae7961a4d8d96600ba_jpg.rf.32f7438c342e397838be8189c204446f.jpg\n",
            "c3e9e81ba1540aae7961a4d8d96600ba_jpg.rf.d0ef355e121a971f315ab22160109b11.jpg\n",
            "c46bf04050a2a9323dfe563e8813602f_jpg.rf.2bce3ad335a7be28858cd00cb3f40567.jpg\n",
            "c46bf04050a2a9323dfe563e8813602f_jpg.rf.3c67770c7bc1ae2f34811acc4fea44c1.jpg\n",
            "c46bf04050a2a9323dfe563e8813602f_jpg.rf.ff5a4cfb28be5ab4636539e081efb107.jpg\n",
            "c733616ab773817dd1a356dbbdf2ee33_jpg.rf.8bc96d3c3f94c91defbbb399aeb94bd0.jpg\n",
            "c733616ab773817dd1a356dbbdf2ee33_jpg.rf.8c2d39cca659bfec090ee10dd8062ef5.jpg\n",
            "c733616ab773817dd1a356dbbdf2ee33_jpg.rf.f0637765e389d17285e20d9e98d707bf.jpg\n",
            "c76c79e40bd9839a05237934cfa89ca3_jpg.rf.1bc63c348e985893973dea8fa15569ad.jpg\n",
            "c76c79e40bd9839a05237934cfa89ca3_jpg.rf.9a8aff67f0474c909c78cb647d887169.jpg\n",
            "c76c79e40bd9839a05237934cfa89ca3_jpg.rf.dee57a5076074452c76467e0c19d0ae3.jpg\n",
            "c7890b749d14d3488066cbdfac4620fd_jpg.rf.1efa9f080f6e933d2f5831041808e244.jpg\n",
            "c7890b749d14d3488066cbdfac4620fd_jpg.rf.257e75b14b6cfba7dfa565acc4e09aee.jpg\n",
            "c7890b749d14d3488066cbdfac4620fd_jpg.rf.76f2ad22e2a1c25bc8df3e234a2875e4.jpg\n",
            "ca869123d8a0cbcc6e54f4a445e5a78a_jpg.rf.1b0eec370b291dd2002d949abe4d9786.jpg\n",
            "ca869123d8a0cbcc6e54f4a445e5a78a_jpg.rf.5a9d4bcaf2ccf730c794bb7d57d77524.jpg\n",
            "ca869123d8a0cbcc6e54f4a445e5a78a_jpg.rf.cb3d9d5a5fd961cfb91b7cb00efeab83.jpg\n",
            "cae099fe41d6aa30033d71e433c33c8d_jpg.rf.2c5556b5ec9b5e12bef8a8135dbd3db6.jpg\n",
            "cae099fe41d6aa30033d71e433c33c8d_jpg.rf.4a845b5a7d4639700ca427c1099a1acc.jpg\n",
            "cae099fe41d6aa30033d71e433c33c8d_jpg.rf.e244d328c4a1dc04bdd511daa54a5bcb.jpg\n",
            "ce54969567273b9b8a275812ff56e16c_jpg.rf.29c743680e34c742cc77893515011b9e.jpg\n",
            "ce54969567273b9b8a275812ff56e16c_jpg.rf.9dcc1b3107606542dc0633cbc7ff5026.jpg\n",
            "ce54969567273b9b8a275812ff56e16c_jpg.rf.c314f1d0e3f3e5009805961ff05a7934.jpg\n",
            "cf2784fa97151d5316b2961b1e62dc45_jpg.rf.5d084fce203d3441c10c50c670717b07.jpg\n",
            "cf2784fa97151d5316b2961b1e62dc45_jpg.rf.5e86f14e3c821254e4afac25e3ade2b1.jpg\n",
            "cf2784fa97151d5316b2961b1e62dc45_jpg.rf.fe672984de7dabfff5b9cde323862f11.jpg\n",
            "_classes.txt\n",
            "coco_annotation.py\n",
            "convert.py\n",
            "d079f4e77b2445abceca7534356db743_jpg.rf.15980e0041c274dd182fc8a6bdd25047.jpg\n",
            "d079f4e77b2445abceca7534356db743_jpg.rf.86f033e983acf1e547451e03dee0e582.jpg\n",
            "d079f4e77b2445abceca7534356db743_jpg.rf.e7fc6fdfea0d14dc4c82a6068b9e4159.jpg\n",
            "d0cc2420bce5b14dfd39e55dc3737e57_jpg.rf.798223ce68149c49db97b6936b162fea.jpg\n",
            "d0cc2420bce5b14dfd39e55dc3737e57_jpg.rf.88c1e9b2ecc41404c643afeae66588e3.jpg\n",
            "d0cc2420bce5b14dfd39e55dc3737e57_jpg.rf.a1e5deac03ed76b34211a0db4f49de60.jpg\n",
            "d29148a2233950a7777285281cbfccff_jpg.rf.20e8ed774b4d58497375cf75613ce12f.jpg\n",
            "d29148a2233950a7777285281cbfccff_jpg.rf.40093760ef1ab3612d0c64743229660a.jpg\n",
            "d29148a2233950a7777285281cbfccff_jpg.rf.ac8323d05a30dae895f9f6b84d20ea68.jpg\n",
            "d33c33de41dbe1a95a43212c58fd12b7_jpg.rf.39ad6f496db1c7983d23577c21d6b498.jpg\n",
            "d33c33de41dbe1a95a43212c58fd12b7_jpg.rf.97eb2e7fe56237be37aa16911f677084.jpg\n",
            "d33c33de41dbe1a95a43212c58fd12b7_jpg.rf.b8aeaddf76563fcb8e403f431c8f746f.jpg\n",
            "d3a4e1b8f13ef89f419251f5c5839d0d_jpg.rf.0eac09b57ab66fc36635004e7f2124de.jpg\n",
            "d3a4e1b8f13ef89f419251f5c5839d0d_jpg.rf.12d1445a2e7628e803d679154eafd783.jpg\n",
            "d3a4e1b8f13ef89f419251f5c5839d0d_jpg.rf.52991bd24deab85602f52dda5aca25d4.jpg\n",
            "d415969922564f317be0d1433330626f_jpg.rf.28d3ae6c7470773e33b2e1d8ab45d13b.jpg\n",
            "d415969922564f317be0d1433330626f_jpg.rf.5bc5eaf797dffc2a83bca91da5ebcd80.jpg\n",
            "d415969922564f317be0d1433330626f_jpg.rf.ea52055e8d217e2f8c5f785c5b114aea.jpg\n",
            "d494cb268ad7f9f55587de138edc1dc4_jpg.rf.0b7a384e3d2d7cd15c45edce54fd465a.jpg\n",
            "d494cb268ad7f9f55587de138edc1dc4_jpg.rf.1225ba2bab92010c41fd82111da127c5.jpg\n",
            "d494cb268ad7f9f55587de138edc1dc4_jpg.rf.3b871f28d54bdb72507fb3451f231850.jpg\n",
            "d67b5b9e900409b050dd9bd594f90709_jpg.rf.4ee38829bdf99d869ea4efb62d7b268f.jpg\n",
            "d67b5b9e900409b050dd9bd594f90709_jpg.rf.c8f40141d74f9737a0979fb96b6f34d2.jpg\n",
            "d67b5b9e900409b050dd9bd594f90709_jpg.rf.d4b4698f0544628c496bee35512f21e2.jpg\n",
            "d795f84f39716798482fb2937868ed8a_jpg.rf.3eb9d5c21be9982bc0438b394988ec12.jpg\n",
            "d795f84f39716798482fb2937868ed8a_jpg.rf.62de48b291ec4dab492ffd28d07e46e2.jpg\n",
            "d795f84f39716798482fb2937868ed8a_jpg.rf.cad9a430bd9734f8a4d5a7bbefe008db.jpg\n",
            "d9acc69c5d57623cda22786e309201c9_jpg.rf.163bbc086efbf7cedbb02c4b36c83a28.jpg\n",
            "d9acc69c5d57623cda22786e309201c9_jpg.rf.5ee63a61ee05ff129fdbccefc3a0162e.jpg\n",
            "d9acc69c5d57623cda22786e309201c9_jpg.rf.68535cd44500e60be8d5d02bc2ff3c71.jpg\n",
            "darknet53.cfg\n",
            "dd6b5c3cb2d7e77f38f1dfeb2bff0431_jpg.rf.9a8ea23dbdf192fee0434dbb0eb0f22c.jpg\n",
            "dd6b5c3cb2d7e77f38f1dfeb2bff0431_jpg.rf.cc1ce4e567e8abf653acf2434e59ebdf.jpg\n",
            "dd6b5c3cb2d7e77f38f1dfeb2bff0431_jpg.rf.d5e6c00de132b8eb8ba382332327fb37.jpg\n",
            "ddad9dc4d945006d66f5349d64498559_jpg.rf.36d31b7cdbbe48577906109fa1edf766.jpg\n",
            "ddad9dc4d945006d66f5349d64498559_jpg.rf.48e7a4d1dbc55402801f6f3eb2515561.jpg\n",
            "ddad9dc4d945006d66f5349d64498559_jpg.rf.4a027c535d57e5c9ec84c9180a32c196.jpg\n",
            "de60ba81aa78387928e4bdc11f3be301_jpg.rf.6681071e793fdbd2f46b2f15c20db879.jpg\n",
            "de60ba81aa78387928e4bdc11f3be301_jpg.rf.a7cd83b2e02587367bb3305dbda0b78b.jpg\n",
            "de60ba81aa78387928e4bdc11f3be301_jpg.rf.d5ff9b3d612bf126db5f6959d6bf5cee.jpg\n",
            "e40003d4bbcdac7196b9502bfe2fb6ed_jpg.rf.b847f770b71b7f853198176ef25b8516.jpg\n",
            "e40003d4bbcdac7196b9502bfe2fb6ed_jpg.rf.d6bf64a0bd417c7ffc6c45fc60fb02a5.jpg\n",
            "e40003d4bbcdac7196b9502bfe2fb6ed_jpg.rf.fff02b8d5496821ff5b6def111287362.jpg\n",
            "e6e3a2ff2c75970490079f00136885ad_jpg.rf.196dbeb361aea01da0d89796ee64e56b.jpg\n",
            "e6e3a2ff2c75970490079f00136885ad_jpg.rf.a604bf09d249b5f66896ab2dbadd1a85.jpg\n",
            "e6e3a2ff2c75970490079f00136885ad_jpg.rf.bf5f02039da79608e7ba637b0f18b8dc.jpg\n",
            "e79deba8fe520409790b601ad61da4ee_jpg.rf.4d07e4475f01148efb81bd6fa74b14ea.jpg\n",
            "e79deba8fe520409790b601ad61da4ee_jpg.rf.83a6e8ba2d0d752b3ab81886c1c838bf.jpg\n",
            "e79deba8fe520409790b601ad61da4ee_jpg.rf.c5ace9198f249698fecd9cd44699ad3e.jpg\n",
            "e8480d7fb9881d8a0e88b7be4d103f6d_jpg.rf.45bdf3534f70d8ac1475f0521b4480b0.jpg\n",
            "e8480d7fb9881d8a0e88b7be4d103f6d_jpg.rf.928686545c1fc6e46d2b584750b57d37.jpg\n",
            "e8480d7fb9881d8a0e88b7be4d103f6d_jpg.rf.f5a8297fdaadf713f5aa50520a5aae2f.jpg\n",
            "ea799d77875c399618c45cd9409f34ee_jpg.rf.20f1e302ce66ba51ba16dd954123378d.jpg\n",
            "ea799d77875c399618c45cd9409f34ee_jpg.rf.3cbbfad204c76abb175b51ac851c1b6b.jpg\n",
            "ea799d77875c399618c45cd9409f34ee_jpg.rf.73793ae5eedc9e1a2ec843305741e27c.jpg\n",
            "eb9e7928e756c3cf9164e7afc08c4653_jpg.rf.268e96829cc026a5763f0182c1e8b842.jpg\n",
            "eb9e7928e756c3cf9164e7afc08c4653_jpg.rf.746289ad0d0f3f589717876a2b835faa.jpg\n",
            "eb9e7928e756c3cf9164e7afc08c4653_jpg.rf.7f6a60da5223783cc3525b307708142a.jpg\n",
            "ec4c30d88ecc70b6a3e76dbd9b17324a_jpg.rf.334f863b8bb588cb413d6f23e5c572e3.jpg\n",
            "ec4c30d88ecc70b6a3e76dbd9b17324a_jpg.rf.a3a828973a59e98475fa9d4c9b3bc6b0.jpg\n",
            "ec4c30d88ecc70b6a3e76dbd9b17324a_jpg.rf.aaf770cf8e03c34de0727104563ac2ee.jpg\n",
            "ec5ab1930d6aa16fff2582b48f82cada_jpg.rf.9ed7a8384c58e621e1bd8d199c9911eb.jpg\n",
            "ec5ab1930d6aa16fff2582b48f82cada_jpg.rf.a4317db23e4c499293ae36f9fd900360.jpg\n",
            "ec5ab1930d6aa16fff2582b48f82cada_jpg.rf.aae26a4e7732a2ecb663aca13ca5e2be.jpg\n",
            "edd285915356686fb53fb52c1ded0e53_jpg.rf.575ba04e0fde0ae4a7556799951ffb28.jpg\n",
            "edd285915356686fb53fb52c1ded0e53_jpg.rf.c889f2395a10814f1b3bc7c2eff34762.jpg\n",
            "edd285915356686fb53fb52c1ded0e53_jpg.rf.db25cbd151cf96bddaea8e570c74aa8a.jpg\n",
            "ef1d425fd5370fbf8b7adea43b755304_jpg.rf.098e333d5b6303fdc9c280fbaf5a79c4.jpg\n",
            "ef1d425fd5370fbf8b7adea43b755304_jpg.rf.c511c91a1669993209db75e7013631ba.jpg\n",
            "ef1d425fd5370fbf8b7adea43b755304_jpg.rf.f7787e4a869bce3acd75d98f934e857e.jpg\n",
            "f02d615907c77dc15f02bd1372e4398f_jpg.rf.30b6af213aeb1691056f9bdf8c568ffc.jpg\n",
            "f02d615907c77dc15f02bd1372e4398f_jpg.rf.8557a2e6c1a157a570333dd454271cb0.jpg\n",
            "f02d615907c77dc15f02bd1372e4398f_jpg.rf.ba5c8eb326916870dab8aeef50cd91ec.jpg\n",
            "f041d3171dfe3137390c85fc5437e447_jpg.rf.3020fee02bc4def16c99bed406ad8671.jpg\n",
            "f041d3171dfe3137390c85fc5437e447_jpg.rf.594627e68a410fbed5266fde10811a18.jpg\n",
            "f041d3171dfe3137390c85fc5437e447_jpg.rf.a4744a0326d7d31d016563fd0ab94aea.jpg\n",
            "f1ea0167087976926d4fe0aa36b961ce_jpg.rf.792c747c6116ade848581cd7c6be27e2.jpg\n",
            "f1ea0167087976926d4fe0aa36b961ce_jpg.rf.7cfb591bdf3cb30001cfecb3b153724e.jpg\n",
            "f1ea0167087976926d4fe0aa36b961ce_jpg.rf.afe8570c46a7a9651d7353b8f753e9c7.jpg\n",
            "f2672cdc28767484b556da3ab6f1003e_jpg.rf.1e58ffa93dd27f57436a6b49d82d98e7.jpg\n",
            "f2672cdc28767484b556da3ab6f1003e_jpg.rf.3509d0a9193d954d2cef5fc1371760c4.jpg\n",
            "f2672cdc28767484b556da3ab6f1003e_jpg.rf.eb54d003a3fad58875432fdfef1764bc.jpg\n",
            "f3302c754c6fd42130014199ee327d10_jpg.rf.5a539486e56c8a43d6c4eb79bf8390cf.jpg\n",
            "f3302c754c6fd42130014199ee327d10_jpg.rf.ac1176b46e92b65a435b4c64bde17da7.jpg\n",
            "f3302c754c6fd42130014199ee327d10_jpg.rf.f184e1e646cf33f3fa880c05ab94984c.jpg\n",
            "f3a5df526393445c6e2d38f66c1f5c27_jpg.rf.30434c68a81ca711cc012fba179621fb.jpg\n",
            "f3a5df526393445c6e2d38f66c1f5c27_jpg.rf.4318c9a5d50fd309db266f4e848a1202.jpg\n",
            "f3a5df526393445c6e2d38f66c1f5c27_jpg.rf.7313c3f78aaf7e508f685612f68538c7.jpg\n",
            "f52e1873b8583f8bf4f7ddf6e9649f07_jpg.rf.2537eb51bebf5c74c4bd317859fdeae6.jpg\n",
            "f52e1873b8583f8bf4f7ddf6e9649f07_jpg.rf.501bcfa0d1fb2050080a5caa9ce7ee07.jpg\n",
            "f52e1873b8583f8bf4f7ddf6e9649f07_jpg.rf.f49dc0690959dadeb1524da1a3cb38f7.jpg\n",
            "f587402be410b424bcbbac06e1dc6162_jpg.rf.23f779c5fef0d59e809103bf5bd3b7a3.jpg\n",
            "f587402be410b424bcbbac06e1dc6162_jpg.rf.b4179f89a43522928b4423c1bf422e3e.jpg\n",
            "f587402be410b424bcbbac06e1dc6162_jpg.rf.e827e0b68851bce5ae35b7bc5e7c0c4e.jpg\n",
            "f9a9a175f26d4b26bca3a5338cc1405e_jpg.rf.1bfc00ef85611686b0566f4ea49a4c9f.jpg\n",
            "f9a9a175f26d4b26bca3a5338cc1405e_jpg.rf.3260d2b6441db8b3e01beb6e26540341.jpg\n",
            "f9a9a175f26d4b26bca3a5338cc1405e_jpg.rf.d028744643f733777684eace4ef99cd6.jpg\n",
            "fa3cf2724c1648a8822b59ac0759475f_jpg.rf.2503a3b4a48386cdce9d069893234e2b.jpg\n",
            "fa3cf2724c1648a8822b59ac0759475f_jpg.rf.577379a932d9dff33794eba38ee6340d.jpg\n",
            "fa3cf2724c1648a8822b59ac0759475f_jpg.rf.89df60eac6ac5c0f593914ab045233d0.jpg\n",
            "fa4e2b9a8cf58f405f69a56c662834f2_jpg.rf.29021f89f2a16c44ecb9f34623bd3a9a.jpg\n",
            "fa4e2b9a8cf58f405f69a56c662834f2_jpg.rf.97f7416f560f73f366f58f69446c9287.jpg\n",
            "fa4e2b9a8cf58f405f69a56c662834f2_jpg.rf.d612185e16b2f1e8680764ed00dd4711.jpg\n",
            "fb586797e8ad818c7e3e3a6411f73d84_jpg.rf.57db9c805851d5fdc9e3a5f28e9717bb.jpg\n",
            "fb586797e8ad818c7e3e3a6411f73d84_jpg.rf.85d8f5b9e28cd8b994d730f9e135ab6d.jpg\n",
            "fb586797e8ad818c7e3e3a6411f73d84_jpg.rf.ed5a5085ee7d3245a50079b0e080ab12.jpg\n",
            "fc9d7bc0453cb3324406401c00224d30_jpg.rf.172aecee627f7179de58fbbc01d619f8.jpg\n",
            "fc9d7bc0453cb3324406401c00224d30_jpg.rf.d5b9739fe980fcc412eb535b6d177524.jpg\n",
            "fc9d7bc0453cb3324406401c00224d30_jpg.rf.e9e48a12d9bcbcb2a03df0571e7617b6.jpg\n",
            "\u001b[0m\u001b[01;34mfont\u001b[0m/\n",
            "IMG_0166_JPG.rf.1b943996d63e88f793c9225b051e88aa.jpg\n",
            "IMG_0166_JPG.rf.5496677843330113f25e1d96d9e5501c.jpg\n",
            "IMG_0166_JPG.rf.866e83ca31acd30da2673fcb7e2abbfe.jpg\n",
            "IMG_0167_JPG.rf.51e844ec48d744ea0d541c3978e68c8f.jpg\n",
            "IMG_0167_JPG.rf.5ef94865f654a98f644c83ec15c0c7f0.jpg\n",
            "IMG_0167_JPG.rf.700e471552dde4992d80e528387e102f.jpg\n",
            "IMG_0291_JPG.rf.0c3ecbe3fa43d54ee4fbee9f4be3c957.jpg\n",
            "IMG_0291_JPG.rf.d2ba6353082aa25c15708824c08dfb27.jpg\n",
            "IMG_0291_JPG.rf.df9096730aa1a08ad2999bcd27d3ce48.jpg\n",
            "IMG_0292_JPG.rf.430049672fd781b9df9e34badf1b48a8.jpg\n",
            "IMG_0292_JPG.rf.5eba9597d38f1d22018bb5d619ef742e.jpg\n",
            "IMG_0292_JPG.rf.baaccc7cf58cb3b0c9d1bc3f1ce32a3d.jpg\n",
            "IMG_0294_JPG.rf.517f9201b72a4266d46b2954a0f80c14.jpg\n",
            "IMG_0294_JPG.rf.bd8d20acd3d837e056c6714500e83270.jpg\n",
            "IMG_0294_JPG.rf.cb349f708d70f8f46097636ec55f5419.jpg\n",
            "IMG_0295_JPG.rf.282c3259eadee31b6cfd1548f0aa4e6d.jpg\n",
            "IMG_0295_JPG.rf.32f999d96696f80ebe62ade6437b2fe2.jpg\n",
            "IMG_0295_JPG.rf.939fab6c2495e85e1b177306373fbe6e.jpg\n",
            "IMG_0296_JPG.rf.530c25c318deab34b53cadb7918fa500.jpg\n",
            "IMG_0296_JPG.rf.e8332a65a587b3f337f25bca237988af.jpg\n",
            "IMG_0296_JPG.rf.fe6246bc705bb866f527a6ae2efb1b99.jpg\n",
            "IMG_0297_JPG.rf.47e3984909ef5581659ae1a350978094.jpg\n",
            "IMG_0297_JPG.rf.5e635cca1323148499732eaf858ba2b2.jpg\n",
            "IMG_0297_JPG.rf.a66ff62117c20eb55204281f042b32c7.jpg\n",
            "IMG_0298_JPG.rf.5b5e7dd4118e128457567019a928e264.jpg\n",
            "IMG_0298_JPG.rf.6d6ac51367b303c05c261e7e8b11de67.jpg\n",
            "IMG_0298_JPG.rf.c72da1b09a38ec0adab3af9bb3abc0c1.jpg\n",
            "IMG_0299_JPG.rf.4d6c7558e7fd08da45a6fabde3296e5b.jpg\n",
            "IMG_0299_JPG.rf.9f796e9ea3695af07f61b110f53ee45f.jpg\n",
            "IMG_0299_JPG.rf.ae4ab20b4db16431416f89b8d9582906.jpg\n",
            "IMG_0317_JPG.rf.00207d2fe8c0a0f20715333d49d22b4f.jpg\n",
            "IMG_0317_JPG.rf.b4f86e6c57fca84c485b3bbcde731959.jpg\n",
            "IMG_0317_JPG.rf.c4575757a6e19ad9fb88d28b1a15193e.jpg\n",
            "IMG_0318_JPG.rf.60de6e8f2c9365770ed11379dfd1cb55.jpg\n",
            "IMG_0318_JPG.rf.8d091ab4bbe2cd70b92ad64592315ac8.jpg\n",
            "IMG_0318_JPG.rf.f752cb565b0c634895506816ba026b7e.jpg\n",
            "kmeans.py\n",
            "LICENSE\n",
            "\u001b[01;34mmodel_data\u001b[0m/\n",
            "README.dataset.txt\n",
            "README.md\n",
            "README.roboflow.txt\n",
            "\u001b[01;34mtest\u001b[0m/\n",
            "\u001b[01;34mtrain\u001b[0m/\n",
            "train_bottleneck.py\n",
            "train.py\n",
            "Tutorial.ipynb\n",
            "\u001b[01;34mvalid\u001b[0m/\n",
            "voc_annotation.py\n",
            "\u001b[01;34myolo3\u001b[0m/\n",
            "yolo.py\n",
            "yolov3.cfg\n",
            "yolov3-tiny.cfg\n",
            "yolo_video.py\n"
          ]
        }
      ],
      "source": [
        "# show that all our images, _annotations.txt, and _classes.txt made it to our root directory\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvzqgP92W7bt"
      },
      "source": [
        "## Set up and train our model\n",
        "\n",
        "Next, we'll download pre-trained weighs weights from DarkNet, set up our YOLOv3 architecture with those pre-trained weights, and initiate training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJzW08g2VlwD",
        "outputId": "5328606c-7505-4c48-9924-0aef129ef3b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-01 09:21:31--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 162.0.215.52\n",
            "Connecting to pjreddie.com (pjreddie.com)|162.0.215.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: â€˜yolov3.weightsâ€™\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  20.2MB/s    in 11s     \n",
            "\n",
            "2024-04-01 09:22:17 (22.1 MB/s) - â€˜yolov3.weightsâ€™ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download our DarkNet weights\n",
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITgjTyPYrkST"
      },
      "source": [
        "In dependency errors change modeules in `model.py` and `convert.py` as tensorflow modules are outdated: <br>\n",
        "- `from keras.layers import LeakyReLU`\n",
        "- `from keras.layers import BatchNormalization`\n",
        "- `import matplotlib.pyplot as plot`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mub8GJMBVluA",
        "outputId": "a27338ae-5309-4b20-d54b-c486b93df49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Loading weights.\n",
            "Weights Header:  0 2 0 [32013312]\n",
            "Parsing Darknet config.\n",
            "Creating Keras model.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "Parsing section net_0\n",
            "Parsing section convolutional_0\n",
            "conv2d bn leaky (3, 3, 3, 32)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2024-04-01 09:22:20.305036: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2024-04-01 09:22:20.311279: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2024-04-01 09:22:20.311483: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x486ebc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2024-04-01 09:22:20.311513: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2024-04-01 09:22:20.313870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2024-04-01 09:22:20.644125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-04-01 09:22:20.644531: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x485bcd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2024-04-01 09:22:20.644566: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2024-04-01 09:22:20.645354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-04-01 09:22:20.645560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2024-04-01 09:22:20.645891: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-04-01 09:22:20.646136: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-04-01 09:22:20.646363: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-04-01 09:22:20.646542: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-04-01 09:22:20.646728: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-04-01 09:22:20.646895: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-04-01 09:22:20.647065: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-04-01 09:22:20.647086: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2024-04-01 09:22:20.647123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2024-04-01 09:22:20.647136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2024-04-01 09:22:20.647147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Parsing section convolutional_1\n",
            "conv2d bn leaky (3, 3, 32, 64)\n",
            "Parsing section convolutional_2\n",
            "conv2d bn leaky (1, 1, 64, 32)\n",
            "Parsing section convolutional_3\n",
            "conv2d bn leaky (3, 3, 32, 64)\n",
            "Parsing section shortcut_0\n",
            "Parsing section convolutional_4\n",
            "conv2d bn leaky (3, 3, 64, 128)\n",
            "Parsing section convolutional_5\n",
            "conv2d bn leaky (1, 1, 128, 64)\n",
            "Parsing section convolutional_6\n",
            "conv2d bn leaky (3, 3, 64, 128)\n",
            "Parsing section shortcut_1\n",
            "Parsing section convolutional_7\n",
            "conv2d bn leaky (1, 1, 128, 64)\n",
            "Parsing section convolutional_8\n",
            "conv2d bn leaky (3, 3, 64, 128)\n",
            "Parsing section shortcut_2\n",
            "Parsing section convolutional_9\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_10\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_11\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_3\n",
            "Parsing section convolutional_12\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_13\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_4\n",
            "Parsing section convolutional_14\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_15\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_5\n",
            "Parsing section convolutional_16\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_17\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_6\n",
            "Parsing section convolutional_18\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_19\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_7\n",
            "Parsing section convolutional_20\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_21\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_8\n",
            "Parsing section convolutional_22\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_23\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_9\n",
            "Parsing section convolutional_24\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_25\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_10\n",
            "Parsing section convolutional_26\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_27\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_28\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_11\n",
            "Parsing section convolutional_29\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_30\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_12\n",
            "Parsing section convolutional_31\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_32\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_13\n",
            "Parsing section convolutional_33\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_34\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_14\n",
            "Parsing section convolutional_35\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_36\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_15\n",
            "Parsing section convolutional_37\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_38\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_16\n",
            "Parsing section convolutional_39\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_40\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_17\n",
            "Parsing section convolutional_41\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_42\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_18\n",
            "Parsing section convolutional_43\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_44\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_45\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_19\n",
            "Parsing section convolutional_46\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_47\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_20\n",
            "Parsing section convolutional_48\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_49\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_21\n",
            "Parsing section convolutional_50\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_51\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_22\n",
            "Parsing section convolutional_52\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_53\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_54\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_55\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_56\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_57\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_58\n",
            "conv2d    linear (1, 1, 1024, 255)\n",
            "Parsing section yolo_0\n",
            "Parsing section route_0\n",
            "Parsing section convolutional_59\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section upsample_0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Parsing section route_1\n",
            "Concatenating route layers: [<tf.Tensor 'up_sampling2d_1/ResizeNearestNeighbor:0' shape=(?, ?, ?, 256) dtype=float32>, <tf.Tensor 'add_19/add:0' shape=(?, ?, ?, 512) dtype=float32>]\n",
            "Parsing section convolutional_60\n",
            "conv2d bn leaky (1, 1, 768, 256)\n",
            "Parsing section convolutional_61\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_62\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_63\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_64\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_65\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_66\n",
            "conv2d    linear (1, 1, 512, 255)\n",
            "Parsing section yolo_1\n",
            "Parsing section route_2\n",
            "Parsing section convolutional_67\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section upsample_1\n",
            "Parsing section route_3\n",
            "Concatenating route layers: [<tf.Tensor 'up_sampling2d_2/ResizeNearestNeighbor:0' shape=(?, ?, ?, 128) dtype=float32>, <tf.Tensor 'add_11/add:0' shape=(?, ?, ?, 256) dtype=float32>]\n",
            "Parsing section convolutional_68\n",
            "conv2d bn leaky (1, 1, 384, 128)\n",
            "Parsing section convolutional_69\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_70\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_71\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_72\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_73\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_74\n",
            "conv2d    linear (1, 1, 256, 255)\n",
            "Parsing section yolo_2\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 3 128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, None, None, 3 0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 6 18432       zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 6 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 3 2048        leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 3 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, None, None, 6 18432       leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, None, None, 6 256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 6 0           leaky_re_lu_2[0][0]              \n",
            "                                                                 leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, None, None, 6 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, None, None, 1 73728       zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, None, None, 1 512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, None, None, 6 8192        leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, None, None, 6 256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, None, None, 1 512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 1 0           leaky_re_lu_5[0][0]              \n",
            "                                                                 leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, None, None, 6 8192        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, None, None, 6 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, None, None, 1 512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 1 0           add_2[0][0]                      \n",
            "                                                                 leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, None, None, 1 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, None, None, 2 294912      zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, None, None, 2 1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, None, None, 1 512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, None, None, 2 1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 2 0           leaky_re_lu_10[0][0]             \n",
            "                                                                 leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, None, None, 1 32768       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, None, None, 1 512         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, None, None, 2 1024        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 2 0           add_4[0][0]                      \n",
            "                                                                 leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, None, None, 1 32768       add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, None, None, 1 512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, None, None, 2 1024        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 2 0           add_5[0][0]                      \n",
            "                                                                 leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, None, None, 1 32768       add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, None, None, 1 512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, None, None, 2 1024        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 2 0           add_6[0][0]                      \n",
            "                                                                 leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, None, None, 1 32768       add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, None, None, 1 512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, None, None, 2 1024        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 2 0           add_7[0][0]                      \n",
            "                                                                 leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, None, None, 1 32768       add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, None, None, 1 512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, None, None, 2 1024        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 2 0           add_8[0][0]                      \n",
            "                                                                 leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, None, None, 1 32768       add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, None, None, 1 512         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, None, None, 2 1024        conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 2 0           add_9[0][0]                      \n",
            "                                                                 leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, None, None, 1 32768       add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, None, None, 1 512         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, None, None, 2 1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 2 0           add_10[0][0]                     \n",
            "                                                                 leaky_re_lu_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, None, None, 2 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, None, None, 5 1179648     zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, None, None, 5 2048        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, None, None, 2 1024        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, None, None, 5 2048        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, None, None, 5 0           leaky_re_lu_27[0][0]             \n",
            "                                                                 leaky_re_lu_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, None, None, 2 131072      add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, None, None, 2 1024        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, None, None, 5 2048        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, None, None, 5 0           add_12[0][0]                     \n",
            "                                                                 leaky_re_lu_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, None, None, 2 131072      add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, None, None, 2 1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, None, None, 5 2048        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, None, None, 5 0           add_13[0][0]                     \n",
            "                                                                 leaky_re_lu_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, None, None, 2 131072      add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, None, None, 2 1024        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, None, None, 5 2048        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_35 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, None, None, 5 0           add_14[0][0]                     \n",
            "                                                                 leaky_re_lu_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, None, None, 2 131072      add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, None, None, 2 1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, None, None, 5 2048        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_37 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, None, None, 5 0           add_15[0][0]                     \n",
            "                                                                 leaky_re_lu_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, None, None, 2 131072      add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, None, None, 2 1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_38 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, None, None, 5 2048        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_39 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, None, None, 5 0           add_16[0][0]                     \n",
            "                                                                 leaky_re_lu_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, None, None, 2 131072      add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, None, None, 2 1024        conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_40 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, None, None, 5 2048        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_41 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, None, None, 5 0           add_17[0][0]                     \n",
            "                                                                 leaky_re_lu_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, None, None, 2 131072      add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, None, None, 2 1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_42 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, None, None, 5 2048        conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_43 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, None, None, 5 0           add_18[0][0]                     \n",
            "                                                                 leaky_re_lu_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, None, None, 5 0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, None, None, 1 4718592     zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, None, None, 1 4096        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_44 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, None, None, 5 2048        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_45 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, None, None, 1 4096        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_46 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, None, None, 1 0           leaky_re_lu_44[0][0]             \n",
            "                                                                 leaky_re_lu_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, None, None, 5 524288      add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, None, None, 5 2048        conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_47 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, None, None, 1 4096        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_48 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, None, None, 1 0           add_20[0][0]                     \n",
            "                                                                 leaky_re_lu_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, None, None, 5 524288      add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, None, None, 5 2048        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_49 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, None, None, 1 4096        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_50 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, None, None, 1 0           add_21[0][0]                     \n",
            "                                                                 leaky_re_lu_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, None, None, 5 524288      add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, None, None, 5 2048        conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_51 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, None, None, 1 4096        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_52 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, None, None, 1 0           add_22[0][0]                     \n",
            "                                                                 leaky_re_lu_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, None, None, 5 524288      add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, None, None, 5 2048        conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_53 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, None, None, 1 4096        conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_54 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, None, None, 5 2048        conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_55 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, None, None, 1 4096        conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_56 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, None, None, 5 2048        conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_57 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, None, None, 2 1024        conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_59 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, None, None, 2 0           leaky_re_lu_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, None, 7 0           up_sampling2d_1[0][0]            \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, None, None, 2 196608      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, None, None, 2 1024        conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_60 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, None, None, 5 2048        conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_61 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, None, None, 2 1024        conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_62 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, None, None, 5 2048        conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_63 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, None, None, 2 1024        conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_64 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, None, None, 1 512         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_66 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, None, None, 1 0           leaky_re_lu_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, None, None, 3 0           up_sampling2d_2[0][0]            \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, None, None, 1 49152       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, None, None, 1 512         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_67 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, None, None, 2 1024        conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_68 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, None, None, 1 512         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_69 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_69[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, None, None, 2 1024        conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_70 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_70[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, None, None, 1 512         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_71 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, None, None, 1 4096        conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, None, None, 5 2048        conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, None, None, 2 1024        conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_58 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_65 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_72 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, None, None, 2 261375      leaky_re_lu_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, None, None, 2 130815      leaky_re_lu_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, None, None, 2 65535       leaky_re_lu_72[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 62,001,757\n",
            "Trainable params: 61,949,149\n",
            "Non-trainable params: 52,608\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Saved Keras model to model_data/yolo.h5\n",
            "Read 62001757 of 62001757.0 from Darknet weights.\n"
          ]
        }
      ],
      "source": [
        "# call a Python script to set up our architecture with downloaded pre-trained weights\n",
        "!python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEDHwJ36YyXA"
      },
      "source": [
        "Below, we'll call a \"self-contained\" Python script that initiates training our model on our custom dataset.\n",
        "\n",
        "Pay notable attention to:\n",
        "- setting the paths for our `annotation_path`, `classes_path`, `class_names`. If you move the Roboflow data location, you'll need to update these.\n",
        "- `val_split` dictates the size of our training data relative to our taining data\n",
        "- `lr=1e-3` to set the learning rate of the model. Smaller optimizes more slowly but potentially more precisely.\n",
        "- `batch_size` for the number of images trained per batch\n",
        "-  `epoch` inside `model.fit_generator()` sets the number training epochs to increase/decrease training examples (and time)\n",
        "\n",
        "Consider reading the YOLOv3 paper [here](https://pjreddie.com/media/files/papers/YOLOv3.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A-TrrRTXqc2"
      },
      "source": [
        "To resolve dependencoes the following should be editted in the `model.py`:\n",
        "- from `keras.layers.advanced_activations` to `from keras.layers import LeakyReLU`\n",
        "- from `from keras.layers.normalization import BatchNormalization` to `from keras.layers import BatchNormalization`\n",
        "- from `K.control_flow_ops.while_loop` to `tf.while_loop`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4hBFndz8VeI6",
        "outputId": "0a72a5b5-734d-4af4-9cf3-8d2281e2f845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------CLASS NAMES-------------------\n",
            "['bishop', 'black-bishop', 'black-king', 'black-knight', 'black-pawn', 'black-queen', 'black-rook', 'white-bishop', 'white-king', 'white-knight', 'white-pawn', 'white-queen', 'white-rook']\n",
            "-------------------CLASS NAMES-------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping loading weights for layer #1 (named conv2d_1) due to mismatch in shape for weight conv2d_1/kernel:0. Weight expects shape (3, 3, 32, 64). Received saved weight with shape (32, 3, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #2 (named batch_normalization_1) due to mismatch in shape for weight batch_normalization_1/gamma:0. Weight expects shape (64,). Received saved weight with shape (32,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #2 (named batch_normalization_1) due to mismatch in shape for weight batch_normalization_1/beta:0. Weight expects shape (64,). Received saved weight with shape (32,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #2 (named batch_normalization_1) due to mismatch in shape for weight batch_normalization_1/moving_mean:0. Weight expects shape (64,). Received saved weight with shape (32,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #2 (named batch_normalization_1) due to mismatch in shape for weight batch_normalization_1/moving_variance:0. Weight expects shape (64,). Received saved weight with shape (32,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #5 (named conv2d_2) due to mismatch in shape for weight conv2d_2/kernel:0. Weight expects shape (1, 1, 64, 32). Received saved weight with shape (64, 32, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #6 (named batch_normalization_2) due to mismatch in shape for weight batch_normalization_2/gamma:0. Weight expects shape (32,). Received saved weight with shape (64,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #6 (named batch_normalization_2) due to mismatch in shape for weight batch_normalization_2/beta:0. Weight expects shape (32,). Received saved weight with shape (64,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #6 (named batch_normalization_2) due to mismatch in shape for weight batch_normalization_2/moving_mean:0. Weight expects shape (32,). Received saved weight with shape (64,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #6 (named batch_normalization_2) due to mismatch in shape for weight batch_normalization_2/moving_variance:0. Weight expects shape (32,). Received saved weight with shape (64,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #8 (named conv2d_3) due to mismatch in shape for weight conv2d_3/kernel:0. Weight expects shape (3, 3, 32, 64). Received saved weight with shape (32, 64, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #9 (named batch_normalization_3) due to mismatch in shape for weight batch_normalization_3/gamma:0. Weight expects shape (64,). Received saved weight with shape (32,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #9 (named batch_normalization_3) due to mismatch in shape for weight batch_normalization_3/beta:0. Weight expects shape (64,). Received saved weight with shape (32,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #9 (named batch_normalization_3) due to mismatch in shape for weight batch_normalization_3/moving_mean:0. Weight expects shape (64,). Received saved weight with shape (32,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #9 (named batch_normalization_3) due to mismatch in shape for weight batch_normalization_3/moving_variance:0. Weight expects shape (64,). Received saved weight with shape (32,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #11 (named conv2d_4) due to mismatch in shape for weight conv2d_4/kernel:0. Weight expects shape (3, 3, 64, 128). Received saved weight with shape (64, 32, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #12 (named batch_normalization_4) due to mismatch in shape for weight batch_normalization_4/gamma:0. Weight expects shape (128,). Received saved weight with shape (64,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #12 (named batch_normalization_4) due to mismatch in shape for weight batch_normalization_4/beta:0. Weight expects shape (128,). Received saved weight with shape (64,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #12 (named batch_normalization_4) due to mismatch in shape for weight batch_normalization_4/moving_mean:0. Weight expects shape (128,). Received saved weight with shape (64,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #12 (named batch_normalization_4) due to mismatch in shape for weight batch_normalization_4/moving_variance:0. Weight expects shape (128,). Received saved weight with shape (64,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #16 (named conv2d_5) due to mismatch in shape for weight conv2d_5/kernel:0. Weight expects shape (1, 1, 128, 64). Received saved weight with shape (128, 64, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #17 (named batch_normalization_5) due to mismatch in shape for weight batch_normalization_5/gamma:0. Weight expects shape (64,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #17 (named batch_normalization_5) due to mismatch in shape for weight batch_normalization_5/beta:0. Weight expects shape (64,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #17 (named batch_normalization_5) due to mismatch in shape for weight batch_normalization_5/moving_mean:0. Weight expects shape (64,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #17 (named batch_normalization_5) due to mismatch in shape for weight batch_normalization_5/moving_variance:0. Weight expects shape (64,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #19 (named conv2d_6) due to mismatch in shape for weight conv2d_6/kernel:0. Weight expects shape (3, 3, 64, 128). Received saved weight with shape (64, 128, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #20 (named batch_normalization_6) due to mismatch in shape for weight batch_normalization_6/gamma:0. Weight expects shape (128,). Received saved weight with shape (64,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #20 (named batch_normalization_6) due to mismatch in shape for weight batch_normalization_6/beta:0. Weight expects shape (128,). Received saved weight with shape (64,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #20 (named batch_normalization_6) due to mismatch in shape for weight batch_normalization_6/moving_mean:0. Weight expects shape (128,). Received saved weight with shape (64,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #20 (named batch_normalization_6) due to mismatch in shape for weight batch_normalization_6/moving_variance:0. Weight expects shape (128,). Received saved weight with shape (64,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #22 (named conv2d_7) due to mismatch in shape for weight conv2d_7/kernel:0. Weight expects shape (1, 1, 128, 64). Received saved weight with shape (128, 64, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #23 (named batch_normalization_7) due to mismatch in shape for weight batch_normalization_7/gamma:0. Weight expects shape (64,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #23 (named batch_normalization_7) due to mismatch in shape for weight batch_normalization_7/beta:0. Weight expects shape (64,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #23 (named batch_normalization_7) due to mismatch in shape for weight batch_normalization_7/moving_mean:0. Weight expects shape (64,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #23 (named batch_normalization_7) due to mismatch in shape for weight batch_normalization_7/moving_variance:0. Weight expects shape (64,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #26 (named conv2d_8) due to mismatch in shape for weight conv2d_8/kernel:0. Weight expects shape (3, 3, 64, 128). Received saved weight with shape (64, 128, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #27 (named batch_normalization_8) due to mismatch in shape for weight batch_normalization_8/gamma:0. Weight expects shape (128,). Received saved weight with shape (64,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #27 (named batch_normalization_8) due to mismatch in shape for weight batch_normalization_8/beta:0. Weight expects shape (128,). Received saved weight with shape (64,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #27 (named batch_normalization_8) due to mismatch in shape for weight batch_normalization_8/moving_mean:0. Weight expects shape (128,). Received saved weight with shape (64,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #27 (named batch_normalization_8) due to mismatch in shape for weight batch_normalization_8/moving_variance:0. Weight expects shape (128,). Received saved weight with shape (64,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #29 (named conv2d_9) due to mismatch in shape for weight conv2d_9/kernel:0. Weight expects shape (3, 3, 128, 256). Received saved weight with shape (128, 64, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #30 (named batch_normalization_9) due to mismatch in shape for weight batch_normalization_9/gamma:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #30 (named batch_normalization_9) due to mismatch in shape for weight batch_normalization_9/beta:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #30 (named batch_normalization_9) due to mismatch in shape for weight batch_normalization_9/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #30 (named batch_normalization_9) due to mismatch in shape for weight batch_normalization_9/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #34 (named conv2d_10) due to mismatch in shape for weight conv2d_10/kernel:0. Weight expects shape (1, 1, 256, 128). Received saved weight with shape (256, 128, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #35 (named batch_normalization_10) due to mismatch in shape for weight batch_normalization_10/gamma:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #35 (named batch_normalization_10) due to mismatch in shape for weight batch_normalization_10/beta:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #35 (named batch_normalization_10) due to mismatch in shape for weight batch_normalization_10/moving_mean:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #35 (named batch_normalization_10) due to mismatch in shape for weight batch_normalization_10/moving_variance:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #37 (named conv2d_11) due to mismatch in shape for weight conv2d_11/kernel:0. Weight expects shape (3, 3, 128, 256). Received saved weight with shape (128, 256, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #38 (named batch_normalization_11) due to mismatch in shape for weight batch_normalization_11/gamma:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #38 (named batch_normalization_11) due to mismatch in shape for weight batch_normalization_11/beta:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #38 (named batch_normalization_11) due to mismatch in shape for weight batch_normalization_11/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #38 (named batch_normalization_11) due to mismatch in shape for weight batch_normalization_11/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #40 (named conv2d_12) due to mismatch in shape for weight conv2d_12/kernel:0. Weight expects shape (1, 1, 256, 128). Received saved weight with shape (256, 128, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #41 (named batch_normalization_12) due to mismatch in shape for weight batch_normalization_12/gamma:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #41 (named batch_normalization_12) due to mismatch in shape for weight batch_normalization_12/beta:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #41 (named batch_normalization_12) due to mismatch in shape for weight batch_normalization_12/moving_mean:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #41 (named batch_normalization_12) due to mismatch in shape for weight batch_normalization_12/moving_variance:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #44 (named conv2d_13) due to mismatch in shape for weight conv2d_13/kernel:0. Weight expects shape (3, 3, 128, 256). Received saved weight with shape (128, 256, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #45 (named batch_normalization_13) due to mismatch in shape for weight batch_normalization_13/gamma:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #45 (named batch_normalization_13) due to mismatch in shape for weight batch_normalization_13/beta:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #45 (named batch_normalization_13) due to mismatch in shape for weight batch_normalization_13/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #45 (named batch_normalization_13) due to mismatch in shape for weight batch_normalization_13/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #47 (named conv2d_14) due to mismatch in shape for weight conv2d_14/kernel:0. Weight expects shape (1, 1, 256, 128). Received saved weight with shape (256, 128, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #48 (named batch_normalization_14) due to mismatch in shape for weight batch_normalization_14/gamma:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #48 (named batch_normalization_14) due to mismatch in shape for weight batch_normalization_14/beta:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #48 (named batch_normalization_14) due to mismatch in shape for weight batch_normalization_14/moving_mean:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #48 (named batch_normalization_14) due to mismatch in shape for weight batch_normalization_14/moving_variance:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #51 (named conv2d_15) due to mismatch in shape for weight conv2d_15/kernel:0. Weight expects shape (3, 3, 128, 256). Received saved weight with shape (128, 256, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #52 (named batch_normalization_15) due to mismatch in shape for weight batch_normalization_15/gamma:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #52 (named batch_normalization_15) due to mismatch in shape for weight batch_normalization_15/beta:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #52 (named batch_normalization_15) due to mismatch in shape for weight batch_normalization_15/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #52 (named batch_normalization_15) due to mismatch in shape for weight batch_normalization_15/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #54 (named conv2d_16) due to mismatch in shape for weight conv2d_16/kernel:0. Weight expects shape (1, 1, 256, 128). Received saved weight with shape (256, 128, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #55 (named batch_normalization_16) due to mismatch in shape for weight batch_normalization_16/gamma:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #55 (named batch_normalization_16) due to mismatch in shape for weight batch_normalization_16/beta:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #55 (named batch_normalization_16) due to mismatch in shape for weight batch_normalization_16/moving_mean:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #55 (named batch_normalization_16) due to mismatch in shape for weight batch_normalization_16/moving_variance:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #58 (named conv2d_17) due to mismatch in shape for weight conv2d_17/kernel:0. Weight expects shape (3, 3, 128, 256). Received saved weight with shape (128, 256, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #59 (named batch_normalization_17) due to mismatch in shape for weight batch_normalization_17/gamma:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #59 (named batch_normalization_17) due to mismatch in shape for weight batch_normalization_17/beta:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #59 (named batch_normalization_17) due to mismatch in shape for weight batch_normalization_17/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #59 (named batch_normalization_17) due to mismatch in shape for weight batch_normalization_17/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #61 (named conv2d_18) due to mismatch in shape for weight conv2d_18/kernel:0. Weight expects shape (1, 1, 256, 128). Received saved weight with shape (256, 128, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #62 (named batch_normalization_18) due to mismatch in shape for weight batch_normalization_18/gamma:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #62 (named batch_normalization_18) due to mismatch in shape for weight batch_normalization_18/beta:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #62 (named batch_normalization_18) due to mismatch in shape for weight batch_normalization_18/moving_mean:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #62 (named batch_normalization_18) due to mismatch in shape for weight batch_normalization_18/moving_variance:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #65 (named conv2d_19) due to mismatch in shape for weight conv2d_19/kernel:0. Weight expects shape (3, 3, 128, 256). Received saved weight with shape (128, 256, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #66 (named batch_normalization_19) due to mismatch in shape for weight batch_normalization_19/gamma:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #66 (named batch_normalization_19) due to mismatch in shape for weight batch_normalization_19/beta:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #66 (named batch_normalization_19) due to mismatch in shape for weight batch_normalization_19/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #66 (named batch_normalization_19) due to mismatch in shape for weight batch_normalization_19/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #68 (named conv2d_20) due to mismatch in shape for weight conv2d_20/kernel:0. Weight expects shape (1, 1, 256, 128). Received saved weight with shape (256, 128, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #69 (named batch_normalization_20) due to mismatch in shape for weight batch_normalization_20/gamma:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #69 (named batch_normalization_20) due to mismatch in shape for weight batch_normalization_20/beta:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #69 (named batch_normalization_20) due to mismatch in shape for weight batch_normalization_20/moving_mean:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #69 (named batch_normalization_20) due to mismatch in shape for weight batch_normalization_20/moving_variance:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #72 (named conv2d_21) due to mismatch in shape for weight conv2d_21/kernel:0. Weight expects shape (3, 3, 128, 256). Received saved weight with shape (128, 256, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #73 (named batch_normalization_21) due to mismatch in shape for weight batch_normalization_21/gamma:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #73 (named batch_normalization_21) due to mismatch in shape for weight batch_normalization_21/beta:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #73 (named batch_normalization_21) due to mismatch in shape for weight batch_normalization_21/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #73 (named batch_normalization_21) due to mismatch in shape for weight batch_normalization_21/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #75 (named conv2d_22) due to mismatch in shape for weight conv2d_22/kernel:0. Weight expects shape (1, 1, 256, 128). Received saved weight with shape (256, 128, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #76 (named batch_normalization_22) due to mismatch in shape for weight batch_normalization_22/gamma:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #76 (named batch_normalization_22) due to mismatch in shape for weight batch_normalization_22/beta:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #76 (named batch_normalization_22) due to mismatch in shape for weight batch_normalization_22/moving_mean:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #76 (named batch_normalization_22) due to mismatch in shape for weight batch_normalization_22/moving_variance:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #79 (named conv2d_23) due to mismatch in shape for weight conv2d_23/kernel:0. Weight expects shape (3, 3, 128, 256). Received saved weight with shape (128, 256, 1, 1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create YOLOv3 model with 9 anchors and 13 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping loading weights for layer #80 (named batch_normalization_23) due to mismatch in shape for weight batch_normalization_23/gamma:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #80 (named batch_normalization_23) due to mismatch in shape for weight batch_normalization_23/beta:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #80 (named batch_normalization_23) due to mismatch in shape for weight batch_normalization_23/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #80 (named batch_normalization_23) due to mismatch in shape for weight batch_normalization_23/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #82 (named conv2d_24) due to mismatch in shape for weight conv2d_24/kernel:0. Weight expects shape (1, 1, 256, 128). Received saved weight with shape (256, 128, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #83 (named batch_normalization_24) due to mismatch in shape for weight batch_normalization_24/gamma:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #83 (named batch_normalization_24) due to mismatch in shape for weight batch_normalization_24/beta:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #83 (named batch_normalization_24) due to mismatch in shape for weight batch_normalization_24/moving_mean:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #83 (named batch_normalization_24) due to mismatch in shape for weight batch_normalization_24/moving_variance:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #86 (named conv2d_25) due to mismatch in shape for weight conv2d_25/kernel:0. Weight expects shape (3, 3, 128, 256). Received saved weight with shape (128, 256, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #87 (named batch_normalization_25) due to mismatch in shape for weight batch_normalization_25/gamma:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #87 (named batch_normalization_25) due to mismatch in shape for weight batch_normalization_25/beta:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #87 (named batch_normalization_25) due to mismatch in shape for weight batch_normalization_25/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #87 (named batch_normalization_25) due to mismatch in shape for weight batch_normalization_25/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #89 (named conv2d_26) due to mismatch in shape for weight conv2d_26/kernel:0. Weight expects shape (3, 3, 256, 512). Received saved weight with shape (256, 128, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #90 (named batch_normalization_26) due to mismatch in shape for weight batch_normalization_26/gamma:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #90 (named batch_normalization_26) due to mismatch in shape for weight batch_normalization_26/beta:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #90 (named batch_normalization_26) due to mismatch in shape for weight batch_normalization_26/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #90 (named batch_normalization_26) due to mismatch in shape for weight batch_normalization_26/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #94 (named conv2d_27) due to mismatch in shape for weight conv2d_27/kernel:0. Weight expects shape (1, 1, 512, 256). Received saved weight with shape (512, 256, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #95 (named batch_normalization_27) due to mismatch in shape for weight batch_normalization_27/gamma:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #95 (named batch_normalization_27) due to mismatch in shape for weight batch_normalization_27/beta:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #95 (named batch_normalization_27) due to mismatch in shape for weight batch_normalization_27/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #95 (named batch_normalization_27) due to mismatch in shape for weight batch_normalization_27/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #97 (named conv2d_28) due to mismatch in shape for weight conv2d_28/kernel:0. Weight expects shape (3, 3, 256, 512). Received saved weight with shape (256, 512, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #98 (named batch_normalization_28) due to mismatch in shape for weight batch_normalization_28/gamma:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #98 (named batch_normalization_28) due to mismatch in shape for weight batch_normalization_28/beta:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #98 (named batch_normalization_28) due to mismatch in shape for weight batch_normalization_28/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #98 (named batch_normalization_28) due to mismatch in shape for weight batch_normalization_28/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #100 (named conv2d_29) due to mismatch in shape for weight conv2d_29/kernel:0. Weight expects shape (1, 1, 512, 256). Received saved weight with shape (512, 256, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #101 (named batch_normalization_29) due to mismatch in shape for weight batch_normalization_29/gamma:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #101 (named batch_normalization_29) due to mismatch in shape for weight batch_normalization_29/beta:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #101 (named batch_normalization_29) due to mismatch in shape for weight batch_normalization_29/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #101 (named batch_normalization_29) due to mismatch in shape for weight batch_normalization_29/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #104 (named conv2d_30) due to mismatch in shape for weight conv2d_30/kernel:0. Weight expects shape (3, 3, 256, 512). Received saved weight with shape (256, 512, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #105 (named batch_normalization_30) due to mismatch in shape for weight batch_normalization_30/gamma:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #105 (named batch_normalization_30) due to mismatch in shape for weight batch_normalization_30/beta:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #105 (named batch_normalization_30) due to mismatch in shape for weight batch_normalization_30/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #105 (named batch_normalization_30) due to mismatch in shape for weight batch_normalization_30/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #107 (named conv2d_31) due to mismatch in shape for weight conv2d_31/kernel:0. Weight expects shape (1, 1, 512, 256). Received saved weight with shape (512, 256, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #108 (named batch_normalization_31) due to mismatch in shape for weight batch_normalization_31/gamma:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #108 (named batch_normalization_31) due to mismatch in shape for weight batch_normalization_31/beta:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #108 (named batch_normalization_31) due to mismatch in shape for weight batch_normalization_31/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #108 (named batch_normalization_31) due to mismatch in shape for weight batch_normalization_31/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #111 (named conv2d_32) due to mismatch in shape for weight conv2d_32/kernel:0. Weight expects shape (3, 3, 256, 512). Received saved weight with shape (256, 512, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #112 (named batch_normalization_32) due to mismatch in shape for weight batch_normalization_32/gamma:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #112 (named batch_normalization_32) due to mismatch in shape for weight batch_normalization_32/beta:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #112 (named batch_normalization_32) due to mismatch in shape for weight batch_normalization_32/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #112 (named batch_normalization_32) due to mismatch in shape for weight batch_normalization_32/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #114 (named conv2d_33) due to mismatch in shape for weight conv2d_33/kernel:0. Weight expects shape (1, 1, 512, 256). Received saved weight with shape (512, 256, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #115 (named batch_normalization_33) due to mismatch in shape for weight batch_normalization_33/gamma:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #115 (named batch_normalization_33) due to mismatch in shape for weight batch_normalization_33/beta:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #115 (named batch_normalization_33) due to mismatch in shape for weight batch_normalization_33/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #115 (named batch_normalization_33) due to mismatch in shape for weight batch_normalization_33/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #118 (named conv2d_34) due to mismatch in shape for weight conv2d_34/kernel:0. Weight expects shape (3, 3, 256, 512). Received saved weight with shape (256, 512, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #119 (named batch_normalization_34) due to mismatch in shape for weight batch_normalization_34/gamma:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #119 (named batch_normalization_34) due to mismatch in shape for weight batch_normalization_34/beta:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #119 (named batch_normalization_34) due to mismatch in shape for weight batch_normalization_34/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #119 (named batch_normalization_34) due to mismatch in shape for weight batch_normalization_34/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #121 (named conv2d_35) due to mismatch in shape for weight conv2d_35/kernel:0. Weight expects shape (1, 1, 512, 256). Received saved weight with shape (512, 256, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #122 (named batch_normalization_35) due to mismatch in shape for weight batch_normalization_35/gamma:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #122 (named batch_normalization_35) due to mismatch in shape for weight batch_normalization_35/beta:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #122 (named batch_normalization_35) due to mismatch in shape for weight batch_normalization_35/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #122 (named batch_normalization_35) due to mismatch in shape for weight batch_normalization_35/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #125 (named conv2d_36) due to mismatch in shape for weight conv2d_36/kernel:0. Weight expects shape (3, 3, 256, 512). Received saved weight with shape (256, 512, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #126 (named batch_normalization_36) due to mismatch in shape for weight batch_normalization_36/gamma:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #126 (named batch_normalization_36) due to mismatch in shape for weight batch_normalization_36/beta:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #126 (named batch_normalization_36) due to mismatch in shape for weight batch_normalization_36/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #126 (named batch_normalization_36) due to mismatch in shape for weight batch_normalization_36/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #128 (named conv2d_37) due to mismatch in shape for weight conv2d_37/kernel:0. Weight expects shape (1, 1, 512, 256). Received saved weight with shape (512, 256, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #129 (named batch_normalization_37) due to mismatch in shape for weight batch_normalization_37/gamma:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #129 (named batch_normalization_37) due to mismatch in shape for weight batch_normalization_37/beta:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #129 (named batch_normalization_37) due to mismatch in shape for weight batch_normalization_37/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #129 (named batch_normalization_37) due to mismatch in shape for weight batch_normalization_37/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #132 (named conv2d_38) due to mismatch in shape for weight conv2d_38/kernel:0. Weight expects shape (3, 3, 256, 512). Received saved weight with shape (256, 512, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #133 (named batch_normalization_38) due to mismatch in shape for weight batch_normalization_38/gamma:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #133 (named batch_normalization_38) due to mismatch in shape for weight batch_normalization_38/beta:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #133 (named batch_normalization_38) due to mismatch in shape for weight batch_normalization_38/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #133 (named batch_normalization_38) due to mismatch in shape for weight batch_normalization_38/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #135 (named conv2d_39) due to mismatch in shape for weight conv2d_39/kernel:0. Weight expects shape (1, 1, 512, 256). Received saved weight with shape (512, 256, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #136 (named batch_normalization_39) due to mismatch in shape for weight batch_normalization_39/gamma:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #136 (named batch_normalization_39) due to mismatch in shape for weight batch_normalization_39/beta:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #136 (named batch_normalization_39) due to mismatch in shape for weight batch_normalization_39/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #136 (named batch_normalization_39) due to mismatch in shape for weight batch_normalization_39/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #139 (named conv2d_40) due to mismatch in shape for weight conv2d_40/kernel:0. Weight expects shape (3, 3, 256, 512). Received saved weight with shape (256, 512, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #140 (named batch_normalization_40) due to mismatch in shape for weight batch_normalization_40/gamma:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #140 (named batch_normalization_40) due to mismatch in shape for weight batch_normalization_40/beta:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #140 (named batch_normalization_40) due to mismatch in shape for weight batch_normalization_40/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #140 (named batch_normalization_40) due to mismatch in shape for weight batch_normalization_40/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #142 (named conv2d_41) due to mismatch in shape for weight conv2d_41/kernel:0. Weight expects shape (1, 1, 512, 256). Received saved weight with shape (512, 256, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #143 (named batch_normalization_41) due to mismatch in shape for weight batch_normalization_41/gamma:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #143 (named batch_normalization_41) due to mismatch in shape for weight batch_normalization_41/beta:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #143 (named batch_normalization_41) due to mismatch in shape for weight batch_normalization_41/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #143 (named batch_normalization_41) due to mismatch in shape for weight batch_normalization_41/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #146 (named conv2d_42) due to mismatch in shape for weight conv2d_42/kernel:0. Weight expects shape (3, 3, 256, 512). Received saved weight with shape (256, 512, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #147 (named batch_normalization_42) due to mismatch in shape for weight batch_normalization_42/gamma:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #147 (named batch_normalization_42) due to mismatch in shape for weight batch_normalization_42/beta:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #147 (named batch_normalization_42) due to mismatch in shape for weight batch_normalization_42/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #147 (named batch_normalization_42) due to mismatch in shape for weight batch_normalization_42/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #149 (named conv2d_43) due to mismatch in shape for weight conv2d_43/kernel:0. Weight expects shape (3, 3, 512, 1024). Received saved weight with shape (512, 256, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #150 (named batch_normalization_43) due to mismatch in shape for weight batch_normalization_43/gamma:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #150 (named batch_normalization_43) due to mismatch in shape for weight batch_normalization_43/beta:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #150 (named batch_normalization_43) due to mismatch in shape for weight batch_normalization_43/moving_mean:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #150 (named batch_normalization_43) due to mismatch in shape for weight batch_normalization_43/moving_variance:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #154 (named conv2d_44) due to mismatch in shape for weight conv2d_44/kernel:0. Weight expects shape (1, 1, 1024, 512). Received saved weight with shape (1024, 512, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #155 (named batch_normalization_44) due to mismatch in shape for weight batch_normalization_44/gamma:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #155 (named batch_normalization_44) due to mismatch in shape for weight batch_normalization_44/beta:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #155 (named batch_normalization_44) due to mismatch in shape for weight batch_normalization_44/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #155 (named batch_normalization_44) due to mismatch in shape for weight batch_normalization_44/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #157 (named conv2d_45) due to mismatch in shape for weight conv2d_45/kernel:0. Weight expects shape (3, 3, 512, 1024). Received saved weight with shape (512, 1024, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #158 (named batch_normalization_45) due to mismatch in shape for weight batch_normalization_45/gamma:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #158 (named batch_normalization_45) due to mismatch in shape for weight batch_normalization_45/beta:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #158 (named batch_normalization_45) due to mismatch in shape for weight batch_normalization_45/moving_mean:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #158 (named batch_normalization_45) due to mismatch in shape for weight batch_normalization_45/moving_variance:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #160 (named conv2d_46) due to mismatch in shape for weight conv2d_46/kernel:0. Weight expects shape (1, 1, 1024, 512). Received saved weight with shape (1024, 512, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #161 (named batch_normalization_46) due to mismatch in shape for weight batch_normalization_46/gamma:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #161 (named batch_normalization_46) due to mismatch in shape for weight batch_normalization_46/beta:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #161 (named batch_normalization_46) due to mismatch in shape for weight batch_normalization_46/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #161 (named batch_normalization_46) due to mismatch in shape for weight batch_normalization_46/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #164 (named conv2d_47) due to mismatch in shape for weight conv2d_47/kernel:0. Weight expects shape (3, 3, 512, 1024). Received saved weight with shape (512, 1024, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #165 (named batch_normalization_47) due to mismatch in shape for weight batch_normalization_47/gamma:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #165 (named batch_normalization_47) due to mismatch in shape for weight batch_normalization_47/beta:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #165 (named batch_normalization_47) due to mismatch in shape for weight batch_normalization_47/moving_mean:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #165 (named batch_normalization_47) due to mismatch in shape for weight batch_normalization_47/moving_variance:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #167 (named conv2d_48) due to mismatch in shape for weight conv2d_48/kernel:0. Weight expects shape (1, 1, 1024, 512). Received saved weight with shape (1024, 512, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #168 (named batch_normalization_48) due to mismatch in shape for weight batch_normalization_48/gamma:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #168 (named batch_normalization_48) due to mismatch in shape for weight batch_normalization_48/beta:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #168 (named batch_normalization_48) due to mismatch in shape for weight batch_normalization_48/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #168 (named batch_normalization_48) due to mismatch in shape for weight batch_normalization_48/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #171 (named conv2d_49) due to mismatch in shape for weight conv2d_49/kernel:0. Weight expects shape (3, 3, 512, 1024). Received saved weight with shape (512, 1024, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #172 (named batch_normalization_49) due to mismatch in shape for weight batch_normalization_49/gamma:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #172 (named batch_normalization_49) due to mismatch in shape for weight batch_normalization_49/beta:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #172 (named batch_normalization_49) due to mismatch in shape for weight batch_normalization_49/moving_mean:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #172 (named batch_normalization_49) due to mismatch in shape for weight batch_normalization_49/moving_variance:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #174 (named conv2d_50) due to mismatch in shape for weight conv2d_50/kernel:0. Weight expects shape (1, 1, 1024, 512). Received saved weight with shape (1024, 512, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #175 (named batch_normalization_50) due to mismatch in shape for weight batch_normalization_50/gamma:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #175 (named batch_normalization_50) due to mismatch in shape for weight batch_normalization_50/beta:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #175 (named batch_normalization_50) due to mismatch in shape for weight batch_normalization_50/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #175 (named batch_normalization_50) due to mismatch in shape for weight batch_normalization_50/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #178 (named conv2d_51) due to mismatch in shape for weight conv2d_51/kernel:0. Weight expects shape (3, 3, 512, 1024). Received saved weight with shape (512, 1024, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #179 (named batch_normalization_51) due to mismatch in shape for weight batch_normalization_51/gamma:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #179 (named batch_normalization_51) due to mismatch in shape for weight batch_normalization_51/beta:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #179 (named batch_normalization_51) due to mismatch in shape for weight batch_normalization_51/moving_mean:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #179 (named batch_normalization_51) due to mismatch in shape for weight batch_normalization_51/moving_variance:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #181 (named conv2d_52) due to mismatch in shape for weight conv2d_52/kernel:0. Weight expects shape (1, 1, 1024, 512). Received saved weight with shape (1024, 512, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #182 (named batch_normalization_52) due to mismatch in shape for weight batch_normalization_52/gamma:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #182 (named batch_normalization_52) due to mismatch in shape for weight batch_normalization_52/beta:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #182 (named batch_normalization_52) due to mismatch in shape for weight batch_normalization_52/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #182 (named batch_normalization_52) due to mismatch in shape for weight batch_normalization_52/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #185 (named conv2d_53) due to mismatch in shape for weight conv2d_53/kernel:0. Weight expects shape (3, 3, 512, 1024). Received saved weight with shape (512, 1024, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #186 (named batch_normalization_53) due to mismatch in shape for weight batch_normalization_53/gamma:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #186 (named batch_normalization_53) due to mismatch in shape for weight batch_normalization_53/beta:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #186 (named batch_normalization_53) due to mismatch in shape for weight batch_normalization_53/moving_mean:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #186 (named batch_normalization_53) due to mismatch in shape for weight batch_normalization_53/moving_variance:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #188 (named conv2d_54) due to mismatch in shape for weight conv2d_54/kernel:0. Weight expects shape (1, 1, 1024, 512). Received saved weight with shape (1024, 512, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #189 (named batch_normalization_54) due to mismatch in shape for weight batch_normalization_54/gamma:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #189 (named batch_normalization_54) due to mismatch in shape for weight batch_normalization_54/beta:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #189 (named batch_normalization_54) due to mismatch in shape for weight batch_normalization_54/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #189 (named batch_normalization_54) due to mismatch in shape for weight batch_normalization_54/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #191 (named conv2d_55) due to mismatch in shape for weight conv2d_55/kernel:0. Weight expects shape (3, 3, 512, 1024). Received saved weight with shape (512, 1024, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #192 (named batch_normalization_55) due to mismatch in shape for weight batch_normalization_55/gamma:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #192 (named batch_normalization_55) due to mismatch in shape for weight batch_normalization_55/beta:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #192 (named batch_normalization_55) due to mismatch in shape for weight batch_normalization_55/moving_mean:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #192 (named batch_normalization_55) due to mismatch in shape for weight batch_normalization_55/moving_variance:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #194 (named conv2d_56) due to mismatch in shape for weight conv2d_56/kernel:0. Weight expects shape (1, 1, 1024, 512). Received saved weight with shape (1024, 512, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #195 (named batch_normalization_56) due to mismatch in shape for weight batch_normalization_56/gamma:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #195 (named batch_normalization_56) due to mismatch in shape for weight batch_normalization_56/beta:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #195 (named batch_normalization_56) due to mismatch in shape for weight batch_normalization_56/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #195 (named batch_normalization_56) due to mismatch in shape for weight batch_normalization_56/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #197 (named conv2d_57) due to mismatch in shape for weight conv2d_57/kernel:0. Weight expects shape (3, 3, 512, 1024). Received saved weight with shape (512, 1024, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #198 (named batch_normalization_57) due to mismatch in shape for weight batch_normalization_57/gamma:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #198 (named batch_normalization_57) due to mismatch in shape for weight batch_normalization_57/beta:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #198 (named batch_normalization_57) due to mismatch in shape for weight batch_normalization_57/moving_mean:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #198 (named batch_normalization_57) due to mismatch in shape for weight batch_normalization_57/moving_variance:0. Weight expects shape (1024,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #200 (named conv2d_60) due to mismatch in shape for weight conv2d_60/kernel:0. Weight expects shape (1, 1, 768, 256). Received saved weight with shape (256, 512, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #205 (named conv2d_61) due to mismatch in shape for weight conv2d_61/kernel:0. Weight expects shape (3, 3, 256, 512). Received saved weight with shape (256, 768, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #206 (named batch_normalization_60) due to mismatch in shape for weight batch_normalization_60/gamma:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #206 (named batch_normalization_60) due to mismatch in shape for weight batch_normalization_60/beta:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #206 (named batch_normalization_60) due to mismatch in shape for weight batch_normalization_60/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #206 (named batch_normalization_60) due to mismatch in shape for weight batch_normalization_60/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #208 (named conv2d_62) due to mismatch in shape for weight conv2d_62/kernel:0. Weight expects shape (1, 1, 512, 256). Received saved weight with shape (512, 256, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #209 (named batch_normalization_61) due to mismatch in shape for weight batch_normalization_61/gamma:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #209 (named batch_normalization_61) due to mismatch in shape for weight batch_normalization_61/beta:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #209 (named batch_normalization_61) due to mismatch in shape for weight batch_normalization_61/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #209 (named batch_normalization_61) due to mismatch in shape for weight batch_normalization_61/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #211 (named conv2d_63) due to mismatch in shape for weight conv2d_63/kernel:0. Weight expects shape (3, 3, 256, 512). Received saved weight with shape (256, 512, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #212 (named batch_normalization_62) due to mismatch in shape for weight batch_normalization_62/gamma:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #212 (named batch_normalization_62) due to mismatch in shape for weight batch_normalization_62/beta:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #212 (named batch_normalization_62) due to mismatch in shape for weight batch_normalization_62/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #212 (named batch_normalization_62) due to mismatch in shape for weight batch_normalization_62/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #214 (named conv2d_64) due to mismatch in shape for weight conv2d_64/kernel:0. Weight expects shape (1, 1, 512, 256). Received saved weight with shape (512, 256, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #215 (named batch_normalization_63) due to mismatch in shape for weight batch_normalization_63/gamma:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #215 (named batch_normalization_63) due to mismatch in shape for weight batch_normalization_63/beta:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #215 (named batch_normalization_63) due to mismatch in shape for weight batch_normalization_63/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #215 (named batch_normalization_63) due to mismatch in shape for weight batch_normalization_63/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #217 (named conv2d_65) due to mismatch in shape for weight conv2d_65/kernel:0. Weight expects shape (3, 3, 256, 512). Received saved weight with shape (256, 512, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #218 (named batch_normalization_64) due to mismatch in shape for weight batch_normalization_64/gamma:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #218 (named batch_normalization_64) due to mismatch in shape for weight batch_normalization_64/beta:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #218 (named batch_normalization_64) due to mismatch in shape for weight batch_normalization_64/moving_mean:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #218 (named batch_normalization_64) due to mismatch in shape for weight batch_normalization_64/moving_variance:0. Weight expects shape (512,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #220 (named conv2d_68) due to mismatch in shape for weight conv2d_68/kernel:0. Weight expects shape (1, 1, 384, 128). Received saved weight with shape (128, 256, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #225 (named conv2d_69) due to mismatch in shape for weight conv2d_69/kernel:0. Weight expects shape (3, 3, 128, 256). Received saved weight with shape (128, 384, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #226 (named batch_normalization_67) due to mismatch in shape for weight batch_normalization_67/gamma:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #226 (named batch_normalization_67) due to mismatch in shape for weight batch_normalization_67/beta:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #226 (named batch_normalization_67) due to mismatch in shape for weight batch_normalization_67/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #226 (named batch_normalization_67) due to mismatch in shape for weight batch_normalization_67/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #228 (named conv2d_70) due to mismatch in shape for weight conv2d_70/kernel:0. Weight expects shape (1, 1, 256, 128). Received saved weight with shape (256, 128, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #229 (named batch_normalization_68) due to mismatch in shape for weight batch_normalization_68/gamma:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #229 (named batch_normalization_68) due to mismatch in shape for weight batch_normalization_68/beta:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #229 (named batch_normalization_68) due to mismatch in shape for weight batch_normalization_68/moving_mean:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #229 (named batch_normalization_68) due to mismatch in shape for weight batch_normalization_68/moving_variance:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #231 (named conv2d_71) due to mismatch in shape for weight conv2d_71/kernel:0. Weight expects shape (3, 3, 128, 256). Received saved weight with shape (128, 256, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #232 (named batch_normalization_69) due to mismatch in shape for weight batch_normalization_69/gamma:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #232 (named batch_normalization_69) due to mismatch in shape for weight batch_normalization_69/beta:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #232 (named batch_normalization_69) due to mismatch in shape for weight batch_normalization_69/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #232 (named batch_normalization_69) due to mismatch in shape for weight batch_normalization_69/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #234 (named conv2d_72) due to mismatch in shape for weight conv2d_72/kernel:0. Weight expects shape (1, 1, 256, 128). Received saved weight with shape (256, 128, 3, 3)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #235 (named batch_normalization_70) due to mismatch in shape for weight batch_normalization_70/gamma:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #235 (named batch_normalization_70) due to mismatch in shape for weight batch_normalization_70/beta:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #235 (named batch_normalization_70) due to mismatch in shape for weight batch_normalization_70/moving_mean:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #235 (named batch_normalization_70) due to mismatch in shape for weight batch_normalization_70/moving_variance:0. Weight expects shape (128,). Received saved weight with shape (256,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #237 (named conv2d_73) due to mismatch in shape for weight conv2d_73/kernel:0. Weight expects shape (3, 3, 128, 256). Received saved weight with shape (128, 256, 1, 1)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #238 (named batch_normalization_71) due to mismatch in shape for weight batch_normalization_71/gamma:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #238 (named batch_normalization_71) due to mismatch in shape for weight batch_normalization_71/beta:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #238 (named batch_normalization_71) due to mismatch in shape for weight batch_normalization_71/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #238 (named batch_normalization_71) due to mismatch in shape for weight batch_normalization_71/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (128,)\n",
            "WARNING:tensorflow:Skipping loading of weights for layer #240 (named conv2d_58) due to mismatch in number of weights. Layer expects 2 weight(s). Received 1 saved weight(s)\n",
            "WARNING:tensorflow:Skipping loading of weights for layer #241 (named conv2d_66) due to mismatch in number of weights. Layer expects 2 weight(s). Received 1 saved weight(s)\n",
            "WARNING:tensorflow:Skipping loading of weights for layer #242 (named conv2d_74) due to mismatch in number of weights. Layer expects 2 weight(s). Received 1 saved weight(s)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #243 (named batch_normalization_58) due to mismatch in shape for weight batch_normalization_58/gamma:0. Weight expects shape (256,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #243 (named batch_normalization_58) due to mismatch in shape for weight batch_normalization_58/beta:0. Weight expects shape (256,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #243 (named batch_normalization_58) due to mismatch in shape for weight batch_normalization_58/moving_mean:0. Weight expects shape (256,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #243 (named batch_normalization_58) due to mismatch in shape for weight batch_normalization_58/moving_variance:0. Weight expects shape (256,). Received saved weight with shape (1024,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #244 (named batch_normalization_65) due to mismatch in shape for weight batch_normalization_65/gamma:0. Weight expects shape (128,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #244 (named batch_normalization_65) due to mismatch in shape for weight batch_normalization_65/beta:0. Weight expects shape (128,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #244 (named batch_normalization_65) due to mismatch in shape for weight batch_normalization_65/moving_mean:0. Weight expects shape (128,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading weights for layer #244 (named batch_normalization_65) due to mismatch in shape for weight batch_normalization_65/moving_variance:0. Weight expects shape (128,). Received saved weight with shape (512,)\n",
            "WARNING:tensorflow:Skipping loading of weights for layer #249 (named conv2d_59) due to mismatch in number of weights. Layer expects 1 weight(s). Received 2 saved weight(s)\n",
            "WARNING:tensorflow:Skipping loading of weights for layer #250 (named conv2d_67) due to mismatch in number of weights. Layer expects 1 weight(s). Received 2 saved weight(s)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load weights model_data/yolo.h5.\n",
            "Freeze the first 249 layers of total 252 layers.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-24-4000e33e97dd>:62: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 485 samples, val on 121 samples, with batch size 32.\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 68s 3s/step - loss: 6733.2632 - val_loss: 5689.3042\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 4969.5767 - val_loss: 4316.5547\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 3929.9155 - val_loss: 3529.4773\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 3183.5647 - val_loss: 2905.9753\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 2656.5554 - val_loss: 2431.2898\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 42s 3s/step - loss: 2256.7410 - val_loss: 2116.1836\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 1952.4166 - val_loss: 1838.6471\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 1702.8302 - val_loss: 1605.6627\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 41s 3s/step - loss: 1501.6453 - val_loss: 1410.7443\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 41s 3s/step - loss: 1335.0844 - val_loss: 1307.1454\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 1198.7023 - val_loss: 1133.5880\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 43s 3s/step - loss: 1088.0710 - val_loss: 1064.0566\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 41s 3s/step - loss: 992.0398 - val_loss: 973.0200\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 928.0815 - val_loss: 873.3094\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 44s 3s/step - loss: 854.5637 - val_loss: 843.5269\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 787.6256 - val_loss: 760.8005\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 740.7978 - val_loss: 690.2160\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 44s 3s/step - loss: 688.7546 - val_loss: 683.1353\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 652.4343 - val_loss: 609.6424\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 615.9363 - val_loss: 637.2894\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 45s 3s/step - loss: 587.0986 - val_loss: 578.9739\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 553.3613 - val_loss: 548.3095\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 41s 3s/step - loss: 529.9490 - val_loss: 546.7839\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 45s 3s/step - loss: 492.8919 - val_loss: 505.2185\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 484.2397 - val_loss: 495.7664\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 463.1848 - val_loss: 469.7141\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 41s 3s/step - loss: 444.8804 - val_loss: 477.2668\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 423.1716 - val_loss: 463.6015\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 398.9616 - val_loss: 424.7126\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 51s 4s/step - loss: 410.7959 - val_loss: 432.3932\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 376.4940 - val_loss: 396.8722\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 377.2176 - val_loss: 381.4202\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 45s 3s/step - loss: 354.8221 - val_loss: 393.1423\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 352.0507 - val_loss: 358.1499\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 339.0653 - val_loss: 339.8529\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 42s 3s/step - loss: 331.8840 - val_loss: 349.9238\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 322.6307 - val_loss: 340.2316\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 307.2904 - val_loss: 319.0593\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 45s 3s/step - loss: 309.6865 - val_loss: 331.7798\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 306.4482 - val_loss: 323.5012\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 308.7077 - val_loss: 299.4660\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 46s 3s/step - loss: 282.4796 - val_loss: 305.0940\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 289.8405 - val_loss: 298.5493\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 275.5987 - val_loss: 288.0119\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 41s 3s/step - loss: 272.2071 - val_loss: 278.8210\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 263.6799 - val_loss: 284.8224\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 37s 3s/step - loss: 257.9639 - val_loss: 284.0878\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 45s 3s/step - loss: 257.7780 - val_loss: 246.4240\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 252.1956 - val_loss: 269.0352\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 253.9751 - val_loss: 252.9249\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 44s 3s/step - loss: 241.9012 - val_loss: 244.0731\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 247.7070 - val_loss: 258.8232\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 231.5049 - val_loss: 251.0775\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 230.9035 - val_loss: 245.0518\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 232.4988 - val_loss: 246.9952\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 228.9249 - val_loss: 242.9271\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 217.7407 - val_loss: 250.0245\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 219.2038 - val_loss: 224.2639\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 221.2991 - val_loss: 224.9149\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 216.1694 - val_loss: 227.7427\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 209.1997 - val_loss: 223.4837\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 216.8671 - val_loss: 236.5106\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 44s 3s/step - loss: 209.6718 - val_loss: 196.5970\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 206.3732 - val_loss: 231.1318\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 205.1314 - val_loss: 215.1389\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 201.3992 - val_loss: 210.8424\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 196.2188 - val_loss: 206.3229\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 197.1885 - val_loss: 214.1415\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 195.9600 - val_loss: 211.2606\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 197.5817 - val_loss: 211.0878\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 191.2763 - val_loss: 198.5929\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 186.5159 - val_loss: 204.8740\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 190.6539 - val_loss: 202.9035\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 182.9492 - val_loss: 199.4714\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 185.0459 - val_loss: 206.3907\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 183.0875 - val_loss: 196.6480\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 179.3400 - val_loss: 195.8466\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 42s 3s/step - loss: 183.8137 - val_loss: 186.3706\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 178.8996 - val_loss: 182.7124\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 181.5725 - val_loss: 183.5095\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 174.1083 - val_loss: 193.6531\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 173.9783 - val_loss: 179.2453\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 175.2676 - val_loss: 186.4788\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 173.9808 - val_loss: 192.3298\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 172.8144 - val_loss: 177.5053\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 169.9291 - val_loss: 192.5528\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 168.3002 - val_loss: 188.8269\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 171.1684 - val_loss: 188.4311\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 164.2710 - val_loss: 171.7152\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 43s 3s/step - loss: 171.0474 - val_loss: 170.3179\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 40s 3s/step - loss: 164.7795 - val_loss: 188.4789\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 165.8781 - val_loss: 171.3673\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 164.1362 - val_loss: 180.3255\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 158.8119 - val_loss: 153.8375\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 161.8929 - val_loss: 178.9937\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 161.6533 - val_loss: 175.2287\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 162.1103 - val_loss: 166.2340\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 160.8703 - val_loss: 171.6461\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 39s 3s/step - loss: 160.6250 - val_loss: 180.1338\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 38s 3s/step - loss: 156.4658 - val_loss: 171.1443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-24-4000e33e97dd>:81: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unfreeze all of the layers.\n",
            "Train on 485 samples, val on 121 samples, with batch size 32.\n",
            "Epoch 26/75\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node model_2/batch_normalization_61/FusedBatchNormV3 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-24-4000e33e97dd>\", line 193, in <cell line: 192>\n\n  File \"<ipython-input-24-4000e33e97dd>\", line 81, in _main\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2913, in fit_generator\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py\", line 597, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py\", line 990, in _fused_batch_norm\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/control_flow_util.py\", line 108, in smart_cond\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py\", line 964, in _fused_batch_norm_training\n\nOOM when allocating tensor with shape[32,256,26,26] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_2/batch_normalization_61/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_76705]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-4000e33e97dd>\u001b[0m in \u001b[0;36m<cell line: 192>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0m_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-4000e33e97dd>\u001b[0m in \u001b[0;36m_main\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;31m# note that more GPU memory is required after unfreezing the body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train on {} samples, val on {} samples, with batch size {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_train\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_generator_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2911\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2912\u001b[0m         )\n\u001b[0;32m-> 2913\u001b[0;31m         return self.fit(\n\u001b[0m\u001b[1;32m   2914\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2915\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node model_2/batch_normalization_61/FusedBatchNormV3 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-24-4000e33e97dd>\", line 193, in <cell line: 192>\n\n  File \"<ipython-input-24-4000e33e97dd>\", line 81, in _main\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2913, in fit_generator\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py\", line 597, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py\", line 990, in _fused_batch_norm\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/control_flow_util.py\", line 108, in smart_cond\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py\", line 964, in _fused_batch_norm_training\n\nOOM when allocating tensor with shape[32,256,26,26] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_2/batch_normalization_61/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_76705]"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Self-contained Python script to train YOLOv3 on your own dataset\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.layers import Input, Lambda\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
        "from yolo3.utils import get_random_data\n",
        "\n",
        "\n",
        "def _main():\n",
        "    annotation_path = '_annotations.txt'  # path to Roboflow data annotations\n",
        "    log_dir = 'logs/000/'                 # where we're storing our logs\n",
        "    classes_path = '_classes.txt'         # path to Roboflow class names\n",
        "    anchors_path = 'model_data/yolo_anchors.txt'\n",
        "    class_names = get_classes(classes_path)\n",
        "    print(\"-------------------CLASS NAMES-------------------\")\n",
        "    print(class_names)\n",
        "    print(\"-------------------CLASS NAMES-------------------\")\n",
        "    num_classes = len(class_names)\n",
        "    anchors = get_anchors(anchors_path)\n",
        "\n",
        "    input_shape = (416,416) # multiple of 32, hw\n",
        "\n",
        "    is_tiny_version = len(anchors)==6 # default setting\n",
        "    if is_tiny_version:\n",
        "        model = create_tiny_model(input_shape, anchors, num_classes,\n",
        "            freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n",
        "    else:\n",
        "        model = create_model(input_shape, anchors, num_classes,\n",
        "            freeze_body=2, weights_path='model_data/yolo.h5') # make sure you know what you freeze\n",
        "\n",
        "    logging = TensorBoard(log_dir=log_dir)\n",
        "    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
        "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
        "\n",
        "    val_split = 0.2 # set the size of the validation set\n",
        "    with open(annotation_path) as f:\n",
        "        lines = f.readlines()\n",
        "    np.random.seed(10101)\n",
        "    np.random.shuffle(lines)\n",
        "    np.random.seed(None)\n",
        "    num_val = int(len(lines)*val_split)\n",
        "    num_train = len(lines) - num_val\n",
        "\n",
        "    # Train with frozen layers first, to get a stable loss.\n",
        "    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
        "    if True:\n",
        "        model.compile(optimizer=Adam(lr=1e-3), loss={\n",
        "            # use custom yolo_loss Lambda layer.\n",
        "            'yolo_loss': lambda y_true, y_pred: y_pred})\n",
        "\n",
        "        batch_size = 32\n",
        "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "                steps_per_epoch=max(1, num_train//batch_size),\n",
        "                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "                validation_steps=max(1, num_val//batch_size),\n",
        "                epochs=100,\n",
        "                initial_epoch=0,\n",
        "                callbacks=[logging, checkpoint])\n",
        "        model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
        "\n",
        "    # Unfreeze and continue training, to fine-tune.\n",
        "    # Train longer if the result is not good.\n",
        "    if True:\n",
        "        for i in range(len(model.layers)):\n",
        "            model.layers[i].trainable = True\n",
        "        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
        "        print('Unfreeze all of the layers.')\n",
        "\n",
        "        batch_size = 32 # note that more GPU memory is required after unfreezing the body\n",
        "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "            steps_per_epoch=max(1, num_train//batch_size),\n",
        "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "            validation_steps=max(1, num_val//batch_size),\n",
        "            epochs=75,\n",
        "            initial_epoch=25,\n",
        "            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
        "        model.save_weights(log_dir + 'trained_weights_final.h5')\n",
        "\n",
        "    # Further training if needed.\n",
        "\n",
        "\n",
        "def get_classes(classes_path):\n",
        "    '''loads the classes'''\n",
        "    with open(classes_path) as f:\n",
        "        class_names = f.readlines()\n",
        "    class_names = [c.strip() for c in class_names]\n",
        "    return class_names\n",
        "\n",
        "def get_anchors(anchors_path):\n",
        "    '''loads the anchors from a file'''\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "    anchors = [float(x) for x in anchors.split(',')]\n",
        "    return np.array(anchors).reshape(-1, 2)\n",
        "\n",
        "\n",
        "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
        "            weights_path='model_data/yolo.h5'):\n",
        "    '''create the training model'''\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
        "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
        "\n",
        "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
        "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
        "\n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "        if freeze_body in [1, 2]:\n",
        "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
        "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        "\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
        "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
        "    '''create the training model, for Tiny YOLOv3'''\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
        "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
        "\n",
        "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
        "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
        "\n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "        if freeze_body in [1, 2]:\n",
        "            # Freeze the darknet body or freeze all but 2 output layers.\n",
        "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        "\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "\n",
        "    return model\n",
        "\n",
        "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    '''data generator for fit_generator'''\n",
        "    n = len(annotation_lines)\n",
        "    i = 0\n",
        "    while True:\n",
        "        image_data = []\n",
        "        box_data = []\n",
        "        for b in range(batch_size):\n",
        "            if i==0:\n",
        "                np.random.shuffle(annotation_lines)\n",
        "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
        "            image_data.append(image)\n",
        "            box_data.append(box)\n",
        "            i = (i+1) % n\n",
        "        image_data = np.array(image_data)\n",
        "        box_data = np.array(box_data)\n",
        "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
        "        yield [image_data, *y_true], np.zeros(batch_size)\n",
        "\n",
        "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    n = len(annotation_lines)\n",
        "    if n==0 or batch_size<=0: return None\n",
        "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    _main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SGHHX4zfgSF"
      },
      "source": [
        "The code when ran, resulted on an OOM error or Out Of Memory error: `OOM when allocating tensor with shape[32,256,26,26] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48yw4UaOYgQS"
      },
      "outputs": [],
      "source": [
        "## can call this cell instead of the above\n",
        "# !python train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFX-2_M8bMQ3"
      },
      "source": [
        "## Use our model for inference\n",
        "\n",
        "For predictions, we'll call a a Python script called `yolo_video.py` with required arguments for our use case: a path to our specific first stage trained weights (see our blog for why we're using only stage one), a path to our custom class names, and a flag to specify we're using images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlVyevd8b8gG"
      },
      "source": [
        "Additional arguments for `yolo_video.py` are as follows:\n",
        "\n",
        "```\n",
        "usage: yolo_video.py [-h] [--model MODEL] [--anchors ANCHORS]\n",
        "                     [--classes CLASSES] [--gpu_num GPU_NUM] [--image]\n",
        "                     [--input] [--output]\n",
        "\n",
        "positional arguments:\n",
        "  --input        Video input path\n",
        "  --output       Video output path\n",
        "\n",
        "optional arguments:\n",
        "  -h, --help         show this help message and exit\n",
        "  --model MODEL      path to model weight file, default model_data/yolo.h5\n",
        "  --anchors ANCHORS  path to anchor definitions, default\n",
        "                     model_data/yolo_anchors.txt\n",
        "  --classes CLASSES  path to class definitions, default\n",
        "                     model_data/coco_classes.txt\n",
        "  --gpu_num GPU_NUM  Number of GPU to use, default 1\n",
        "  --image            Image detection mode, will ignore all positional arguments\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcJbmgNEO1bE"
      },
      "outputs": [],
      "source": [
        "!python yolo_video.py --model=\"./logs/000/trained_weights_stage_1.h5\" --classes=\"_classes.txt\" --image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbACT_RJdGVg"
      },
      "source": [
        "For input image names into the above, consider trying the following:\n",
        "\n",
        "- `00a7a49c47d51fd16a4cbb17e2d2cf86.jpg` # white-king works! + knight\n",
        "- `015d0d7ff365f0b7492ff079c8c7d56c.jpg` # black-queen mixes up\n",
        "- `176b28b5c417f39a9e5d37545fca5b4c.jpg` # finds only five\n",
        "- `4673f994f60a2ea7afdddc1b752947c0.jpg` # white-rook (thinks king)\n",
        "- `5ca7f0cb1c500554e65ad031190f8e9f.jpg` # white-pawn (missed white-king)\n",
        "- `fbf15139f38a46e02b5f4061c0c9b08f.jpg` # black-king success!\n",
        "\n",
        "You can view these images in your Colab notebook by clicking on the image name in the expanded left-hand panel (Files â†’ keras-yolo3 â†’ IMG_NAME )."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88oJlBl4dumo"
      },
      "source": [
        "## Move currently trained model to GDrive\n",
        "\n",
        "Optionally, you may want to save the new weights that your model trained so that the next time you run this notebook, you can either skip training and use these weights for inference or begin training where you left off with this weights file.\n",
        "\n",
        "Following the below will link your Colab notebook to your Google Drive, and save the weights (named as the current time you saved them to enforce a unique file name) in your Drive folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4t94dBNdsxz"
      },
      "outputs": [],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLe0Y4Z8BOVF"
      },
      "outputs": [],
      "source": [
        "# create a copy of the weights file with a datetime\n",
        "# and move that file to your own Drive\n",
        "%cp ./logs/000/trained_weights_stage_1.h5 ./logs/000/trained_weights_stage_1_$(date +%F-%H:%M).h5\n",
        "%mv ./logs/000/trained_weights_stage_1_$(date +%F-%H:%M).h5 /content/drive/My\\ Drive/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk-McnkGlHfq"
      },
      "source": [
        "# Supplementary Activity (Custom dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpLCafeEtL1G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
